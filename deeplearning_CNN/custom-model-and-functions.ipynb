{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true,y_pred):\n",
    "    error = y_true,y_pred\n",
    "    is_small_error = tf.abs(error)<1\n",
    "    squared_loss = tf.square(error)/2\n",
    "    linear_loss = tf.abs(error)-0.5\n",
    "    return tf.where(is_small_error,squared_loss,linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_pytorcch/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - loss: 0.8762 - val_loss: 0.8128\n",
      "Epoch 2/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.8093 - val_loss: 0.7901\n",
      "Epoch 3/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.8062 - val_loss: 0.7773\n",
      "Epoch 4/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - loss: 0.8051 - val_loss: 0.7743\n",
      "Epoch 5/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 0.8046 - val_loss: 0.7789\n",
      "Epoch 6/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 0.8044 - val_loss: 0.7741\n",
      "Epoch 7/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.8042 - val_loss: 0.7778\n",
      "Epoch 8/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.8041 - val_loss: 0.7745\n",
      "Epoch 9/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 0.8041 - val_loss: 0.7773\n",
      "Epoch 10/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.8039 - val_loss: 0.7750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x306c23450>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=huber_fn,optimizer='nadam')\n",
    "model.fit(X_train_scaled,y_train,validation_data=(X_valid_scaled,y_valid),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model.save(\"custom_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= keras.models.load_model(\"./custom_model.keras\",custom_objects={\"huber_fn\":huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - loss: 0.8038 - val_loss: 0.7768\n",
      "Epoch 2/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 0.8037 - val_loss: 0.7753\n",
      "Epoch 3/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.8037 - val_loss: 0.7765\n",
      "Epoch 4/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 0.8036 - val_loss: 0.7765\n",
      "Epoch 5/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 0.8037 - val_loss: 0.7761\n",
      "Epoch 6/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.8036 - val_loss: 0.7764\n",
      "Epoch 7/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 0.8036 - val_loss: 0.7759\n",
      "Epoch 8/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 0.8036 - val_loss: 0.7762\n",
      "Epoch 9/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 0.8036 - val_loss: 0.7763\n",
      "Epoch 10/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 0.8035 - val_loss: 0.7762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x306be2fd0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train,epochs=10,validation_data=(X_valid_scaled,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true,y_pred):\n",
    "        error = y_true-y_pred\n",
    "        is_small_error = tf.abs(error)<threshold\n",
    "        sqaured_loss= tf.square(error)/2\n",
    "        linear_loss  = threshold*tf.abs(error)-threshold**2/2\n",
    "        return tf.where(is_small_error,sqaured_loss,linear_loss)\n",
    "    return huber_fn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0),optimizer=\"nadam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"custom_model_with_threshold.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_pytorcch/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'nadam', because it has 11 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model= keras.models.load_model(\"custom_model_with_threshold.keras\",custom_objects={\"huber_fn\":create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberClass(keras.losses.Loss):\n",
    "    def __init__(self, threshold=2.0,**kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self,y_true,y_pred):\n",
    "        error  = y_true-y_pred\n",
    "        is_small_error= tf.abs(error)<self.threshold\n",
    "        squared_loss = tf.square(error)/2\n",
    "        linear_loss = self.threshold*tf.abs(error)-self.threshold**2/2\n",
    "        return tf.where(is_small_error,squared_loss,linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config=super().get_config()\n",
    "        return {**base_config,\"threshold\":self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential_6, built=True>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "model = keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30,activation=\"relu\",kernel_initializer=\"he_normal\",input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberClass(2.),optimizer=\"nadam\",metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - loss: 1.0512 - mae: 1.1438 - val_loss: 0.5086 - val_mae: 0.6718\n",
      "Epoch 2/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - loss: 0.3170 - mae: 0.5816 - val_loss: 0.3527 - val_mae: 0.5571\n",
      "Epoch 3/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 0.2611 - mae: 0.5243 - val_loss: 0.2689 - val_mae: 0.4982\n",
      "Epoch 4/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.2328 - mae: 0.4929 - val_loss: 0.2207 - val_mae: 0.4657\n",
      "Epoch 5/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 0.2178 - mae: 0.4754 - val_loss: 0.1899 - val_mae: 0.4453\n",
      "Epoch 6/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - loss: 0.2093 - mae: 0.4654 - val_loss: 0.1996 - val_mae: 0.4471\n",
      "Epoch 7/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 0.2036 - mae: 0.4589 - val_loss: 0.2243 - val_mae: 0.4549\n",
      "Epoch 8/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 0.1995 - mae: 0.4528 - val_loss: 0.1774 - val_mae: 0.4297\n",
      "Epoch 9/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 0.1953 - mae: 0.4484 - val_loss: 0.1850 - val_mae: 0.4317\n",
      "Epoch 10/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 0.1926 - mae: 0.4448 - val_loss: 0.2058 - val_mae: 0.4387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x148942f50>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train,epochs=10,validation_data=(X_valid_scaled,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"custom_model_with_loss_function_class.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= keras.models.load_model(\"./custom_model_with_loss_function_class.keras\",custom_objects={\"HuberClass\":HuberClass})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - loss: 0.1904 - mae: 0.4411 - val_loss: 429.6693 - val_mae: 215.8347\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 0.1878 - mae: 0.4383 - val_loss: 437.0641 - val_mae: 219.5320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x148cb2f50>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train,validation_data=(X_valid,y_valid),epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Activations , Initializers , Regularizers ,and Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softpluz(z):\n",
    "    return tf.math.log(tf.exp(z)+1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_glorot_initializer(shape,dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2./(shape[0]+shape[1]))\n",
    "    return tf.random.normal(shape,stddev=stddev,dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01*weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_positive_weights(weights):\n",
    "    return tf.where(weights<0.,tf.zeros_like(weights),weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(30,activation=my_softpluz,kernel_initializer=my_glorot_initializer,kernel_regularizer=my_l1_regularizer,kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self,factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self,weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor*weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\":self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "model = keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30,activation=\"relu\",kernel_initializer=\"he_normal\",input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\",optimizer=\"nadam\",metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 375us/step - huber_fn: 1.0833 - loss: 2.6041\n",
      "Epoch 2/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - huber_fn: 0.3403 - loss: 0.7644\n",
      "Epoch 3/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - huber_fn: 0.2811 - loss: 0.6060\n",
      "Epoch 4/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - huber_fn: 0.2461 - loss: 0.5150\n",
      "Epoch 5/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - huber_fn: 0.2273 - loss: 0.4674\n",
      "Epoch 6/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - huber_fn: 0.2166 - loss: 0.4419\n",
      "Epoch 7/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - huber_fn: 0.2097 - loss: 0.4269\n",
      "Epoch 8/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - huber_fn: 0.2048 - loss: 0.4167\n",
      "Epoch 9/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - huber_fn: 0.2010 - loss: 0.4091\n",
      "Epoch 10/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - huber_fn: 0.1980 - loss: 0.4029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x149552050>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = keras.metrics.Precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0,1,1,1,0,1,0,1],[1,1,0,1,0,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0,1,0,0,1,0,1,1],[1,0,1,1,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasVariable shape=(1,), dtype=float32, path=precision_1/true_positives>,\n",
       " <KerasVariable shape=(1,), dtype=float32, path=precision_1/false_positives>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetrics(keras.metrics.Metric):\n",
    "    def __init__(self,threshold=2.0,**kwargs):\n",
    "        super().__init__(**kwargs) # handles base args(e.g. dtype )\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(name=\"total\",initializer=\"zeros\")\n",
    "        self.count = self.add_weight(name=\"count\",initializer=\"zeros\")\n",
    "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
    "        metric = self.huber_fn(y_true,y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true),tf.float32))\n",
    "    def result(self):\n",
    "        return self.total/self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config,\"threshold\":self.threshold}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = HuberMetrics(2.0)\n",
    "m(tf.constant([[2.0]]),tf.constant([[10.]]))\n",
    "# how done it let's see\n",
    "#total  = 2*|10-2|-2^2/2\n",
    "# count =1\n",
    "# result 14/1=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasVariable shape=(), dtype=float32, path=huber_metrics_2/total>,\n",
       " <KerasVariable shape=(), dtype=float32, path=huber_metrics_2/count>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasVariable shape=(), dtype=float32, path=huber_metrics_2/total>,\n",
       " <KerasVariable shape=(), dtype=float32, path=huber_metrics_2/count>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reset_state()\n",
    "m.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check our HuberMetrics working or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "model = keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30,activation=\"relu\",kernel_initializer=\"he_normal\",input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0),optimizer=\"nadam\",metrics=[HuberMetrics(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - huber_metrics_3: 1.0512 - loss: 1.0512 - val_huber_metrics_3: 0.5086 - val_loss: 0.5086\n",
      "Epoch 2/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - huber_metrics_3: 0.3174 - loss: 0.3174 - val_huber_metrics_3: 0.3527 - val_loss: 0.3527\n",
      "Epoch 3/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - huber_metrics_3: 0.2612 - loss: 0.2612 - val_huber_metrics_3: 0.2689 - val_loss: 0.2689\n",
      "Epoch 4/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - huber_metrics_3: 0.2328 - loss: 0.2328 - val_huber_metrics_3: 0.2207 - val_loss: 0.2207\n",
      "Epoch 5/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - huber_metrics_3: 0.2178 - loss: 0.2178 - val_huber_metrics_3: 0.1899 - val_loss: 0.1899\n",
      "Epoch 6/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - huber_metrics_3: 0.2093 - loss: 0.2093 - val_huber_metrics_3: 0.1996 - val_loss: 0.1996\n",
      "Epoch 7/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - huber_metrics_3: 0.2036 - loss: 0.2036 - val_huber_metrics_3: 0.2243 - val_loss: 0.2243\n",
      "Epoch 8/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - huber_metrics_3: 0.1995 - loss: 0.1995 - val_huber_metrics_3: 0.1774 - val_loss: 0.1774\n",
      "Epoch 9/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - huber_metrics_3: 0.1954 - loss: 0.1954 - val_huber_metrics_3: 0.1850 - val_loss: 0.1850\n",
      "Epoch 10/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - huber_metrics_3: 0.1924 - loss: 0.1924 - val_huber_metrics_3: 0.2058 - val_loss: 0.2058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x306ba0850>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train,epochs=10,validation_data=(X_valid_scaled,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"custom-sequanlial-model-with-custom-metrics.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model(\"./custom-sequanlial-model-with-custom-metrics.keras\",custom_objects={\"huber_fn\":huber_fn,\n",
    "                                                                                                       \"HuberMetrics\":HuberMetrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - huber_metrics_3: 1.6087 - loss: 1.0373 - val_huber_metrics_3: 2.2222 - val_loss: 0.7968\n",
      "Epoch 2/3\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - huber_metrics_3: 2.3350 - loss: 0.8245 - val_huber_metrics_3: 2.2330 - val_loss: 0.7840\n",
      "Epoch 3/3\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - huber_metrics_3: 2.3522 - loss: 0.8146 - val_huber_metrics_3: 2.2478 - val_loss: 0.7787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14957c4d0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train,epochs=3,validation_data=(X_valid_scaled,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make it more reliable to model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetrics(tf.keras.metrics.Mean):\n",
    "    def __init__(self, threshold=2.0,name=\"Hubermetrics\",dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name,dtype=dtype)\n",
    "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
    "        metric= self.huber_fn(y_true,y_pred)\n",
    "        super(HuberMetrics,self).update_state(metric,sample_weight)\n",
    "    def get_config(self):\n",
    "        base_config= super().get_config()\n",
    "        return {**base_config,\"threshold\":self.threshold}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "                          input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.Huber(2.0), optimizer=\"nadam\",\n",
    "              weighted_metrics=[HuberMetrics(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355us/step - Hubermetrics: 1.0599 - loss: 0.5274\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - Hubermetrics: 0.3215 - loss: 0.1598\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2,\n",
    "                    sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3256884217262268, 0.32568849524955656)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(history.history[\"loss\"][0],\n",
    "history.history[\"Hubermetrics\"][0] * sample_weight.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric_v2.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"my_model_with_a_custom_metric_v2.keras\",\n",
    "                                   custom_objects={\"HuberMetrics\": HuberMetrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323us/step - Hubermetrics: 0.2626 - loss: 0.2261\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - Hubermetrics: 0.2298 - loss: 0.1999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14b43af50>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x:tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 2.7182817,  7.389056 , 20.085537 ], dtype=float32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer(tf.constant([1.,2.,3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 6.2862 - val_loss: 5.4560\n",
      "Epoch 2/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 5.7819 - val_loss: 5.4560\n",
      "Epoch 3/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - loss: 5.7819 - val_loss: 5.4560\n",
      "Epoch 4/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - loss: 5.7819 - val_loss: 5.4560\n",
      "Epoch 5/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 5.7819 - val_loss: 5.4560\n",
      "Epoch 6/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - loss: 5.7819 - val_loss: 5.4560\n",
      "Epoch 7/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 5.7823 - val_loss: 5.4560\n",
      "Epoch 8/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - loss: 5.7819 - val_loss: 5.4560\n",
      "Epoch 9/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - loss: 5.7842 - val_loss: 5.4560\n",
      "Epoch 10/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - loss: 5.7819 - val_loss: 5.4560\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218us/step - loss: 5.5903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.579812526702881"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## adding the exponential layer on model \n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30,activation=\"relu\",kernel_initializer=\"he_normal\",input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "model.compile(optimizer=\"sgd\",loss=\"mse\")\n",
    "model.fit(X_train_scaled,y_train,epochs=10,validation_data=(X_valid_scaled,y_valid))\n",
    "model.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self,units,activation=None,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units= units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "    def build(self,batch_input_shape):# Create the layer's variable by calling add_weight()\n",
    "        self.kernel=self.add_weight(\n",
    "            name='kernal',shape=[batch_input_shape[-1],self.units],\n",
    "            initializer = 'he_normal')\n",
    "        self.bias = self.add_weight(\n",
    "            name='bias',shape=[self.units],initializer = 'zeros')\n",
    "        super().build(batch_input_shape)\n",
    "        \n",
    "    def call(self,X): # Perform the desired operations . In this case ,we compute the metrix mutiplication of the inputs X and the layer's kernel \n",
    "        return self.activation(X @ self.kernel+self.bias)\n",
    "    \n",
    "    def get_config(self): \n",
    "        base_config=super().get_config()\n",
    "        return {**base_config,\"units\":self.units,\n",
    "                \"activation\":keras.activation.serializer(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7z/kfcjh8xj1wbc9dktydd14w540000gn/T/ipykernel_1591/4222156707.py:3: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - loss: 5.7265 - val_loss: 6.9255\n",
      "Epoch 2/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 0.9550 - val_loss: 2.6011\n",
      "Epoch 3/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 0.7034 - val_loss: 0.8613\n",
      "Epoch 4/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 0.5803 - val_loss: 0.4588\n",
      "Epoch 5/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 0.5049 - val_loss: 0.4805\n",
      "Epoch 6/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 0.4642 - val_loss: 0.4709\n",
      "Epoch 7/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.4396 - val_loss: 0.4394\n",
      "Epoch 8/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 0.4249 - val_loss: 0.3929\n",
      "Epoch 9/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - loss: 0.4142 - val_loss: 0.4076\n",
      "Epoch 10/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - loss: 0.4059 - val_loss: 0.3804\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207us/step - loss: 0.3991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3931061625480652"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create the model with custom model \n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    MyDense(30,activation=\"relu\",input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "    \n",
    "])\n",
    "model.compile(optimizer=\"nadam\",loss=\"mse\")\n",
    "model.fit(X_train_scaled,y_train,validation_data=(X_valid_scaled,y_valid),epochs=10)\n",
    "model.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self,X):\n",
    "        X1,X2=X\n",
    "        print(\"X1.shape: \", X1.shape ,\" X2.shape: \", X2.shape)\n",
    "        return [X1+X2,X1*X2,X1/X2]\n",
    "    \n",
    "    def compute_output_shape(self,batch_input_shape):\n",
    "        b1,b2 = batch_input_shape\n",
    "        return [b1,b1,b1] # should probably handle broadcasting rules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_68>,\n",
       " <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_69>,\n",
       " <KerasTensor shape=(None, 2), dtype=float32, sparse=False, name=keras_tensor_70>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the multilayer \n",
    "input1= tf.keras.Input(shape=[2])\n",
    "input2= tf.keras.Input(shape=[2])\n",
    "MyMultiLayer()((input1,input2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (2, 2)  X2.shape:  (2, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 9., 18.],\n",
       "        [ 6., 10.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[18., 72.],\n",
       "        [ 8., 21.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[0.5      , 0.5      ],\n",
       "        [0.5      , 2.3333333]], dtype=float32)>]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – tests MyMultiLayer with actual data \n",
    "X1, X2 = np.array([[3., 6.], [2., 7.]]), np.array([[6., 12.], [4., 3.]]) \n",
    "MyMultiLayer()((X1, X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the layer with different behaviour during training and during testing \n",
    "class MyGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__( **kwargs)\n",
    "        self.stddev= stddev\n",
    "    \n",
    "    def call(self,X,training=None):\n",
    "        if training:\n",
    "            noise=tf.random.normal(tf.shape(X),stddev=self.stddev)\n",
    "            return X+noise\n",
    "        else:\n",
    "            return X\n",
    "    \n",
    "    def compute_output_shape(self,batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7z/kfcjh8xj1wbc9dktydd14w540000gn/T/ipykernel_1591/2361834058.py:4: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__( **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - loss: 2.7619 - val_loss: 25.1369\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 1.3951 - val_loss: 14.9793\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234us/step - loss: 1.1206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1244221925735474"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    MyGaussianNoise(stddev=1.0, input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residualblock layer \n",
    "class Residualblock(keras.layers.Layer):\n",
    "    def __init__(self,n_layers , n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [tf.keras.layers.Dense(n_neurons,activation=\"elu\",kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(n_layers)]\n",
    "    def call(self,inputs):\n",
    "        Z=inputs\n",
    "        for layer in self.hidden:\n",
    "            Z=layer(Z)\n",
    "        return inputs+Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self,output_dim,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden1 = keras.layers.Dense(30,activation=\"elu\",kernel_initializer=\"he_normal\")\n",
    "        self.block1 = Residualblock(2,30)\n",
    "        self.block2 = Residualblock(2,30)\n",
    "        self.out=keras.layers.Dense(output_dim)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1+3):\n",
    "            Z= self.block1(Z)\n",
    "        return self.out(Z)\n",
    "    \n",
    "    def get_config(self): # for: that able to load and save model\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config,\"output_dim\":self.output_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Data_pytorcch/lib/python3.11/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'residual_regressor', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522us/step - loss: 93.5322 \n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 2.2380\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - loss: 1.4496\n"
     ]
    }
   ],
   "source": [
    "# extra code – shows that the model can be used normally\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "model.save(\"my_custom_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527us/step - loss: 1.2329\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - loss: 0.9327\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.1215348],\n",
       "       [2.0058653],\n",
       "       [3.7029212]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – the model can be loaded and you can continue training or use it\n",
    "#              to make predictions\n",
    "model = tf.keras.models.load_model(\n",
    "    \"my_custom_model.keras\",\n",
    "    custom_objects={\"ResidualRegressor\": ResidualRegressor}\n",
    ")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "model.predict(X_test_scaled[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have defined the model using the sequential API instead:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "block1 = Residualblock(2, 30)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    block1, block1, block1, block1,\n",
    "    Residualblock(2, 30),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Losses and Metrics Based on Model Internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegresser(tf.keras.Model):\n",
    "    def __init__(self,output_dim,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden=[keras.layers.Dense(30,activation=\"relu\",\n",
    "                                        kernel_initializer=\"he_normal\")\n",
    "                     for _ in range(5)]\n",
    "        self.out =tf.keras.layers.Dense(output_dim)\n",
    "        \n",
    "    def build(self,batch_input_shape):\n",
    "        n_inputs=batch_input_shape[-1]\n",
    "        self.reconstruct =tf.keras.layers.Dense(n_inputs)\n",
    "    \n",
    "    def call(self,inputs,training=None):\n",
    "        Z= inputs \n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        recontruction=self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(recontruction-inputs))\n",
    "        self.add_loss(0.05*recon_loss)\n",
    "        return self.out(Z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - loss: 1.1051\n",
      "Epoch 2/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - loss: 0.5082\n",
      "Epoch 3/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.4392\n",
      "Epoch 4/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 0.3985\n",
      "Epoch 5/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 0.3805\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step\n"
     ]
    }
   ],
   "source": [
    "# extra code\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = ReconstructingRegresser(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Gradients Using AutoDiff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1,w2):\n",
    "    return 3 *w1**2+2*w1*w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(3,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1,w2 = 5,3\n",
    "eps = 1e-6\n",
    "(f(w1+eps,w2)-f(w1,w2))/eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1,w2+eps)-f(w1,w2))/eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using autodiff\n",
    "w1,w2= tf.Variable(5.),tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1,w2)\n",
    "gradients = tape.gradient(z,[w1,w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z= f(w1,w2)\n",
    "dz_dw1=tape.gradient(z,w1)\n",
    "dz_dw2=tape.gradient(z,w2)\n",
    "del tape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1,dz_dw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z=f(c1,c2)\n",
    "gradients = tape.gradient(z,[c1,c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z= f(w1,w2)\n",
    "    jacobians= jacobian_tape.gradient(z,[w1,w2])\n",
    "hessians = [hessian_tape.gradient(jacobians,[w1,w2])\n",
    "            for jacobian in jacobians]\n",
    "del hessian_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=8.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>]]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1,w2):\n",
    "    return 3*w1**2+tf.stop_gradient(2*w1*w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1,w2)\n",
    "gradients = tape.gradient(z,[w1,w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable([100.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = tf.sqrt(x)\n",
    "gradients = tape.gradient(z,[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.05], dtype=float32)>]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([1.0e30])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softpluz(x)\n",
    "    \n",
    "tape.gradient(z,[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(1 + tf.exp(-tf.abs(z))) + tf.maximum(0., z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the proof that this equation is equal to log(1 + exp(z)):\n",
    "\n",
    "softplus(z) = log(1 + exp(z))\n",
    "\n",
    "softplus(z) = log(1 + exp(z)) - log(exp(z)) + log(exp(z)) ; just adding and subtracting the same value\n",
    "\n",
    "softplus(z) = log[(1 + exp(z)) / exp(z)] + log(exp(z)) ; since log(a) - log(b) = log(a / b)\n",
    "\n",
    "softplus(z) = log[(1 + exp(z)) / exp(z)] + z ; since log(exp(z)) = z\n",
    "\n",
    "softplus(z) = log[1 / exp(z) + exp(z) / exp(z)] + z ; since (1 + a) / b = 1 / b + a / b\n",
    "\n",
    "softplus(z) = log[exp(–z) + 1] + z ; since 1 / exp(z) = exp(–z), and exp(z) / exp(z) = 1\n",
    "\n",
    "softplus(z) = softplus(–z) + z ; we recognize the definition at the top, but with –z\n",
    "\n",
    "softplus(z) = softplus(–|z|) + max(0, z) ; if you consider both cases, z < 0 or z ≥ 0, you will see that this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def my_better_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "    def my_softplus_gradient(grad):\n",
    "        return grad/(1+1/exp)\n",
    "    return tf.math.log(exp+1),my_softplus_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – shows that the function is now stable, as well as its gradients\n",
    "x = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation='relu',kernel_initializer=\"he_normal\",kernel_regularizer=l2_reg),\n",
    "    keras.layers.Dense(1,kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X,y, batch_size=32):\n",
    "    idx = np.random.randint(len(X),size=batch_size)\n",
    "    return X[idx] , y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration,total,loss,metrics = None):\n",
    "    metrics = \" - \".join([\"{}:{:.4f}\".format(m.name,m.result())\n",
    "                          for m in [loss]+(metrics or [])])\n",
    "    end = \" \" if iteration<total<total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration,total)+metrics,end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs =5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train)//batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There’s a lot going on in this code, so let’s walk through it:\n",
    "• We create two nested loops: one for the epochs, the other for the batches within\n",
    "an epoch.\n",
    "\n",
    "• Then we sample a random batch from the training set.\n",
    "\n",
    "• Inside the tf.GradientTape() block, we make a prediction for one batch (using\n",
    "the model as a function), and we compute the loss: it is equal to the main loss\n",
    "plus the other losses (in this model, there is one regularization loss per layer).\n",
    "\n",
    "Since the mean_squared_error() function returns one loss per instance, we\n",
    "compute the mean over the batch using tf.reduce_mean() (if you wanted to\n",
    "apply different weights to each instance, this is where you would do it). The regu‐\n",
    "larization losses are already reduced to a single scalar each, so we just need to\n",
    "sum them (using tf.add_n(), which sums multiple tensors of the same shape\n",
    "and data type).\n",
    "\n",
    "• Next, we ask the tape to compute the gradient of the loss with regards to each\n",
    "trainable variable (not all variables!), and we apply them to the optimizer to per‐\n",
    "form a Gradient Descent step.\n",
    "\n",
    "• Next we update the mean loss and the metrics (over the current epoch), and we\n",
    "display the status bar.\n",
    "\n",
    "• At the end of each epoch, we display the status bar again to make it look com‐\n",
    "plete11 and to print a line feed, and we reset the states of the mean loss and the\n",
    "metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1/5\n",
      "32/11610 - mean:9.8421 - mean_absolute_error:1.8926\n",
      "64/11610 - mean:8.9422 - mean_absolute_error:1.8288\n",
      "96/11610 - mean:8.6537 - mean_absolute_error:1.7784\n",
      "128/11610 - mean:8.4475 - mean_absolute_error:1.7439\n",
      "160/11610 - mean:7.9601 - mean_absolute_error:1.6643\n",
      "192/11610 - mean:7.5523 - mean_absolute_error:1.5714\n",
      "224/11610 - mean:7.5341 - mean_absolute_error:1.5677\n",
      "256/11610 - mean:7.3369 - mean_absolute_error:1.5274\n",
      "288/11610 - mean:7.1592 - mean_absolute_error:1.4853\n",
      "320/11610 - mean:7.0650 - mean_absolute_error:1.4684\n",
      "352/11610 - mean:6.8702 - mean_absolute_error:1.4234\n",
      "384/11610 - mean:6.6834 - mean_absolute_error:1.3767\n",
      "416/11610 - mean:6.5661 - mean_absolute_error:1.3502\n",
      "448/11610 - mean:6.4240 - mean_absolute_error:1.3234\n",
      "480/11610 - mean:6.3097 - mean_absolute_error:1.2977\n",
      "512/11610 - mean:6.1904 - mean_absolute_error:1.2737\n",
      "544/11610 - mean:6.0755 - mean_absolute_error:1.2513\n",
      "576/11610 - mean:5.9891 - mean_absolute_error:1.2390\n",
      "608/11610 - mean:5.8657 - mean_absolute_error:1.2119\n",
      "640/11610 - mean:5.7651 - mean_absolute_error:1.1860\n",
      "672/11610 - mean:5.6622 - mean_absolute_error:1.1620\n",
      "704/11610 - mean:5.5668 - mean_absolute_error:1.1439\n",
      "736/11610 - mean:5.4859 - mean_absolute_error:1.1282\n",
      "768/11610 - mean:5.3883 - mean_absolute_error:1.1047\n",
      "800/11610 - mean:5.3113 - mean_absolute_error:1.0851\n",
      "832/11610 - mean:5.2420 - mean_absolute_error:1.0709\n",
      "864/11610 - mean:5.1654 - mean_absolute_error:1.0516\n",
      "896/11610 - mean:5.0971 - mean_absolute_error:1.0360\n",
      "928/11610 - mean:5.0350 - mean_absolute_error:1.0230\n",
      "960/11610 - mean:4.9774 - mean_absolute_error:1.0115\n",
      "992/11610 - mean:4.9181 - mean_absolute_error:0.9989\n",
      "1024/11610 - mean:4.8571 - mean_absolute_error:0.9852\n",
      "1056/11610 - mean:4.7985 - mean_absolute_error:0.9733\n",
      "1088/11610 - mean:4.7438 - mean_absolute_error:0.9633\n",
      "1120/11610 - mean:4.6903 - mean_absolute_error:0.9526\n",
      "1152/11610 - mean:4.6401 - mean_absolute_error:0.9422\n",
      "1184/11610 - mean:4.6018 - mean_absolute_error:0.9373\n",
      "1216/11610 - mean:4.5630 - mean_absolute_error:0.9320\n",
      "1248/11610 - mean:4.5114 - mean_absolute_error:0.9208\n",
      "1280/11610 - mean:4.4677 - mean_absolute_error:0.9114\n",
      "1312/11610 - mean:4.4239 - mean_absolute_error:0.9030\n",
      "1344/11610 - mean:4.4090 - mean_absolute_error:0.8990\n",
      "1376/11610 - mean:4.3739 - mean_absolute_error:0.8948\n",
      "1408/11610 - mean:4.3250 - mean_absolute_error:0.8839\n",
      "1440/11610 - mean:4.2804 - mean_absolute_error:0.8756\n",
      "1472/11610 - mean:4.2515 - mean_absolute_error:0.8730\n",
      "1504/11610 - mean:4.2147 - mean_absolute_error:0.8678\n",
      "1536/11610 - mean:4.1777 - mean_absolute_error:0.8612\n",
      "1568/11610 - mean:4.1441 - mean_absolute_error:0.8540\n",
      "1600/11610 - mean:4.1133 - mean_absolute_error:0.8509\n",
      "1632/11610 - mean:4.0780 - mean_absolute_error:0.8445\n",
      "1664/11610 - mean:4.0388 - mean_absolute_error:0.8370\n",
      "1696/11610 - mean:4.0081 - mean_absolute_error:0.8323\n",
      "1728/11610 - mean:3.9682 - mean_absolute_error:0.8241\n",
      "1760/11610 - mean:3.9385 - mean_absolute_error:0.8197\n",
      "1792/11610 - mean:3.9074 - mean_absolute_error:0.8161\n",
      "1824/11610 - mean:3.8749 - mean_absolute_error:0.8102\n",
      "1856/11610 - mean:3.8426 - mean_absolute_error:0.8055\n",
      "1888/11610 - mean:3.8082 - mean_absolute_error:0.7993\n",
      "1920/11610 - mean:3.7821 - mean_absolute_error:0.7959\n",
      "1952/11610 - mean:3.7501 - mean_absolute_error:0.7897\n",
      "1984/11610 - mean:3.7213 - mean_absolute_error:0.7864\n",
      "2016/11610 - mean:3.7014 - mean_absolute_error:0.7852\n",
      "2048/11610 - mean:3.6718 - mean_absolute_error:0.7808\n",
      "2080/11610 - mean:3.6458 - mean_absolute_error:0.7772\n",
      "2112/11610 - mean:3.6175 - mean_absolute_error:0.7728\n",
      "2144/11610 - mean:3.5945 - mean_absolute_error:0.7707\n",
      "2176/11610 - mean:3.5721 - mean_absolute_error:0.7684\n",
      "2208/11610 - mean:3.5510 - mean_absolute_error:0.7668\n",
      "2240/11610 - mean:3.5226 - mean_absolute_error:0.7622\n",
      "2272/11610 - mean:3.4999 - mean_absolute_error:0.7584\n",
      "2304/11610 - mean:3.4763 - mean_absolute_error:0.7553\n",
      "2336/11610 - mean:3.4550 - mean_absolute_error:0.7524\n",
      "2368/11610 - mean:3.4292 - mean_absolute_error:0.7483\n",
      "2400/11610 - mean:3.4020 - mean_absolute_error:0.7433\n",
      "2432/11610 - mean:3.3893 - mean_absolute_error:0.7434\n",
      "2464/11610 - mean:3.3714 - mean_absolute_error:0.7433\n",
      "2496/11610 - mean:3.3503 - mean_absolute_error:0.7409\n",
      "2528/11610 - mean:3.3276 - mean_absolute_error:0.7377\n",
      "2560/11610 - mean:3.3076 - mean_absolute_error:0.7361\n",
      "2592/11610 - mean:3.2858 - mean_absolute_error:0.7338\n",
      "2624/11610 - mean:3.2677 - mean_absolute_error:0.7319\n",
      "2656/11610 - mean:3.2456 - mean_absolute_error:0.7290\n",
      "2688/11610 - mean:3.2244 - mean_absolute_error:0.7260\n",
      "2720/11610 - mean:3.2025 - mean_absolute_error:0.7235\n",
      "2752/11610 - mean:3.1819 - mean_absolute_error:0.7205\n",
      "2784/11610 - mean:3.1625 - mean_absolute_error:0.7181\n",
      "2816/11610 - mean:3.1423 - mean_absolute_error:0.7154\n",
      "2848/11610 - mean:3.1237 - mean_absolute_error:0.7127\n",
      "2880/11610 - mean:3.1028 - mean_absolute_error:0.7096\n",
      "2912/11610 - mean:3.0844 - mean_absolute_error:0.7075\n",
      "2944/11610 - mean:3.0651 - mean_absolute_error:0.7052\n",
      "2976/11610 - mean:3.0483 - mean_absolute_error:0.7043\n",
      "3008/11610 - mean:3.0313 - mean_absolute_error:0.7027\n",
      "3040/11610 - mean:3.0123 - mean_absolute_error:0.6999\n",
      "3072/11610 - mean:2.9934 - mean_absolute_error:0.6978\n",
      "3104/11610 - mean:2.9758 - mean_absolute_error:0.6958\n",
      "3136/11610 - mean:2.9611 - mean_absolute_error:0.6950\n",
      "3168/11610 - mean:2.9427 - mean_absolute_error:0.6920\n",
      "3200/11610 - mean:2.9275 - mean_absolute_error:0.6907\n",
      "3232/11610 - mean:2.9080 - mean_absolute_error:0.6872\n",
      "3264/11610 - mean:2.8911 - mean_absolute_error:0.6847\n",
      "3296/11610 - mean:2.8759 - mean_absolute_error:0.6833\n",
      "3328/11610 - mean:2.8592 - mean_absolute_error:0.6809\n",
      "3360/11610 - mean:2.8408 - mean_absolute_error:0.6778\n",
      "3392/11610 - mean:2.8273 - mean_absolute_error:0.6768\n",
      "3424/11610 - mean:2.8118 - mean_absolute_error:0.6752\n",
      "3456/11610 - mean:2.7955 - mean_absolute_error:0.6729\n",
      "3488/11610 - mean:2.7802 - mean_absolute_error:0.6713\n",
      "3520/11610 - mean:2.7640 - mean_absolute_error:0.6690\n",
      "3552/11610 - mean:2.7526 - mean_absolute_error:0.6684\n",
      "3584/11610 - mean:2.7377 - mean_absolute_error:0.6667\n",
      "3616/11610 - mean:2.7269 - mean_absolute_error:0.6654\n",
      "3648/11610 - mean:2.7109 - mean_absolute_error:0.6631\n",
      "3680/11610 - mean:2.6951 - mean_absolute_error:0.6608\n",
      "3712/11610 - mean:2.6831 - mean_absolute_error:0.6601\n",
      "3744/11610 - mean:2.6682 - mean_absolute_error:0.6580\n",
      "3776/11610 - mean:2.6555 - mean_absolute_error:0.6572\n",
      "3808/11610 - mean:2.6441 - mean_absolute_error:0.6563\n",
      "3840/11610 - mean:2.6306 - mean_absolute_error:0.6544\n",
      "3872/11610 - mean:2.6176 - mean_absolute_error:0.6532\n",
      "3904/11610 - mean:2.6065 - mean_absolute_error:0.6520\n",
      "3936/11610 - mean:2.5948 - mean_absolute_error:0.6510\n",
      "3968/11610 - mean:2.5814 - mean_absolute_error:0.6495\n",
      "4000/11610 - mean:2.5674 - mean_absolute_error:0.6477\n",
      "4032/11610 - mean:2.5558 - mean_absolute_error:0.6465\n",
      "4064/11610 - mean:2.5472 - mean_absolute_error:0.6455\n",
      "4096/11610 - mean:2.5358 - mean_absolute_error:0.6446\n",
      "4128/11610 - mean:2.5248 - mean_absolute_error:0.6437\n",
      "4160/11610 - mean:2.5133 - mean_absolute_error:0.6431\n",
      "4192/11610 - mean:2.5042 - mean_absolute_error:0.6428\n",
      "4224/11610 - mean:2.4931 - mean_absolute_error:0.6422\n",
      "4256/11610 - mean:2.4819 - mean_absolute_error:0.6413\n",
      "4288/11610 - mean:2.4729 - mean_absolute_error:0.6416\n",
      "4320/11610 - mean:2.4646 - mean_absolute_error:0.6414\n",
      "4352/11610 - mean:2.4543 - mean_absolute_error:0.6412\n",
      "4384/11610 - mean:2.4417 - mean_absolute_error:0.6394\n",
      "4416/11610 - mean:2.4311 - mean_absolute_error:0.6390\n",
      "4448/11610 - mean:2.4184 - mean_absolute_error:0.6369\n",
      "4480/11610 - mean:2.4072 - mean_absolute_error:0.6356\n",
      "4512/11610 - mean:2.3961 - mean_absolute_error:0.6341\n",
      "4544/11610 - mean:2.3849 - mean_absolute_error:0.6324\n",
      "4576/11610 - mean:2.3737 - mean_absolute_error:0.6311\n",
      "4608/11610 - mean:2.3651 - mean_absolute_error:0.6305\n",
      "4640/11610 - mean:2.3549 - mean_absolute_error:0.6296\n",
      "4672/11610 - mean:2.3458 - mean_absolute_error:0.6291\n",
      "4704/11610 - mean:2.3372 - mean_absolute_error:0.6286\n",
      "4736/11610 - mean:2.3288 - mean_absolute_error:0.6283\n",
      "4768/11610 - mean:2.3190 - mean_absolute_error:0.6276\n",
      "4800/11610 - mean:2.3102 - mean_absolute_error:0.6274\n",
      "4832/11610 - mean:2.3014 - mean_absolute_error:0.6270\n",
      "4864/11610 - mean:2.2911 - mean_absolute_error:0.6258\n",
      "4896/11610 - mean:2.2811 - mean_absolute_error:0.6246\n",
      "4928/11610 - mean:2.2722 - mean_absolute_error:0.6240\n",
      "4960/11610 - mean:2.2637 - mean_absolute_error:0.6236\n",
      "4992/11610 - mean:2.2557 - mean_absolute_error:0.6232\n",
      "5024/11610 - mean:2.2493 - mean_absolute_error:0.6233\n",
      "5056/11610 - mean:2.2402 - mean_absolute_error:0.6224\n",
      "5088/11610 - mean:2.2324 - mean_absolute_error:0.6222\n",
      "5120/11610 - mean:2.2245 - mean_absolute_error:0.6220\n",
      "5152/11610 - mean:2.2148 - mean_absolute_error:0.6205\n",
      "5184/11610 - mean:2.2049 - mean_absolute_error:0.6189\n",
      "5216/11610 - mean:2.1967 - mean_absolute_error:0.6185\n",
      "5248/11610 - mean:2.1881 - mean_absolute_error:0.6177\n",
      "5280/11610 - mean:2.1789 - mean_absolute_error:0.6164\n",
      "5312/11610 - mean:2.1714 - mean_absolute_error:0.6158\n",
      "5344/11610 - mean:2.1633 - mean_absolute_error:0.6149\n",
      "5376/11610 - mean:2.1542 - mean_absolute_error:0.6136\n",
      "5408/11610 - mean:2.1453 - mean_absolute_error:0.6123\n",
      "5440/11610 - mean:2.1367 - mean_absolute_error:0.6114\n",
      "5472/11610 - mean:2.1308 - mean_absolute_error:0.6116\n",
      "5504/11610 - mean:2.1221 - mean_absolute_error:0.6103\n",
      "5536/11610 - mean:2.1134 - mean_absolute_error:0.6091\n",
      "5568/11610 - mean:2.1057 - mean_absolute_error:0.6084\n",
      "5600/11610 - mean:2.0974 - mean_absolute_error:0.6074\n",
      "5632/11610 - mean:2.0952 - mean_absolute_error:0.6081\n",
      "5664/11610 - mean:2.0874 - mean_absolute_error:0.6072\n",
      "5696/11610 - mean:2.0803 - mean_absolute_error:0.6069\n",
      "5728/11610 - mean:2.0746 - mean_absolute_error:0.6064\n",
      "5760/11610 - mean:2.0668 - mean_absolute_error:0.6055\n",
      "5792/11610 - mean:2.0589 - mean_absolute_error:0.6043\n",
      "5824/11610 - mean:2.0523 - mean_absolute_error:0.6036\n",
      "5856/11610 - mean:2.0446 - mean_absolute_error:0.6028\n",
      "5888/11610 - mean:2.0360 - mean_absolute_error:0.6011\n",
      "5920/11610 - mean:2.0283 - mean_absolute_error:0.6000\n",
      "5952/11610 - mean:2.0207 - mean_absolute_error:0.5989\n",
      "5984/11610 - mean:2.0139 - mean_absolute_error:0.5985\n",
      "6016/11610 - mean:2.0076 - mean_absolute_error:0.5978\n",
      "6048/11610 - mean:1.9996 - mean_absolute_error:0.5964\n",
      "6080/11610 - mean:1.9936 - mean_absolute_error:0.5959\n",
      "6112/11610 - mean:1.9890 - mean_absolute_error:0.5958\n",
      "6144/11610 - mean:1.9825 - mean_absolute_error:0.5951\n",
      "6176/11610 - mean:1.9756 - mean_absolute_error:0.5944\n",
      "6208/11610 - mean:1.9686 - mean_absolute_error:0.5935\n",
      "6240/11610 - mean:1.9631 - mean_absolute_error:0.5934\n",
      "6272/11610 - mean:1.9562 - mean_absolute_error:0.5925\n",
      "6304/11610 - mean:1.9490 - mean_absolute_error:0.5915\n",
      "6336/11610 - mean:1.9430 - mean_absolute_error:0.5910\n",
      "6368/11610 - mean:1.9365 - mean_absolute_error:0.5902\n",
      "6400/11610 - mean:1.9315 - mean_absolute_error:0.5900\n",
      "6432/11610 - mean:1.9252 - mean_absolute_error:0.5893\n",
      "6464/11610 - mean:1.9197 - mean_absolute_error:0.5891\n",
      "6496/11610 - mean:1.9147 - mean_absolute_error:0.5891\n",
      "6528/11610 - mean:1.9086 - mean_absolute_error:0.5884\n",
      "6560/11610 - mean:1.9038 - mean_absolute_error:0.5880\n",
      "6592/11610 - mean:1.8981 - mean_absolute_error:0.5875\n",
      "6624/11610 - mean:1.8923 - mean_absolute_error:0.5870\n",
      "6656/11610 - mean:1.8869 - mean_absolute_error:0.5868\n",
      "6688/11610 - mean:1.8820 - mean_absolute_error:0.5868\n",
      "6720/11610 - mean:1.8764 - mean_absolute_error:0.5862\n",
      "6752/11610 - mean:1.8710 - mean_absolute_error:0.5857\n",
      "6784/11610 - mean:1.8654 - mean_absolute_error:0.5853\n",
      "6816/11610 - mean:1.8596 - mean_absolute_error:0.5847\n",
      "6848/11610 - mean:1.8539 - mean_absolute_error:0.5842\n",
      "6880/11610 - mean:1.8483 - mean_absolute_error:0.5837\n",
      "6912/11610 - mean:1.8430 - mean_absolute_error:0.5831\n",
      "6944/11610 - mean:1.8385 - mean_absolute_error:0.5830\n",
      "6976/11610 - mean:1.8327 - mean_absolute_error:0.5824\n",
      "7008/11610 - mean:1.8272 - mean_absolute_error:0.5819\n",
      "7040/11610 - mean:1.8220 - mean_absolute_error:0.5811\n",
      "7072/11610 - mean:1.8182 - mean_absolute_error:0.5812\n",
      "7104/11610 - mean:1.8143 - mean_absolute_error:0.5811\n",
      "7136/11610 - mean:1.8104 - mean_absolute_error:0.5811\n",
      "7168/11610 - mean:1.8052 - mean_absolute_error:0.5807\n",
      "7200/11610 - mean:1.7998 - mean_absolute_error:0.5799\n",
      "7232/11610 - mean:1.7950 - mean_absolute_error:0.5796\n",
      "7264/11610 - mean:1.7893 - mean_absolute_error:0.5788\n",
      "7296/11610 - mean:1.7847 - mean_absolute_error:0.5788\n",
      "7328/11610 - mean:1.7798 - mean_absolute_error:0.5785\n",
      "7360/11610 - mean:1.7758 - mean_absolute_error:0.5785\n",
      "7392/11610 - mean:1.7715 - mean_absolute_error:0.5786\n",
      "7424/11610 - mean:1.7670 - mean_absolute_error:0.5783\n",
      "7456/11610 - mean:1.7620 - mean_absolute_error:0.5779\n",
      "7488/11610 - mean:1.7576 - mean_absolute_error:0.5777\n",
      "7520/11610 - mean:1.7529 - mean_absolute_error:0.5771\n",
      "7552/11610 - mean:1.7476 - mean_absolute_error:0.5762\n",
      "7584/11610 - mean:1.7438 - mean_absolute_error:0.5758\n",
      "7616/11610 - mean:1.7386 - mean_absolute_error:0.5751\n",
      "7648/11610 - mean:1.7343 - mean_absolute_error:0.5745\n",
      "7680/11610 - mean:1.7302 - mean_absolute_error:0.5743\n",
      "7712/11610 - mean:1.7260 - mean_absolute_error:0.5740\n",
      "7744/11610 - mean:1.7215 - mean_absolute_error:0.5736\n",
      "7776/11610 - mean:1.7175 - mean_absolute_error:0.5734\n",
      "7808/11610 - mean:1.7133 - mean_absolute_error:0.5729\n",
      "7840/11610 - mean:1.7091 - mean_absolute_error:0.5726\n",
      "7872/11610 - mean:1.7049 - mean_absolute_error:0.5720\n",
      "7904/11610 - mean:1.7021 - mean_absolute_error:0.5723\n",
      "7936/11610 - mean:1.6989 - mean_absolute_error:0.5721\n",
      "7968/11610 - mean:1.6952 - mean_absolute_error:0.5721\n",
      "8000/11610 - mean:1.6913 - mean_absolute_error:0.5722\n",
      "8032/11610 - mean:1.6876 - mean_absolute_error:0.5722\n",
      "8064/11610 - mean:1.6825 - mean_absolute_error:0.5712\n",
      "8096/11610 - mean:1.6790 - mean_absolute_error:0.5713\n",
      "8128/11610 - mean:1.6757 - mean_absolute_error:0.5714\n",
      "8160/11610 - mean:1.6719 - mean_absolute_error:0.5712\n",
      "8192/11610 - mean:1.6683 - mean_absolute_error:0.5709\n",
      "8224/11610 - mean:1.6640 - mean_absolute_error:0.5703\n",
      "8256/11610 - mean:1.6601 - mean_absolute_error:0.5701\n",
      "8288/11610 - mean:1.6567 - mean_absolute_error:0.5697\n",
      "8320/11610 - mean:1.6518 - mean_absolute_error:0.5686\n",
      "8352/11610 - mean:1.6488 - mean_absolute_error:0.5682\n",
      "8384/11610 - mean:1.6446 - mean_absolute_error:0.5677\n",
      "8416/11610 - mean:1.6406 - mean_absolute_error:0.5672\n",
      "8448/11610 - mean:1.6369 - mean_absolute_error:0.5670\n",
      "8480/11610 - mean:1.6323 - mean_absolute_error:0.5663\n",
      "8512/11610 - mean:1.6295 - mean_absolute_error:0.5662\n",
      "8544/11610 - mean:1.6263 - mean_absolute_error:0.5661\n",
      "8576/11610 - mean:1.6233 - mean_absolute_error:0.5660\n",
      "8608/11610 - mean:1.6200 - mean_absolute_error:0.5656\n",
      "8640/11610 - mean:1.6160 - mean_absolute_error:0.5653\n",
      "8672/11610 - mean:1.6124 - mean_absolute_error:0.5649\n",
      "8704/11610 - mean:1.6096 - mean_absolute_error:0.5647\n",
      "8736/11610 - mean:1.6056 - mean_absolute_error:0.5644\n",
      "8768/11610 - mean:1.6026 - mean_absolute_error:0.5644\n",
      "8800/11610 - mean:1.6019 - mean_absolute_error:0.5649\n",
      "8832/11610 - mean:1.5981 - mean_absolute_error:0.5645\n",
      "8864/11610 - mean:1.5957 - mean_absolute_error:0.5641\n",
      "8896/11610 - mean:1.5922 - mean_absolute_error:0.5639\n",
      "8928/11610 - mean:1.5893 - mean_absolute_error:0.5640\n",
      "8960/11610 - mean:1.5873 - mean_absolute_error:0.5642\n",
      "8992/11610 - mean:1.5844 - mean_absolute_error:0.5641\n",
      "9024/11610 - mean:1.5810 - mean_absolute_error:0.5638\n",
      "9056/11610 - mean:1.5787 - mean_absolute_error:0.5639\n",
      "9088/11610 - mean:1.5750 - mean_absolute_error:0.5634\n",
      "9120/11610 - mean:1.5736 - mean_absolute_error:0.5637\n",
      "9152/11610 - mean:1.5706 - mean_absolute_error:0.5635\n",
      "9184/11610 - mean:1.5675 - mean_absolute_error:0.5633\n",
      "9216/11610 - mean:1.5644 - mean_absolute_error:0.5631\n",
      "9248/11610 - mean:1.5614 - mean_absolute_error:0.5628\n",
      "9280/11610 - mean:1.5580 - mean_absolute_error:0.5624\n",
      "9312/11610 - mean:1.5539 - mean_absolute_error:0.5616\n",
      "9344/11610 - mean:1.5503 - mean_absolute_error:0.5613\n",
      "9376/11610 - mean:1.5487 - mean_absolute_error:0.5616\n",
      "9408/11610 - mean:1.5447 - mean_absolute_error:0.5609\n",
      "9440/11610 - mean:1.5408 - mean_absolute_error:0.5602\n",
      "9472/11610 - mean:1.5383 - mean_absolute_error:0.5601\n",
      "9504/11610 - mean:1.5353 - mean_absolute_error:0.5598\n",
      "9536/11610 - mean:1.5324 - mean_absolute_error:0.5596\n",
      "9568/11610 - mean:1.5304 - mean_absolute_error:0.5598\n",
      "9600/11610 - mean:1.5269 - mean_absolute_error:0.5594\n",
      "9632/11610 - mean:1.5240 - mean_absolute_error:0.5592\n",
      "9664/11610 - mean:1.5209 - mean_absolute_error:0.5590\n",
      "9696/11610 - mean:1.5199 - mean_absolute_error:0.5593\n",
      "9728/11610 - mean:1.5179 - mean_absolute_error:0.5594\n",
      "9760/11610 - mean:1.5143 - mean_absolute_error:0.5588\n",
      "9792/11610 - mean:1.5111 - mean_absolute_error:0.5586\n",
      "9824/11610 - mean:1.5083 - mean_absolute_error:0.5585\n",
      "9856/11610 - mean:1.5049 - mean_absolute_error:0.5581\n",
      "9888/11610 - mean:1.5015 - mean_absolute_error:0.5575\n",
      "9920/11610 - mean:1.4980 - mean_absolute_error:0.5569\n",
      "9952/11610 - mean:1.4956 - mean_absolute_error:0.5567\n",
      "9984/11610 - mean:1.4925 - mean_absolute_error:0.5565\n",
      "10016/11610 - mean:1.4891 - mean_absolute_error:0.5560\n",
      "10048/11610 - mean:1.4861 - mean_absolute_error:0.5557\n",
      "10080/11610 - mean:1.4830 - mean_absolute_error:0.5554\n",
      "10112/11610 - mean:1.4799 - mean_absolute_error:0.5550\n",
      "10144/11610 - mean:1.4785 - mean_absolute_error:0.5549\n",
      "10176/11610 - mean:1.4767 - mean_absolute_error:0.5550\n",
      "10208/11610 - mean:1.4746 - mean_absolute_error:0.5549\n",
      "10240/11610 - mean:1.4711 - mean_absolute_error:0.5543\n",
      "10272/11610 - mean:1.4690 - mean_absolute_error:0.5545\n",
      "10304/11610 - mean:1.4662 - mean_absolute_error:0.5543\n",
      "10336/11610 - mean:1.4636 - mean_absolute_error:0.5540\n",
      "10368/11610 - mean:1.4614 - mean_absolute_error:0.5540\n",
      "10400/11610 - mean:1.4588 - mean_absolute_error:0.5539\n",
      "10432/11610 - mean:1.4567 - mean_absolute_error:0.5540\n",
      "10464/11610 - mean:1.4547 - mean_absolute_error:0.5541\n",
      "10496/11610 - mean:1.4523 - mean_absolute_error:0.5539\n",
      "10528/11610 - mean:1.4497 - mean_absolute_error:0.5537\n",
      "10560/11610 - mean:1.4466 - mean_absolute_error:0.5533\n",
      "10592/11610 - mean:1.4438 - mean_absolute_error:0.5530\n",
      "10624/11610 - mean:1.4414 - mean_absolute_error:0.5529\n",
      "10656/11610 - mean:1.4384 - mean_absolute_error:0.5523\n",
      "10688/11610 - mean:1.4353 - mean_absolute_error:0.5518\n",
      "10720/11610 - mean:1.4338 - mean_absolute_error:0.5519\n",
      "10752/11610 - mean:1.4314 - mean_absolute_error:0.5517\n",
      "10784/11610 - mean:1.4287 - mean_absolute_error:0.5515\n",
      "10816/11610 - mean:1.4274 - mean_absolute_error:0.5519\n",
      "10848/11610 - mean:1.4249 - mean_absolute_error:0.5516\n",
      "10880/11610 - mean:1.4240 - mean_absolute_error:0.5519\n",
      "10912/11610 - mean:1.4226 - mean_absolute_error:0.5521\n",
      "10944/11610 - mean:1.4203 - mean_absolute_error:0.5519\n",
      "10976/11610 - mean:1.4175 - mean_absolute_error:0.5516\n",
      "11008/11610 - mean:1.4150 - mean_absolute_error:0.5514\n",
      "11040/11610 - mean:1.4124 - mean_absolute_error:0.5511\n",
      "11072/11610 - mean:1.4105 - mean_absolute_error:0.5512\n",
      "11104/11610 - mean:1.4080 - mean_absolute_error:0.5510\n",
      "11136/11610 - mean:1.4066 - mean_absolute_error:0.5510\n",
      "11168/11610 - mean:1.4037 - mean_absolute_error:0.5506\n",
      "11200/11610 - mean:1.4009 - mean_absolute_error:0.5501\n",
      "11232/11610 - mean:1.3988 - mean_absolute_error:0.5502\n",
      "11264/11610 - mean:1.3973 - mean_absolute_error:0.5503\n",
      "11296/11610 - mean:1.3964 - mean_absolute_error:0.5506\n",
      "11328/11610 - mean:1.3946 - mean_absolute_error:0.5508\n",
      "11360/11610 - mean:1.3927 - mean_absolute_error:0.5508\n",
      "11392/11610 - mean:1.3902 - mean_absolute_error:0.5505\n",
      "11424/11610 - mean:1.3885 - mean_absolute_error:0.5506\n",
      "11456/11610 - mean:1.3872 - mean_absolute_error:0.5508\n",
      "11488/11610 - mean:1.3849 - mean_absolute_error:0.5504\n",
      "11520/11610 - mean:1.3826 - mean_absolute_error:0.5502\n",
      "11552/11610 - mean:1.3809 - mean_absolute_error:0.5501\n",
      "11584/11610 - mean:1.3788 - mean_absolute_error:0.5499\n",
      "11610/11610 - mean:1.3788 - mean_absolute_error:0.5499\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Mean' object has no attribute 'reset_states'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[164], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m print_status_bar(\u001b[38;5;28mlen\u001b[39m(y_train),\u001b[38;5;28mlen\u001b[39m(y_train),mean_loss,metrics)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m [mean_loss]\u001b[38;5;241m+\u001b[39mmetrics:\n\u001b[0;32m---> 17\u001b[0m     metric\u001b[38;5;241m.\u001b[39mreset_states()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Mean' object has no attribute 'reset_states'"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,n_epochs+1):\n",
    "    print(\"Epoch{}/{}\".format(epoch,n_epochs))\n",
    "    for step in range(1,n_steps+1):\n",
    "        X_batch,y_batch = random_batch(X_train_scaled,y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch,training = True)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch,y_pred))\n",
    "            loss = tf.add_n([main_loss]+model.losses)\n",
    "        gradients= tape.gradient(loss,model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch,y_pred)\n",
    "        print_status_bar(step*batch_size,len(y_train),mean_loss,metrics)\n",
    "    print_status_bar(len(y_train),len(y_train),mean_loss,metrics)\n",
    "    for metric in [mean_loss]+metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/362 - mean:1.3766 - mean_absolute_error:0.5496\n",
      "2/362 - mean:1.3741 - mean_absolute_error:0.5493\n",
      "3/362 - mean:1.3718 - mean_absolute_error:0.5490\n",
      "4/362 - mean:1.3694 - mean_absolute_error:0.5488\n",
      "5/362 - mean:1.3688 - mean_absolute_error:0.5492\n",
      "6/362 - mean:1.3679 - mean_absolute_error:0.5494\n",
      "7/362 - mean:1.3659 - mean_absolute_error:0.5492\n",
      "8/362 - mean:1.3634 - mean_absolute_error:0.5488\n",
      "9/362 - mean:1.3611 - mean_absolute_error:0.5485\n",
      "10/362 - mean:1.3589 - mean_absolute_error:0.5484\n",
      "11/362 - mean:1.3573 - mean_absolute_error:0.5485\n",
      "12/362 - mean:1.3551 - mean_absolute_error:0.5482\n",
      "13/362 - mean:1.3529 - mean_absolute_error:0.5480\n",
      "14/362 - mean:1.3517 - mean_absolute_error:0.5481\n",
      "15/362 - mean:1.3495 - mean_absolute_error:0.5480\n",
      "16/362 - mean:1.3475 - mean_absolute_error:0.5477\n",
      "17/362 - mean:1.3465 - mean_absolute_error:0.5478\n",
      "18/362 - mean:1.3459 - mean_absolute_error:0.5481\n",
      "19/362 - mean:1.3454 - mean_absolute_error:0.5484\n",
      "20/362 - mean:1.3436 - mean_absolute_error:0.5484\n",
      "21/362 - mean:1.3419 - mean_absolute_error:0.5486\n",
      "22/362 - mean:1.3400 - mean_absolute_error:0.5485\n",
      "23/362 - mean:1.3383 - mean_absolute_error:0.5484\n",
      "24/362 - mean:1.3368 - mean_absolute_error:0.5483\n",
      "25/362 - mean:1.3351 - mean_absolute_error:0.5483\n",
      "26/362 - mean:1.3328 - mean_absolute_error:0.5479\n",
      "27/362 - mean:1.3311 - mean_absolute_error:0.5477\n",
      "28/362 - mean:1.3315 - mean_absolute_error:0.5482\n",
      "29/362 - mean:1.3292 - mean_absolute_error:0.5479\n",
      "30/362 - mean:1.3270 - mean_absolute_error:0.5477\n",
      "31/362 - mean:1.3251 - mean_absolute_error:0.5476\n",
      "32/362 - mean:1.3231 - mean_absolute_error:0.5474\n",
      "33/362 - mean:1.3213 - mean_absolute_error:0.5473\n",
      "34/362 - mean:1.3195 - mean_absolute_error:0.5473\n",
      "35/362 - mean:1.3183 - mean_absolute_error:0.5474\n",
      "36/362 - mean:1.3176 - mean_absolute_error:0.5476\n",
      "37/362 - mean:1.3174 - mean_absolute_error:0.5475\n",
      "38/362 - mean:1.3162 - mean_absolute_error:0.5476\n",
      "39/362 - mean:1.3140 - mean_absolute_error:0.5473\n",
      "40/362 - mean:1.3119 - mean_absolute_error:0.5469\n",
      "41/362 - mean:1.3112 - mean_absolute_error:0.5471\n",
      "42/362 - mean:1.3089 - mean_absolute_error:0.5466\n",
      "43/362 - mean:1.3078 - mean_absolute_error:0.5467\n",
      "44/362 - mean:1.3057 - mean_absolute_error:0.5463\n",
      "45/362 - mean:1.3039 - mean_absolute_error:0.5462\n",
      "46/362 - mean:1.3034 - mean_absolute_error:0.5464\n",
      "47/362 - mean:1.3019 - mean_absolute_error:0.5465\n",
      "48/362 - mean:1.3000 - mean_absolute_error:0.5463\n",
      "49/362 - mean:1.2979 - mean_absolute_error:0.5459\n",
      "50/362 - mean:1.2961 - mean_absolute_error:0.5458\n",
      "51/362 - mean:1.2940 - mean_absolute_error:0.5454\n",
      "52/362 - mean:1.2935 - mean_absolute_error:0.5458\n",
      "53/362 - mean:1.2929 - mean_absolute_error:0.5460\n",
      "54/362 - mean:1.2908 - mean_absolute_error:0.5457\n",
      "55/362 - mean:1.2896 - mean_absolute_error:0.5457\n",
      "56/362 - mean:1.2881 - mean_absolute_error:0.5456\n",
      "57/362 - mean:1.2875 - mean_absolute_error:0.5462\n",
      "58/362 - mean:1.2859 - mean_absolute_error:0.5460\n",
      "59/362 - mean:1.2846 - mean_absolute_error:0.5461\n",
      "60/362 - mean:1.2829 - mean_absolute_error:0.5460\n",
      "61/362 - mean:1.2815 - mean_absolute_error:0.5459\n",
      "62/362 - mean:1.2796 - mean_absolute_error:0.5458\n",
      "63/362 - mean:1.2783 - mean_absolute_error:0.5459\n",
      "64/362 - mean:1.2762 - mean_absolute_error:0.5454\n",
      "65/362 - mean:1.2749 - mean_absolute_error:0.5454\n",
      "66/362 - mean:1.2737 - mean_absolute_error:0.5455\n",
      "67/362 - mean:1.2718 - mean_absolute_error:0.5452\n",
      "68/362 - mean:1.2707 - mean_absolute_error:0.5451\n",
      "69/362 - mean:1.2702 - mean_absolute_error:0.5455\n",
      "70/362 - mean:1.2690 - mean_absolute_error:0.5455\n",
      "71/362 - mean:1.2670 - mean_absolute_error:0.5451\n",
      "72/362 - mean:1.2657 - mean_absolute_error:0.5449\n",
      "73/362 - mean:1.2639 - mean_absolute_error:0.5446\n",
      "74/362 - mean:1.2627 - mean_absolute_error:0.5446\n",
      "75/362 - mean:1.2611 - mean_absolute_error:0.5444\n",
      "76/362 - mean:1.2595 - mean_absolute_error:0.5442\n",
      "77/362 - mean:1.2578 - mean_absolute_error:0.5441\n",
      "78/362 - mean:1.2563 - mean_absolute_error:0.5439\n",
      "79/362 - mean:1.2543 - mean_absolute_error:0.5434\n",
      "80/362 - mean:1.2523 - mean_absolute_error:0.5430\n",
      "81/362 - mean:1.2509 - mean_absolute_error:0.5430\n",
      "82/362 - mean:1.2495 - mean_absolute_error:0.5428\n",
      "83/362 - mean:1.2488 - mean_absolute_error:0.5430\n",
      "84/362 - mean:1.2484 - mean_absolute_error:0.5433\n",
      "85/362 - mean:1.2469 - mean_absolute_error:0.5432\n",
      "86/362 - mean:1.2454 - mean_absolute_error:0.5429\n",
      "87/362 - mean:1.2439 - mean_absolute_error:0.5428\n",
      "88/362 - mean:1.2425 - mean_absolute_error:0.5426\n",
      "89/362 - mean:1.2418 - mean_absolute_error:0.5427\n",
      "90/362 - mean:1.2405 - mean_absolute_error:0.5426\n",
      "91/362 - mean:1.2389 - mean_absolute_error:0.5425\n",
      "92/362 - mean:1.2373 - mean_absolute_error:0.5424\n",
      "93/362 - mean:1.2361 - mean_absolute_error:0.5424\n",
      "94/362 - mean:1.2346 - mean_absolute_error:0.5423\n",
      "95/362 - mean:1.2334 - mean_absolute_error:0.5424\n",
      "96/362 - mean:1.2320 - mean_absolute_error:0.5423\n",
      "97/362 - mean:1.2304 - mean_absolute_error:0.5422\n",
      "98/362 - mean:1.2293 - mean_absolute_error:0.5422\n",
      "99/362 - mean:1.2283 - mean_absolute_error:0.5421\n",
      "100/362 - mean:1.2270 - mean_absolute_error:0.5420\n",
      "101/362 - mean:1.2257 - mean_absolute_error:0.5420\n",
      "102/362 - mean:1.2246 - mean_absolute_error:0.5419\n",
      "103/362 - mean:1.2230 - mean_absolute_error:0.5416\n",
      "104/362 - mean:1.2215 - mean_absolute_error:0.5415\n",
      "105/362 - mean:1.2201 - mean_absolute_error:0.5413\n",
      "106/362 - mean:1.2187 - mean_absolute_error:0.5410\n",
      "107/362 - mean:1.2178 - mean_absolute_error:0.5411\n",
      "108/362 - mean:1.2170 - mean_absolute_error:0.5411\n",
      "109/362 - mean:1.2158 - mean_absolute_error:0.5411\n",
      "110/362 - mean:1.2142 - mean_absolute_error:0.5409\n",
      "111/362 - mean:1.2135 - mean_absolute_error:0.5412\n",
      "112/362 - mean:1.2116 - mean_absolute_error:0.5407\n",
      "113/362 - mean:1.2099 - mean_absolute_error:0.5404\n",
      "114/362 - mean:1.2094 - mean_absolute_error:0.5405\n",
      "115/362 - mean:1.2081 - mean_absolute_error:0.5404\n",
      "116/362 - mean:1.2067 - mean_absolute_error:0.5401\n",
      "117/362 - mean:1.2052 - mean_absolute_error:0.5400\n",
      "118/362 - mean:1.2041 - mean_absolute_error:0.5400\n",
      "119/362 - mean:1.2023 - mean_absolute_error:0.5397\n",
      "120/362 - mean:1.2012 - mean_absolute_error:0.5397\n",
      "121/362 - mean:1.1996 - mean_absolute_error:0.5395\n",
      "122/362 - mean:1.1986 - mean_absolute_error:0.5394\n",
      "123/362 - mean:1.1979 - mean_absolute_error:0.5395\n",
      "124/362 - mean:1.1968 - mean_absolute_error:0.5396\n",
      "125/362 - mean:1.1964 - mean_absolute_error:0.5398\n",
      "126/362 - mean:1.1952 - mean_absolute_error:0.5398\n",
      "127/362 - mean:1.1938 - mean_absolute_error:0.5396\n",
      "128/362 - mean:1.1925 - mean_absolute_error:0.5395\n",
      "129/362 - mean:1.1909 - mean_absolute_error:0.5393\n",
      "130/362 - mean:1.1897 - mean_absolute_error:0.5392\n",
      "131/362 - mean:1.1885 - mean_absolute_error:0.5391\n",
      "132/362 - mean:1.1883 - mean_absolute_error:0.5394\n",
      "133/362 - mean:1.1873 - mean_absolute_error:0.5394\n",
      "134/362 - mean:1.1867 - mean_absolute_error:0.5397\n",
      "135/362 - mean:1.1856 - mean_absolute_error:0.5396\n",
      "136/362 - mean:1.1839 - mean_absolute_error:0.5392\n",
      "137/362 - mean:1.1832 - mean_absolute_error:0.5392\n",
      "138/362 - mean:1.1818 - mean_absolute_error:0.5390\n",
      "139/362 - mean:1.1803 - mean_absolute_error:0.5386\n",
      "140/362 - mean:1.1789 - mean_absolute_error:0.5385\n",
      "141/362 - mean:1.1785 - mean_absolute_error:0.5386\n",
      "142/362 - mean:1.1770 - mean_absolute_error:0.5384\n",
      "143/362 - mean:1.1761 - mean_absolute_error:0.5383\n",
      "144/362 - mean:1.1745 - mean_absolute_error:0.5379\n",
      "145/362 - mean:1.1736 - mean_absolute_error:0.5378\n",
      "146/362 - mean:1.1726 - mean_absolute_error:0.5378\n",
      "147/362 - mean:1.1712 - mean_absolute_error:0.5376\n",
      "148/362 - mean:1.1704 - mean_absolute_error:0.5375\n",
      "149/362 - mean:1.1690 - mean_absolute_error:0.5373\n",
      "150/362 - mean:1.1680 - mean_absolute_error:0.5374\n",
      "151/362 - mean:1.1667 - mean_absolute_error:0.5371\n",
      "152/362 - mean:1.1653 - mean_absolute_error:0.5370\n",
      "153/362 - mean:1.1639 - mean_absolute_error:0.5367\n",
      "154/362 - mean:1.1628 - mean_absolute_error:0.5366\n",
      "155/362 - mean:1.1616 - mean_absolute_error:0.5365\n",
      "156/362 - mean:1.1612 - mean_absolute_error:0.5366\n",
      "157/362 - mean:1.1598 - mean_absolute_error:0.5364\n",
      "158/362 - mean:1.1588 - mean_absolute_error:0.5364\n",
      "159/362 - mean:1.1575 - mean_absolute_error:0.5362\n",
      "160/362 - mean:1.1566 - mean_absolute_error:0.5361\n",
      "161/362 - mean:1.1551 - mean_absolute_error:0.5358\n",
      "162/362 - mean:1.1542 - mean_absolute_error:0.5359\n",
      "163/362 - mean:1.1530 - mean_absolute_error:0.5358\n",
      "164/362 - mean:1.1521 - mean_absolute_error:0.5357\n",
      "165/362 - mean:1.1516 - mean_absolute_error:0.5357\n",
      "166/362 - mean:1.1504 - mean_absolute_error:0.5355\n",
      "167/362 - mean:1.1488 - mean_absolute_error:0.5351\n",
      "168/362 - mean:1.1479 - mean_absolute_error:0.5350\n",
      "169/362 - mean:1.1466 - mean_absolute_error:0.5349\n",
      "170/362 - mean:1.1454 - mean_absolute_error:0.5347\n",
      "171/362 - mean:1.1443 - mean_absolute_error:0.5346\n",
      "172/362 - mean:1.1431 - mean_absolute_error:0.5343\n",
      "173/362 - mean:1.1419 - mean_absolute_error:0.5341\n",
      "174/362 - mean:1.1416 - mean_absolute_error:0.5343\n",
      "175/362 - mean:1.1406 - mean_absolute_error:0.5343\n",
      "176/362 - mean:1.1397 - mean_absolute_error:0.5343\n",
      "177/362 - mean:1.1385 - mean_absolute_error:0.5342\n",
      "178/362 - mean:1.1377 - mean_absolute_error:0.5342\n",
      "179/362 - mean:1.1366 - mean_absolute_error:0.5342\n",
      "180/362 - mean:1.1357 - mean_absolute_error:0.5343\n",
      "181/362 - mean:1.1346 - mean_absolute_error:0.5341\n",
      "182/362 - mean:1.1338 - mean_absolute_error:0.5342\n",
      "183/362 - mean:1.1324 - mean_absolute_error:0.5339\n",
      "184/362 - mean:1.1315 - mean_absolute_error:0.5339\n",
      "185/362 - mean:1.1303 - mean_absolute_error:0.5338\n",
      "186/362 - mean:1.1294 - mean_absolute_error:0.5337\n",
      "187/362 - mean:1.1287 - mean_absolute_error:0.5338\n",
      "188/362 - mean:1.1275 - mean_absolute_error:0.5336\n",
      "189/362 - mean:1.1264 - mean_absolute_error:0.5336\n",
      "190/362 - mean:1.1262 - mean_absolute_error:0.5337\n",
      "191/362 - mean:1.1251 - mean_absolute_error:0.5336\n",
      "192/362 - mean:1.1242 - mean_absolute_error:0.5337\n",
      "193/362 - mean:1.1232 - mean_absolute_error:0.5334\n",
      "194/362 - mean:1.1234 - mean_absolute_error:0.5336\n",
      "195/362 - mean:1.1221 - mean_absolute_error:0.5334\n",
      "196/362 - mean:1.1232 - mean_absolute_error:0.5337\n",
      "197/362 - mean:1.1220 - mean_absolute_error:0.5335\n",
      "198/362 - mean:1.1222 - mean_absolute_error:0.5339\n",
      "199/362 - mean:1.1211 - mean_absolute_error:0.5338\n",
      "200/362 - mean:1.1199 - mean_absolute_error:0.5337\n",
      "201/362 - mean:1.1193 - mean_absolute_error:0.5336\n",
      "202/362 - mean:1.1183 - mean_absolute_error:0.5335\n",
      "203/362 - mean:1.1176 - mean_absolute_error:0.5335\n",
      "204/362 - mean:1.1173 - mean_absolute_error:0.5337\n",
      "205/362 - mean:1.1168 - mean_absolute_error:0.5337\n",
      "206/362 - mean:1.1162 - mean_absolute_error:0.5338\n",
      "207/362 - mean:1.1150 - mean_absolute_error:0.5335\n",
      "208/362 - mean:1.1142 - mean_absolute_error:0.5335\n",
      "209/362 - mean:1.1134 - mean_absolute_error:0.5336\n",
      "210/362 - mean:1.1124 - mean_absolute_error:0.5335\n",
      "211/362 - mean:1.1117 - mean_absolute_error:0.5337\n",
      "212/362 - mean:1.1109 - mean_absolute_error:0.5336\n",
      "213/362 - mean:1.1103 - mean_absolute_error:0.5336\n",
      "214/362 - mean:1.1094 - mean_absolute_error:0.5336\n",
      "215/362 - mean:1.1087 - mean_absolute_error:0.5336\n",
      "216/362 - mean:1.1081 - mean_absolute_error:0.5336\n",
      "217/362 - mean:1.1071 - mean_absolute_error:0.5336\n",
      "218/362 - mean:1.1059 - mean_absolute_error:0.5334\n",
      "219/362 - mean:1.1050 - mean_absolute_error:0.5334\n",
      "220/362 - mean:1.1037 - mean_absolute_error:0.5331\n",
      "221/362 - mean:1.1030 - mean_absolute_error:0.5331\n",
      "222/362 - mean:1.1020 - mean_absolute_error:0.5330\n",
      "223/362 - mean:1.1008 - mean_absolute_error:0.5328\n",
      "224/362 - mean:1.1003 - mean_absolute_error:0.5330\n",
      "225/362 - mean:1.0993 - mean_absolute_error:0.5329\n",
      "226/362 - mean:1.0985 - mean_absolute_error:0.5328\n",
      "227/362 - mean:1.0973 - mean_absolute_error:0.5325\n",
      "228/362 - mean:1.0962 - mean_absolute_error:0.5323\n",
      "229/362 - mean:1.0965 - mean_absolute_error:0.5326\n",
      "230/362 - mean:1.0961 - mean_absolute_error:0.5327\n",
      "231/362 - mean:1.0963 - mean_absolute_error:0.5329\n",
      "232/362 - mean:1.0951 - mean_absolute_error:0.5327\n",
      "233/362 - mean:1.0946 - mean_absolute_error:0.5328\n",
      "234/362 - mean:1.0935 - mean_absolute_error:0.5325\n",
      "235/362 - mean:1.0926 - mean_absolute_error:0.5324\n",
      "236/362 - mean:1.0924 - mean_absolute_error:0.5325\n",
      "237/362 - mean:1.0915 - mean_absolute_error:0.5326\n",
      "238/362 - mean:1.0908 - mean_absolute_error:0.5326\n",
      "239/362 - mean:1.0899 - mean_absolute_error:0.5325\n",
      "240/362 - mean:1.0892 - mean_absolute_error:0.5325\n",
      "241/362 - mean:1.0887 - mean_absolute_error:0.5326\n",
      "242/362 - mean:1.0880 - mean_absolute_error:0.5326\n",
      "243/362 - mean:1.0874 - mean_absolute_error:0.5327\n",
      "244/362 - mean:1.0861 - mean_absolute_error:0.5324\n",
      "245/362 - mean:1.0855 - mean_absolute_error:0.5324\n",
      "246/362 - mean:1.0846 - mean_absolute_error:0.5323\n",
      "247/362 - mean:1.0837 - mean_absolute_error:0.5322\n",
      "248/362 - mean:1.0829 - mean_absolute_error:0.5322\n",
      "249/362 - mean:1.0830 - mean_absolute_error:0.5325\n",
      "250/362 - mean:1.0821 - mean_absolute_error:0.5325\n",
      "251/362 - mean:1.0819 - mean_absolute_error:0.5327\n",
      "252/362 - mean:1.0810 - mean_absolute_error:0.5325\n",
      "253/362 - mean:1.0806 - mean_absolute_error:0.5326\n",
      "254/362 - mean:1.0796 - mean_absolute_error:0.5325\n",
      "255/362 - mean:1.0788 - mean_absolute_error:0.5325\n",
      "256/362 - mean:1.0779 - mean_absolute_error:0.5323\n",
      "257/362 - mean:1.0771 - mean_absolute_error:0.5323\n",
      "258/362 - mean:1.0767 - mean_absolute_error:0.5324\n",
      "259/362 - mean:1.0764 - mean_absolute_error:0.5325\n",
      "260/362 - mean:1.0756 - mean_absolute_error:0.5325\n",
      "261/362 - mean:1.0754 - mean_absolute_error:0.5327\n",
      "262/362 - mean:1.0746 - mean_absolute_error:0.5326\n",
      "263/362 - mean:1.0735 - mean_absolute_error:0.5324\n",
      "264/362 - mean:1.0729 - mean_absolute_error:0.5323\n",
      "265/362 - mean:1.0726 - mean_absolute_error:0.5326\n",
      "266/362 - mean:1.0727 - mean_absolute_error:0.5328\n",
      "267/362 - mean:1.0717 - mean_absolute_error:0.5327\n",
      "268/362 - mean:1.0710 - mean_absolute_error:0.5327\n",
      "269/362 - mean:1.0706 - mean_absolute_error:0.5328\n",
      "270/362 - mean:1.0703 - mean_absolute_error:0.5330\n",
      "271/362 - mean:1.0699 - mean_absolute_error:0.5330\n",
      "272/362 - mean:1.0693 - mean_absolute_error:0.5330\n",
      "273/362 - mean:1.0688 - mean_absolute_error:0.5330\n",
      "274/362 - mean:1.0681 - mean_absolute_error:0.5329\n",
      "275/362 - mean:1.0675 - mean_absolute_error:0.5330\n",
      "276/362 - mean:1.0666 - mean_absolute_error:0.5329\n",
      "277/362 - mean:1.0655 - mean_absolute_error:0.5327\n",
      "278/362 - mean:1.0648 - mean_absolute_error:0.5328\n",
      "279/362 - mean:1.0641 - mean_absolute_error:0.5327\n",
      "280/362 - mean:1.0641 - mean_absolute_error:0.5330\n",
      "281/362 - mean:1.0631 - mean_absolute_error:0.5327\n",
      "282/362 - mean:1.0620 - mean_absolute_error:0.5325\n",
      "283/362 - mean:1.0616 - mean_absolute_error:0.5326\n",
      "284/362 - mean:1.0616 - mean_absolute_error:0.5327\n",
      "285/362 - mean:1.0608 - mean_absolute_error:0.5327\n",
      "286/362 - mean:1.0600 - mean_absolute_error:0.5326\n",
      "287/362 - mean:1.0593 - mean_absolute_error:0.5326\n",
      "288/362 - mean:1.0586 - mean_absolute_error:0.5326\n",
      "289/362 - mean:1.0577 - mean_absolute_error:0.5325\n",
      "290/362 - mean:1.0570 - mean_absolute_error:0.5324\n",
      "291/362 - mean:1.0565 - mean_absolute_error:0.5325\n",
      "292/362 - mean:1.0567 - mean_absolute_error:0.5327\n",
      "293/362 - mean:1.0564 - mean_absolute_error:0.5327\n",
      "294/362 - mean:1.0559 - mean_absolute_error:0.5328\n",
      "295/362 - mean:1.0553 - mean_absolute_error:0.5328\n",
      "296/362 - mean:1.0543 - mean_absolute_error:0.5326\n",
      "297/362 - mean:1.0535 - mean_absolute_error:0.5326\n",
      "298/362 - mean:1.0531 - mean_absolute_error:0.5326\n",
      "299/362 - mean:1.0519 - mean_absolute_error:0.5322\n",
      "300/362 - mean:1.0516 - mean_absolute_error:0.5322\n",
      "301/362 - mean:1.0510 - mean_absolute_error:0.5321\n",
      "302/362 - mean:1.0509 - mean_absolute_error:0.5325\n",
      "303/362 - mean:1.0501 - mean_absolute_error:0.5324\n",
      "304/362 - mean:1.0494 - mean_absolute_error:0.5324\n",
      "305/362 - mean:1.0492 - mean_absolute_error:0.5325\n",
      "306/362 - mean:1.0488 - mean_absolute_error:0.5325\n",
      "307/362 - mean:1.0487 - mean_absolute_error:0.5327\n",
      "308/362 - mean:1.0479 - mean_absolute_error:0.5327\n",
      "309/362 - mean:1.0471 - mean_absolute_error:0.5326\n",
      "310/362 - mean:1.0466 - mean_absolute_error:0.5327\n",
      "311/362 - mean:1.0459 - mean_absolute_error:0.5326\n",
      "312/362 - mean:1.0456 - mean_absolute_error:0.5327\n",
      "313/362 - mean:1.0450 - mean_absolute_error:0.5327\n",
      "314/362 - mean:1.0445 - mean_absolute_error:0.5327\n",
      "315/362 - mean:1.0437 - mean_absolute_error:0.5326\n",
      "316/362 - mean:1.0434 - mean_absolute_error:0.5327\n",
      "317/362 - mean:1.0424 - mean_absolute_error:0.5324\n",
      "318/362 - mean:1.0419 - mean_absolute_error:0.5324\n",
      "319/362 - mean:1.0415 - mean_absolute_error:0.5326\n",
      "320/362 - mean:1.0406 - mean_absolute_error:0.5324\n",
      "321/362 - mean:1.0399 - mean_absolute_error:0.5324\n",
      "322/362 - mean:1.0394 - mean_absolute_error:0.5324\n",
      "323/362 - mean:1.0385 - mean_absolute_error:0.5323\n",
      "324/362 - mean:1.0380 - mean_absolute_error:0.5323\n",
      "325/362 - mean:1.0375 - mean_absolute_error:0.5325\n",
      "326/362 - mean:1.0371 - mean_absolute_error:0.5326\n",
      "327/362 - mean:1.0366 - mean_absolute_error:0.5325\n",
      "328/362 - mean:1.0366 - mean_absolute_error:0.5327\n",
      "329/362 - mean:1.0359 - mean_absolute_error:0.5327\n",
      "330/362 - mean:1.0352 - mean_absolute_error:0.5327\n",
      "331/362 - mean:1.0343 - mean_absolute_error:0.5325\n",
      "332/362 - mean:1.0334 - mean_absolute_error:0.5324\n",
      "333/362 - mean:1.0329 - mean_absolute_error:0.5325\n",
      "334/362 - mean:1.0322 - mean_absolute_error:0.5324\n",
      "335/362 - mean:1.0315 - mean_absolute_error:0.5324\n",
      "336/362 - mean:1.0308 - mean_absolute_error:0.5322\n",
      "337/362 - mean:1.0301 - mean_absolute_error:0.5321\n",
      "338/362 - mean:1.0295 - mean_absolute_error:0.5321\n",
      "339/362 - mean:1.0290 - mean_absolute_error:0.5320\n",
      "340/362 - mean:1.0286 - mean_absolute_error:0.5321\n",
      "341/362 - mean:1.0280 - mean_absolute_error:0.5320\n",
      "342/362 - mean:1.0272 - mean_absolute_error:0.5320\n",
      "343/362 - mean:1.0264 - mean_absolute_error:0.5318\n",
      "344/362 - mean:1.0261 - mean_absolute_error:0.5318\n",
      "345/362 - mean:1.0265 - mean_absolute_error:0.5321\n",
      "346/362 - mean:1.0261 - mean_absolute_error:0.5322\n",
      "347/362 - mean:1.0253 - mean_absolute_error:0.5321\n",
      "348/362 - mean:1.0245 - mean_absolute_error:0.5320\n",
      "349/362 - mean:1.0239 - mean_absolute_error:0.5319\n",
      "350/362 - mean:1.0232 - mean_absolute_error:0.5319\n",
      "351/362 - mean:1.0226 - mean_absolute_error:0.5319\n",
      "352/362 - mean:1.0223 - mean_absolute_error:0.5320\n",
      "353/362 - mean:1.0217 - mean_absolute_error:0.5320\n",
      "354/362 - mean:1.0211 - mean_absolute_error:0.5320\n",
      "355/362 - mean:1.0202 - mean_absolute_error:0.5318\n",
      "356/362 - mean:1.0200 - mean_absolute_error:0.5319\n",
      "357/362 - mean:1.0192 - mean_absolute_error:0.5318\n",
      "358/362 - mean:1.0190 - mean_absolute_error:0.5319\n",
      "359/362 - mean:1.0188 - mean_absolute_error:0.5320\n",
      "360/362 - mean:1.0178 - mean_absolute_error:0.5317\n",
      "361/362 - mean:1.0173 - mean_absolute_error:0.5317\n",
      "362/362 - mean:1.0167 - mean_absolute_error:0.5317\n",
      "Epoch 2/5\n",
      "1/362 - mean:0.6754 - mean_absolute_error:0.5136\n",
      "2/362 - mean:0.5296 - mean_absolute_error:0.4536\n",
      "3/362 - mean:0.5203 - mean_absolute_error:0.4649\n",
      "4/362 - mean:0.5055 - mean_absolute_error:0.4481\n",
      "5/362 - mean:0.5073 - mean_absolute_error:0.4445\n",
      "6/362 - mean:0.5049 - mean_absolute_error:0.4516\n",
      "7/362 - mean:0.5581 - mean_absolute_error:0.4751\n",
      "8/362 - mean:0.5825 - mean_absolute_error:0.4817\n",
      "9/362 - mean:0.5685 - mean_absolute_error:0.4808\n",
      "10/362 - mean:0.5781 - mean_absolute_error:0.4875\n",
      "11/362 - mean:0.5805 - mean_absolute_error:0.4789\n",
      "12/362 - mean:0.5807 - mean_absolute_error:0.4804\n",
      "13/362 - mean:0.5769 - mean_absolute_error:0.4808\n",
      "14/362 - mean:0.5794 - mean_absolute_error:0.4808\n",
      "15/362 - mean:0.5860 - mean_absolute_error:0.4875\n",
      "16/362 - mean:0.5854 - mean_absolute_error:0.4881\n",
      "17/362 - mean:0.5936 - mean_absolute_error:0.4919\n",
      "18/362 - mean:0.5936 - mean_absolute_error:0.4901\n",
      "19/362 - mean:0.5790 - mean_absolute_error:0.4807\n",
      "20/362 - mean:0.5890 - mean_absolute_error:0.4852\n",
      "21/362 - mean:0.6038 - mean_absolute_error:0.4899\n",
      "22/362 - mean:0.6034 - mean_absolute_error:0.4911\n",
      "23/362 - mean:0.6060 - mean_absolute_error:0.4943\n",
      "24/362 - mean:0.6107 - mean_absolute_error:0.4978\n",
      "25/362 - mean:0.6146 - mean_absolute_error:0.5000\n",
      "26/362 - mean:0.6188 - mean_absolute_error:0.5011\n",
      "27/362 - mean:0.6158 - mean_absolute_error:0.4983\n",
      "28/362 - mean:0.6095 - mean_absolute_error:0.4960\n",
      "29/362 - mean:0.6193 - mean_absolute_error:0.4988\n",
      "30/362 - mean:0.6092 - mean_absolute_error:0.4939\n",
      "31/362 - mean:0.6019 - mean_absolute_error:0.4907\n",
      "32/362 - mean:0.5961 - mean_absolute_error:0.4873\n",
      "33/362 - mean:0.6243 - mean_absolute_error:0.4972\n",
      "34/362 - mean:0.6211 - mean_absolute_error:0.4946\n",
      "35/362 - mean:0.6248 - mean_absolute_error:0.4972\n",
      "36/362 - mean:0.6176 - mean_absolute_error:0.4931\n",
      "37/362 - mean:0.6228 - mean_absolute_error:0.4953\n",
      "38/362 - mean:0.6184 - mean_absolute_error:0.4926\n",
      "39/362 - mean:0.6121 - mean_absolute_error:0.4904\n",
      "40/362 - mean:0.6184 - mean_absolute_error:0.4940\n",
      "41/362 - mean:0.6173 - mean_absolute_error:0.4925\n",
      "42/362 - mean:0.6203 - mean_absolute_error:0.4942\n",
      "43/362 - mean:0.6169 - mean_absolute_error:0.4933\n",
      "44/362 - mean:0.6144 - mean_absolute_error:0.4918\n",
      "45/362 - mean:0.6198 - mean_absolute_error:0.4944\n",
      "46/362 - mean:0.6201 - mean_absolute_error:0.4949\n",
      "47/362 - mean:0.6209 - mean_absolute_error:0.4948\n",
      "48/362 - mean:0.6233 - mean_absolute_error:0.4964\n",
      "49/362 - mean:0.6207 - mean_absolute_error:0.4961\n",
      "50/362 - mean:0.6193 - mean_absolute_error:0.4950\n",
      "51/362 - mean:0.6187 - mean_absolute_error:0.4950\n",
      "52/362 - mean:0.6212 - mean_absolute_error:0.4948\n",
      "53/362 - mean:0.6306 - mean_absolute_error:0.5001\n",
      "54/362 - mean:0.6312 - mean_absolute_error:0.5000\n",
      "55/362 - mean:0.6280 - mean_absolute_error:0.4980\n",
      "56/362 - mean:0.6259 - mean_absolute_error:0.4973\n",
      "57/362 - mean:0.6249 - mean_absolute_error:0.4968\n",
      "58/362 - mean:0.6359 - mean_absolute_error:0.5018\n",
      "59/362 - mean:0.6357 - mean_absolute_error:0.5019\n",
      "60/362 - mean:0.6409 - mean_absolute_error:0.5050\n",
      "61/362 - mean:0.6471 - mean_absolute_error:0.5066\n",
      "62/362 - mean:0.6439 - mean_absolute_error:0.5053\n",
      "63/362 - mean:0.6446 - mean_absolute_error:0.5062\n",
      "64/362 - mean:0.6507 - mean_absolute_error:0.5091\n",
      "65/362 - mean:0.6549 - mean_absolute_error:0.5115\n",
      "66/362 - mean:0.6615 - mean_absolute_error:0.5141\n",
      "67/362 - mean:0.6625 - mean_absolute_error:0.5154\n",
      "68/362 - mean:0.6647 - mean_absolute_error:0.5174\n",
      "69/362 - mean:0.6651 - mean_absolute_error:0.5176\n",
      "70/362 - mean:0.6642 - mean_absolute_error:0.5176\n",
      "71/362 - mean:0.6628 - mean_absolute_error:0.5176\n",
      "72/362 - mean:0.6679 - mean_absolute_error:0.5191\n",
      "73/362 - mean:0.6677 - mean_absolute_error:0.5198\n",
      "74/362 - mean:0.6692 - mean_absolute_error:0.5195\n",
      "75/362 - mean:0.6681 - mean_absolute_error:0.5203\n",
      "76/362 - mean:0.6707 - mean_absolute_error:0.5215\n",
      "77/362 - mean:0.6694 - mean_absolute_error:0.5219\n",
      "78/362 - mean:0.6674 - mean_absolute_error:0.5213\n",
      "79/362 - mean:0.6665 - mean_absolute_error:0.5210\n",
      "80/362 - mean:0.6633 - mean_absolute_error:0.5199\n",
      "81/362 - mean:0.6613 - mean_absolute_error:0.5191\n",
      "82/362 - mean:0.6637 - mean_absolute_error:0.5210\n",
      "83/362 - mean:0.6645 - mean_absolute_error:0.5213\n",
      "84/362 - mean:0.6625 - mean_absolute_error:0.5204\n",
      "85/362 - mean:0.6588 - mean_absolute_error:0.5187\n",
      "86/362 - mean:0.6567 - mean_absolute_error:0.5177\n",
      "87/362 - mean:0.6545 - mean_absolute_error:0.5166\n",
      "88/362 - mean:0.6577 - mean_absolute_error:0.5183\n",
      "89/362 - mean:0.6590 - mean_absolute_error:0.5192\n",
      "90/362 - mean:0.6561 - mean_absolute_error:0.5181\n",
      "91/362 - mean:0.6550 - mean_absolute_error:0.5181\n",
      "92/362 - mean:0.6536 - mean_absolute_error:0.5167\n",
      "93/362 - mean:0.6504 - mean_absolute_error:0.5150\n",
      "94/362 - mean:0.6513 - mean_absolute_error:0.5155\n",
      "95/362 - mean:0.6519 - mean_absolute_error:0.5159\n",
      "96/362 - mean:0.6504 - mean_absolute_error:0.5153\n",
      "97/362 - mean:0.6494 - mean_absolute_error:0.5151\n",
      "98/362 - mean:0.6512 - mean_absolute_error:0.5159\n",
      "99/362 - mean:0.6523 - mean_absolute_error:0.5167\n",
      "100/362 - mean:0.6514 - mean_absolute_error:0.5165\n",
      "101/362 - mean:0.6497 - mean_absolute_error:0.5154\n",
      "102/362 - mean:0.6500 - mean_absolute_error:0.5158\n",
      "103/362 - mean:0.6499 - mean_absolute_error:0.5159\n",
      "104/362 - mean:0.6504 - mean_absolute_error:0.5164\n",
      "105/362 - mean:0.6492 - mean_absolute_error:0.5159\n",
      "106/362 - mean:0.6488 - mean_absolute_error:0.5158\n",
      "107/362 - mean:0.6487 - mean_absolute_error:0.5156\n",
      "108/362 - mean:0.6475 - mean_absolute_error:0.5148\n",
      "109/362 - mean:0.6508 - mean_absolute_error:0.5154\n",
      "110/362 - mean:0.6512 - mean_absolute_error:0.5161\n",
      "111/362 - mean:0.6498 - mean_absolute_error:0.5159\n",
      "112/362 - mean:0.6494 - mean_absolute_error:0.5153\n",
      "113/362 - mean:0.6482 - mean_absolute_error:0.5147\n",
      "114/362 - mean:0.6485 - mean_absolute_error:0.5150\n",
      "115/362 - mean:0.6472 - mean_absolute_error:0.5146\n",
      "116/362 - mean:0.6465 - mean_absolute_error:0.5145\n",
      "117/362 - mean:0.6451 - mean_absolute_error:0.5138\n",
      "118/362 - mean:0.6441 - mean_absolute_error:0.5133\n",
      "119/362 - mean:0.6427 - mean_absolute_error:0.5126\n",
      "120/362 - mean:0.6397 - mean_absolute_error:0.5107\n",
      "121/362 - mean:0.6390 - mean_absolute_error:0.5106\n",
      "122/362 - mean:0.6374 - mean_absolute_error:0.5095\n",
      "123/362 - mean:0.6353 - mean_absolute_error:0.5084\n",
      "124/362 - mean:0.6406 - mean_absolute_error:0.5099\n",
      "125/362 - mean:0.6392 - mean_absolute_error:0.5089\n",
      "126/362 - mean:0.6377 - mean_absolute_error:0.5083\n",
      "127/362 - mean:0.6375 - mean_absolute_error:0.5076\n",
      "128/362 - mean:0.6370 - mean_absolute_error:0.5073\n",
      "129/362 - mean:0.6351 - mean_absolute_error:0.5064\n",
      "130/362 - mean:0.6330 - mean_absolute_error:0.5054\n",
      "131/362 - mean:0.6340 - mean_absolute_error:0.5060\n",
      "132/362 - mean:0.6331 - mean_absolute_error:0.5059\n",
      "133/362 - mean:0.6327 - mean_absolute_error:0.5061\n",
      "134/362 - mean:0.6377 - mean_absolute_error:0.5075\n",
      "135/362 - mean:0.6365 - mean_absolute_error:0.5071\n",
      "136/362 - mean:0.6390 - mean_absolute_error:0.5079\n",
      "137/362 - mean:0.6396 - mean_absolute_error:0.5081\n",
      "138/362 - mean:0.6383 - mean_absolute_error:0.5074\n",
      "139/362 - mean:0.6366 - mean_absolute_error:0.5068\n",
      "140/362 - mean:0.6380 - mean_absolute_error:0.5076\n",
      "141/362 - mean:0.6392 - mean_absolute_error:0.5086\n",
      "142/362 - mean:0.6385 - mean_absolute_error:0.5089\n",
      "143/362 - mean:0.6404 - mean_absolute_error:0.5097\n",
      "144/362 - mean:0.6398 - mean_absolute_error:0.5095\n",
      "145/362 - mean:0.6392 - mean_absolute_error:0.5095\n",
      "146/362 - mean:0.6384 - mean_absolute_error:0.5093\n",
      "147/362 - mean:0.6368 - mean_absolute_error:0.5085\n",
      "148/362 - mean:0.6367 - mean_absolute_error:0.5088\n",
      "149/362 - mean:0.6346 - mean_absolute_error:0.5077\n",
      "150/362 - mean:0.6344 - mean_absolute_error:0.5078\n",
      "151/362 - mean:0.6334 - mean_absolute_error:0.5077\n",
      "152/362 - mean:0.6325 - mean_absolute_error:0.5075\n",
      "153/362 - mean:0.6319 - mean_absolute_error:0.5071\n",
      "154/362 - mean:0.6363 - mean_absolute_error:0.5074\n",
      "155/362 - mean:0.6371 - mean_absolute_error:0.5080\n",
      "156/362 - mean:0.6354 - mean_absolute_error:0.5072\n",
      "157/362 - mean:0.6358 - mean_absolute_error:0.5074\n",
      "158/362 - mean:0.6348 - mean_absolute_error:0.5071\n",
      "159/362 - mean:0.6350 - mean_absolute_error:0.5077\n",
      "160/362 - mean:0.6377 - mean_absolute_error:0.5089\n",
      "161/362 - mean:0.6376 - mean_absolute_error:0.5089\n",
      "162/362 - mean:0.6363 - mean_absolute_error:0.5086\n",
      "163/362 - mean:0.6374 - mean_absolute_error:0.5087\n",
      "164/362 - mean:0.6361 - mean_absolute_error:0.5081\n",
      "165/362 - mean:0.6359 - mean_absolute_error:0.5081\n",
      "166/362 - mean:0.6365 - mean_absolute_error:0.5080\n",
      "167/362 - mean:0.6358 - mean_absolute_error:0.5082\n",
      "168/362 - mean:0.6352 - mean_absolute_error:0.5082\n",
      "169/362 - mean:0.6352 - mean_absolute_error:0.5087\n",
      "170/362 - mean:0.6347 - mean_absolute_error:0.5082\n",
      "171/362 - mean:0.6353 - mean_absolute_error:0.5086\n",
      "172/362 - mean:0.6359 - mean_absolute_error:0.5089\n",
      "173/362 - mean:0.6344 - mean_absolute_error:0.5081\n",
      "174/362 - mean:0.6350 - mean_absolute_error:0.5084\n",
      "175/362 - mean:0.6337 - mean_absolute_error:0.5077\n",
      "176/362 - mean:0.6321 - mean_absolute_error:0.5069\n",
      "177/362 - mean:0.6331 - mean_absolute_error:0.5070\n",
      "178/362 - mean:0.6328 - mean_absolute_error:0.5071\n",
      "179/362 - mean:0.6324 - mean_absolute_error:0.5068\n",
      "180/362 - mean:0.6329 - mean_absolute_error:0.5067\n",
      "181/362 - mean:0.6330 - mean_absolute_error:0.5068\n",
      "182/362 - mean:0.6323 - mean_absolute_error:0.5065\n",
      "183/362 - mean:0.6303 - mean_absolute_error:0.5054\n",
      "184/362 - mean:0.6297 - mean_absolute_error:0.5051\n",
      "185/362 - mean:0.6291 - mean_absolute_error:0.5052\n",
      "186/362 - mean:0.6281 - mean_absolute_error:0.5048\n",
      "187/362 - mean:0.6275 - mean_absolute_error:0.5047\n",
      "188/362 - mean:0.6275 - mean_absolute_error:0.5049\n",
      "189/362 - mean:0.6288 - mean_absolute_error:0.5055\n",
      "190/362 - mean:0.6308 - mean_absolute_error:0.5069\n",
      "191/362 - mean:0.6311 - mean_absolute_error:0.5071\n",
      "192/362 - mean:0.6308 - mean_absolute_error:0.5068\n",
      "193/362 - mean:0.6292 - mean_absolute_error:0.5061\n",
      "194/362 - mean:0.6293 - mean_absolute_error:0.5063\n",
      "195/362 - mean:0.6293 - mean_absolute_error:0.5065\n",
      "196/362 - mean:0.6295 - mean_absolute_error:0.5070\n",
      "197/362 - mean:0.6290 - mean_absolute_error:0.5069\n",
      "198/362 - mean:0.6285 - mean_absolute_error:0.5069\n",
      "199/362 - mean:0.6290 - mean_absolute_error:0.5070\n",
      "200/362 - mean:0.6307 - mean_absolute_error:0.5078\n",
      "201/362 - mean:0.6317 - mean_absolute_error:0.5088\n",
      "202/362 - mean:0.6317 - mean_absolute_error:0.5093\n",
      "203/362 - mean:0.6307 - mean_absolute_error:0.5089\n",
      "204/362 - mean:0.6312 - mean_absolute_error:0.5091\n",
      "205/362 - mean:0.6324 - mean_absolute_error:0.5099\n",
      "206/362 - mean:0.6333 - mean_absolute_error:0.5105\n",
      "207/362 - mean:0.6330 - mean_absolute_error:0.5107\n",
      "208/362 - mean:0.6338 - mean_absolute_error:0.5109\n",
      "209/362 - mean:0.6331 - mean_absolute_error:0.5107\n",
      "210/362 - mean:0.6325 - mean_absolute_error:0.5106\n",
      "211/362 - mean:0.6320 - mean_absolute_error:0.5105\n",
      "212/362 - mean:0.6324 - mean_absolute_error:0.5106\n",
      "213/362 - mean:0.6322 - mean_absolute_error:0.5103\n",
      "214/362 - mean:0.6309 - mean_absolute_error:0.5097\n",
      "215/362 - mean:0.6314 - mean_absolute_error:0.5101\n",
      "216/362 - mean:0.6310 - mean_absolute_error:0.5101\n",
      "217/362 - mean:0.6304 - mean_absolute_error:0.5101\n",
      "218/362 - mean:0.6300 - mean_absolute_error:0.5102\n",
      "219/362 - mean:0.6295 - mean_absolute_error:0.5100\n",
      "220/362 - mean:0.6286 - mean_absolute_error:0.5094\n",
      "221/362 - mean:0.6288 - mean_absolute_error:0.5093\n",
      "222/362 - mean:0.6282 - mean_absolute_error:0.5090\n",
      "223/362 - mean:0.6274 - mean_absolute_error:0.5085\n",
      "224/362 - mean:0.6262 - mean_absolute_error:0.5079\n",
      "225/362 - mean:0.6269 - mean_absolute_error:0.5082\n",
      "226/362 - mean:0.6267 - mean_absolute_error:0.5079\n",
      "227/362 - mean:0.6262 - mean_absolute_error:0.5078\n",
      "228/362 - mean:0.6250 - mean_absolute_error:0.5072\n",
      "229/362 - mean:0.6249 - mean_absolute_error:0.5074\n",
      "230/362 - mean:0.6248 - mean_absolute_error:0.5074\n",
      "231/362 - mean:0.6248 - mean_absolute_error:0.5074\n",
      "232/362 - mean:0.6247 - mean_absolute_error:0.5076\n",
      "233/362 - mean:0.6256 - mean_absolute_error:0.5081\n",
      "234/362 - mean:0.6267 - mean_absolute_error:0.5084\n",
      "235/362 - mean:0.6264 - mean_absolute_error:0.5083\n",
      "236/362 - mean:0.6255 - mean_absolute_error:0.5079\n",
      "237/362 - mean:0.6253 - mean_absolute_error:0.5079\n",
      "238/362 - mean:0.6267 - mean_absolute_error:0.5086\n",
      "239/362 - mean:0.6272 - mean_absolute_error:0.5085\n",
      "240/362 - mean:0.6267 - mean_absolute_error:0.5082\n",
      "241/362 - mean:0.6263 - mean_absolute_error:0.5080\n",
      "242/362 - mean:0.6279 - mean_absolute_error:0.5084\n",
      "243/362 - mean:0.6271 - mean_absolute_error:0.5081\n",
      "244/362 - mean:0.6271 - mean_absolute_error:0.5078\n",
      "245/362 - mean:0.6263 - mean_absolute_error:0.5073\n",
      "246/362 - mean:0.6264 - mean_absolute_error:0.5075\n",
      "247/362 - mean:0.6261 - mean_absolute_error:0.5076\n",
      "248/362 - mean:0.6277 - mean_absolute_error:0.5083\n",
      "249/362 - mean:0.6274 - mean_absolute_error:0.5081\n",
      "250/362 - mean:0.6268 - mean_absolute_error:0.5079\n",
      "251/362 - mean:0.6266 - mean_absolute_error:0.5077\n",
      "252/362 - mean:0.6266 - mean_absolute_error:0.5079\n",
      "253/362 - mean:0.6257 - mean_absolute_error:0.5076\n",
      "254/362 - mean:0.6251 - mean_absolute_error:0.5073\n",
      "255/362 - mean:0.6243 - mean_absolute_error:0.5070\n",
      "256/362 - mean:0.6241 - mean_absolute_error:0.5069\n",
      "257/362 - mean:0.6253 - mean_absolute_error:0.5073\n",
      "258/362 - mean:0.6252 - mean_absolute_error:0.5073\n",
      "259/362 - mean:0.6249 - mean_absolute_error:0.5069\n",
      "260/362 - mean:0.6249 - mean_absolute_error:0.5071\n",
      "261/362 - mean:0.6237 - mean_absolute_error:0.5065\n",
      "262/362 - mean:0.6238 - mean_absolute_error:0.5066\n",
      "263/362 - mean:0.6241 - mean_absolute_error:0.5067\n",
      "264/362 - mean:0.6242 - mean_absolute_error:0.5068\n",
      "265/362 - mean:0.6236 - mean_absolute_error:0.5067\n",
      "266/362 - mean:0.6239 - mean_absolute_error:0.5068\n",
      "267/362 - mean:0.6238 - mean_absolute_error:0.5066\n",
      "268/362 - mean:0.6237 - mean_absolute_error:0.5067\n",
      "269/362 - mean:0.6235 - mean_absolute_error:0.5067\n",
      "270/362 - mean:0.6225 - mean_absolute_error:0.5062\n",
      "271/362 - mean:0.6222 - mean_absolute_error:0.5061\n",
      "272/362 - mean:0.6223 - mean_absolute_error:0.5061\n",
      "273/362 - mean:0.6215 - mean_absolute_error:0.5058\n",
      "274/362 - mean:0.6222 - mean_absolute_error:0.5060\n",
      "275/362 - mean:0.6233 - mean_absolute_error:0.5065\n",
      "276/362 - mean:0.6229 - mean_absolute_error:0.5065\n",
      "277/362 - mean:0.6229 - mean_absolute_error:0.5065\n",
      "278/362 - mean:0.6224 - mean_absolute_error:0.5064\n",
      "279/362 - mean:0.6219 - mean_absolute_error:0.5063\n",
      "280/362 - mean:0.6221 - mean_absolute_error:0.5064\n",
      "281/362 - mean:0.6221 - mean_absolute_error:0.5063\n",
      "282/362 - mean:0.6216 - mean_absolute_error:0.5063\n",
      "283/362 - mean:0.6208 - mean_absolute_error:0.5059\n",
      "284/362 - mean:0.6207 - mean_absolute_error:0.5060\n",
      "285/362 - mean:0.6213 - mean_absolute_error:0.5065\n",
      "286/362 - mean:0.6216 - mean_absolute_error:0.5066\n",
      "287/362 - mean:0.6224 - mean_absolute_error:0.5070\n",
      "288/362 - mean:0.6225 - mean_absolute_error:0.5070\n",
      "289/362 - mean:0.6227 - mean_absolute_error:0.5071\n",
      "290/362 - mean:0.6230 - mean_absolute_error:0.5071\n",
      "291/362 - mean:0.6229 - mean_absolute_error:0.5071\n",
      "292/362 - mean:0.6220 - mean_absolute_error:0.5066\n",
      "293/362 - mean:0.6217 - mean_absolute_error:0.5065\n",
      "294/362 - mean:0.6214 - mean_absolute_error:0.5064\n",
      "295/362 - mean:0.6223 - mean_absolute_error:0.5070\n",
      "296/362 - mean:0.6229 - mean_absolute_error:0.5070\n",
      "297/362 - mean:0.6235 - mean_absolute_error:0.5074\n",
      "298/362 - mean:0.6229 - mean_absolute_error:0.5071\n",
      "299/362 - mean:0.6229 - mean_absolute_error:0.5072\n",
      "300/362 - mean:0.6224 - mean_absolute_error:0.5069\n",
      "301/362 - mean:0.6218 - mean_absolute_error:0.5065\n",
      "302/362 - mean:0.6222 - mean_absolute_error:0.5068\n",
      "303/362 - mean:0.6214 - mean_absolute_error:0.5064\n",
      "304/362 - mean:0.6210 - mean_absolute_error:0.5063\n",
      "305/362 - mean:0.6209 - mean_absolute_error:0.5064\n",
      "306/362 - mean:0.6215 - mean_absolute_error:0.5068\n",
      "307/362 - mean:0.6212 - mean_absolute_error:0.5066\n",
      "308/362 - mean:0.6205 - mean_absolute_error:0.5063\n",
      "309/362 - mean:0.6204 - mean_absolute_error:0.5062\n",
      "310/362 - mean:0.6207 - mean_absolute_error:0.5063\n",
      "311/362 - mean:0.6201 - mean_absolute_error:0.5061\n",
      "312/362 - mean:0.6209 - mean_absolute_error:0.5066\n",
      "313/362 - mean:0.6203 - mean_absolute_error:0.5063\n",
      "314/362 - mean:0.6207 - mean_absolute_error:0.5065\n",
      "315/362 - mean:0.6199 - mean_absolute_error:0.5061\n",
      "316/362 - mean:0.6193 - mean_absolute_error:0.5059\n",
      "317/362 - mean:0.6194 - mean_absolute_error:0.5060\n",
      "318/362 - mean:0.6204 - mean_absolute_error:0.5065\n",
      "319/362 - mean:0.6203 - mean_absolute_error:0.5065\n",
      "320/362 - mean:0.6204 - mean_absolute_error:0.5065\n",
      "321/362 - mean:0.6198 - mean_absolute_error:0.5062\n",
      "322/362 - mean:0.6193 - mean_absolute_error:0.5061\n",
      "323/362 - mean:0.6198 - mean_absolute_error:0.5063\n",
      "324/362 - mean:0.6197 - mean_absolute_error:0.5065\n",
      "325/362 - mean:0.6200 - mean_absolute_error:0.5067\n",
      "326/362 - mean:0.6195 - mean_absolute_error:0.5064\n",
      "327/362 - mean:0.6198 - mean_absolute_error:0.5067\n",
      "328/362 - mean:0.6198 - mean_absolute_error:0.5068\n",
      "329/362 - mean:0.6203 - mean_absolute_error:0.5069\n",
      "330/362 - mean:0.6200 - mean_absolute_error:0.5068\n",
      "331/362 - mean:0.6198 - mean_absolute_error:0.5068\n",
      "332/362 - mean:0.6202 - mean_absolute_error:0.5071\n",
      "333/362 - mean:0.6208 - mean_absolute_error:0.5075\n",
      "334/362 - mean:0.6217 - mean_absolute_error:0.5079\n",
      "335/362 - mean:0.6220 - mean_absolute_error:0.5081\n",
      "336/362 - mean:0.6220 - mean_absolute_error:0.5080\n",
      "337/362 - mean:0.6219 - mean_absolute_error:0.5079\n",
      "338/362 - mean:0.6213 - mean_absolute_error:0.5077\n",
      "339/362 - mean:0.6211 - mean_absolute_error:0.5076\n",
      "340/362 - mean:0.6213 - mean_absolute_error:0.5079\n",
      "341/362 - mean:0.6206 - mean_absolute_error:0.5076\n",
      "342/362 - mean:0.6205 - mean_absolute_error:0.5077\n",
      "343/362 - mean:0.6208 - mean_absolute_error:0.5078\n",
      "344/362 - mean:0.6207 - mean_absolute_error:0.5079\n",
      "345/362 - mean:0.6208 - mean_absolute_error:0.5079\n",
      "346/362 - mean:0.6212 - mean_absolute_error:0.5080\n",
      "347/362 - mean:0.6208 - mean_absolute_error:0.5079\n",
      "348/362 - mean:0.6208 - mean_absolute_error:0.5080\n",
      "349/362 - mean:0.6200 - mean_absolute_error:0.5076\n",
      "350/362 - mean:0.6201 - mean_absolute_error:0.5076\n",
      "351/362 - mean:0.6199 - mean_absolute_error:0.5075\n",
      "352/362 - mean:0.6192 - mean_absolute_error:0.5070\n",
      "353/362 - mean:0.6203 - mean_absolute_error:0.5074\n",
      "354/362 - mean:0.6205 - mean_absolute_error:0.5076\n",
      "355/362 - mean:0.6202 - mean_absolute_error:0.5074\n",
      "356/362 - mean:0.6211 - mean_absolute_error:0.5079\n",
      "357/362 - mean:0.6209 - mean_absolute_error:0.5079\n",
      "358/362 - mean:0.6206 - mean_absolute_error:0.5078\n",
      "359/362 - mean:0.6205 - mean_absolute_error:0.5077\n",
      "360/362 - mean:0.6208 - mean_absolute_error:0.5076\n",
      "361/362 - mean:0.6205 - mean_absolute_error:0.5074\n",
      "362/362 - mean:0.6209 - mean_absolute_error:0.5075\n",
      "Epoch 3/5\n",
      "1/362 - mean:0.4056 - mean_absolute_error:0.3973\n",
      "2/362 - mean:0.4574 - mean_absolute_error:0.4332\n",
      "3/362 - mean:0.4327 - mean_absolute_error:0.4044\n",
      "4/362 - mean:0.4326 - mean_absolute_error:0.4141\n",
      "5/362 - mean:0.4770 - mean_absolute_error:0.4402\n",
      "6/362 - mean:0.5216 - mean_absolute_error:0.4703\n",
      "7/362 - mean:0.5479 - mean_absolute_error:0.4681\n",
      "8/362 - mean:0.5944 - mean_absolute_error:0.4867\n",
      "9/362 - mean:0.5833 - mean_absolute_error:0.4786\n",
      "10/362 - mean:0.6147 - mean_absolute_error:0.4859\n",
      "11/362 - mean:0.6141 - mean_absolute_error:0.4895\n",
      "12/362 - mean:0.6059 - mean_absolute_error:0.4874\n",
      "13/362 - mean:0.5899 - mean_absolute_error:0.4799\n",
      "14/362 - mean:0.5861 - mean_absolute_error:0.4778\n",
      "15/362 - mean:0.5720 - mean_absolute_error:0.4702\n",
      "16/362 - mean:0.5651 - mean_absolute_error:0.4690\n",
      "17/362 - mean:0.5603 - mean_absolute_error:0.4667\n",
      "18/362 - mean:0.5557 - mean_absolute_error:0.4651\n",
      "19/362 - mean:0.5691 - mean_absolute_error:0.4714\n",
      "20/362 - mean:0.5711 - mean_absolute_error:0.4720\n",
      "21/362 - mean:0.5666 - mean_absolute_error:0.4708\n",
      "22/362 - mean:0.5752 - mean_absolute_error:0.4756\n",
      "23/362 - mean:0.5711 - mean_absolute_error:0.4753\n",
      "24/362 - mean:0.5709 - mean_absolute_error:0.4750\n",
      "25/362 - mean:0.5751 - mean_absolute_error:0.4789\n",
      "26/362 - mean:0.5871 - mean_absolute_error:0.4855\n",
      "27/362 - mean:0.5890 - mean_absolute_error:0.4881\n",
      "28/362 - mean:0.5875 - mean_absolute_error:0.4881\n",
      "29/362 - mean:0.5852 - mean_absolute_error:0.4888\n",
      "30/362 - mean:0.5816 - mean_absolute_error:0.4884\n",
      "31/362 - mean:0.5737 - mean_absolute_error:0.4840\n",
      "32/362 - mean:0.5729 - mean_absolute_error:0.4830\n",
      "33/362 - mean:0.5825 - mean_absolute_error:0.4869\n",
      "34/362 - mean:0.5783 - mean_absolute_error:0.4851\n",
      "35/362 - mean:0.5753 - mean_absolute_error:0.4840\n",
      "36/362 - mean:0.6100 - mean_absolute_error:0.4905\n",
      "37/362 - mean:0.6110 - mean_absolute_error:0.4917\n",
      "38/362 - mean:0.6069 - mean_absolute_error:0.4902\n",
      "39/362 - mean:0.6135 - mean_absolute_error:0.4928\n",
      "40/362 - mean:0.6100 - mean_absolute_error:0.4916\n",
      "41/362 - mean:0.6091 - mean_absolute_error:0.4915\n",
      "42/362 - mean:0.6086 - mean_absolute_error:0.4917\n",
      "43/362 - mean:0.6021 - mean_absolute_error:0.4882\n",
      "44/362 - mean:0.6066 - mean_absolute_error:0.4908\n",
      "45/362 - mean:0.6120 - mean_absolute_error:0.4918\n",
      "46/362 - mean:0.6091 - mean_absolute_error:0.4914\n",
      "47/362 - mean:0.6209 - mean_absolute_error:0.4971\n",
      "48/362 - mean:0.6210 - mean_absolute_error:0.4970\n",
      "49/362 - mean:0.6204 - mean_absolute_error:0.4958\n",
      "50/362 - mean:0.6266 - mean_absolute_error:0.4989\n",
      "51/362 - mean:0.6284 - mean_absolute_error:0.4999\n",
      "52/362 - mean:0.6233 - mean_absolute_error:0.4979\n",
      "53/362 - mean:0.6269 - mean_absolute_error:0.4991\n",
      "54/362 - mean:0.6366 - mean_absolute_error:0.5032\n",
      "55/362 - mean:0.6345 - mean_absolute_error:0.5038\n",
      "56/362 - mean:0.6400 - mean_absolute_error:0.5064\n",
      "57/362 - mean:0.6431 - mean_absolute_error:0.5091\n",
      "58/362 - mean:0.6448 - mean_absolute_error:0.5121\n",
      "59/362 - mean:0.6474 - mean_absolute_error:0.5138\n",
      "60/362 - mean:0.6481 - mean_absolute_error:0.5153\n",
      "61/362 - mean:0.6476 - mean_absolute_error:0.5155\n",
      "62/362 - mean:0.6478 - mean_absolute_error:0.5161\n",
      "63/362 - mean:0.6477 - mean_absolute_error:0.5165\n",
      "64/362 - mean:0.6468 - mean_absolute_error:0.5166\n",
      "65/362 - mean:0.6483 - mean_absolute_error:0.5167\n",
      "66/362 - mean:0.6487 - mean_absolute_error:0.5168\n",
      "67/362 - mean:0.6536 - mean_absolute_error:0.5165\n",
      "68/362 - mean:0.6541 - mean_absolute_error:0.5164\n",
      "69/362 - mean:0.6515 - mean_absolute_error:0.5158\n",
      "70/362 - mean:0.6516 - mean_absolute_error:0.5160\n",
      "71/362 - mean:0.6597 - mean_absolute_error:0.5188\n",
      "72/362 - mean:0.6552 - mean_absolute_error:0.5161\n",
      "73/362 - mean:0.6564 - mean_absolute_error:0.5160\n",
      "74/362 - mean:0.6556 - mean_absolute_error:0.5163\n",
      "75/362 - mean:0.6539 - mean_absolute_error:0.5158\n",
      "76/362 - mean:0.6510 - mean_absolute_error:0.5148\n",
      "77/362 - mean:0.6514 - mean_absolute_error:0.5150\n",
      "78/362 - mean:0.6525 - mean_absolute_error:0.5161\n",
      "79/362 - mean:0.6498 - mean_absolute_error:0.5152\n",
      "80/362 - mean:0.6529 - mean_absolute_error:0.5161\n",
      "81/362 - mean:0.6526 - mean_absolute_error:0.5162\n",
      "82/362 - mean:0.6533 - mean_absolute_error:0.5172\n",
      "83/362 - mean:0.6494 - mean_absolute_error:0.5151\n",
      "84/362 - mean:0.6570 - mean_absolute_error:0.5183\n",
      "85/362 - mean:0.6570 - mean_absolute_error:0.5184\n",
      "86/362 - mean:0.6556 - mean_absolute_error:0.5180\n",
      "87/362 - mean:0.6539 - mean_absolute_error:0.5174\n",
      "88/362 - mean:0.6517 - mean_absolute_error:0.5164\n",
      "89/362 - mean:0.6519 - mean_absolute_error:0.5168\n",
      "90/362 - mean:0.6537 - mean_absolute_error:0.5174\n",
      "91/362 - mean:0.6528 - mean_absolute_error:0.5170\n",
      "92/362 - mean:0.6526 - mean_absolute_error:0.5173\n",
      "93/362 - mean:0.6523 - mean_absolute_error:0.5176\n",
      "94/362 - mean:0.6569 - mean_absolute_error:0.5190\n",
      "95/362 - mean:0.6565 - mean_absolute_error:0.5189\n",
      "96/362 - mean:0.6586 - mean_absolute_error:0.5204\n",
      "97/362 - mean:0.6577 - mean_absolute_error:0.5202\n",
      "98/362 - mean:0.6585 - mean_absolute_error:0.5201\n",
      "99/362 - mean:0.6547 - mean_absolute_error:0.5176\n",
      "100/362 - mean:0.6526 - mean_absolute_error:0.5174\n",
      "101/362 - mean:0.6517 - mean_absolute_error:0.5176\n",
      "102/362 - mean:0.6515 - mean_absolute_error:0.5178\n",
      "103/362 - mean:0.6497 - mean_absolute_error:0.5168\n",
      "104/362 - mean:0.6475 - mean_absolute_error:0.5157\n",
      "105/362 - mean:0.6469 - mean_absolute_error:0.5159\n",
      "106/362 - mean:0.6447 - mean_absolute_error:0.5151\n",
      "107/362 - mean:0.6461 - mean_absolute_error:0.5155\n",
      "108/362 - mean:0.6450 - mean_absolute_error:0.5151\n",
      "109/362 - mean:0.6454 - mean_absolute_error:0.5155\n",
      "110/362 - mean:0.6445 - mean_absolute_error:0.5155\n",
      "111/362 - mean:0.6446 - mean_absolute_error:0.5157\n",
      "112/362 - mean:0.6435 - mean_absolute_error:0.5150\n",
      "113/362 - mean:0.6414 - mean_absolute_error:0.5139\n",
      "114/362 - mean:0.6427 - mean_absolute_error:0.5152\n",
      "115/362 - mean:0.6451 - mean_absolute_error:0.5161\n",
      "116/362 - mean:0.6432 - mean_absolute_error:0.5152\n",
      "117/362 - mean:0.6412 - mean_absolute_error:0.5144\n",
      "118/362 - mean:0.6404 - mean_absolute_error:0.5142\n",
      "119/362 - mean:0.6401 - mean_absolute_error:0.5141\n",
      "120/362 - mean:0.6396 - mean_absolute_error:0.5133\n",
      "121/362 - mean:0.6368 - mean_absolute_error:0.5116\n",
      "122/362 - mean:0.6344 - mean_absolute_error:0.5102\n",
      "123/362 - mean:0.6330 - mean_absolute_error:0.5097\n",
      "124/362 - mean:0.6333 - mean_absolute_error:0.5100\n",
      "125/362 - mean:0.6326 - mean_absolute_error:0.5101\n",
      "126/362 - mean:0.6310 - mean_absolute_error:0.5092\n",
      "127/362 - mean:0.6296 - mean_absolute_error:0.5085\n",
      "128/362 - mean:0.6300 - mean_absolute_error:0.5085\n",
      "129/362 - mean:0.6290 - mean_absolute_error:0.5083\n",
      "130/362 - mean:0.6302 - mean_absolute_error:0.5088\n",
      "131/362 - mean:0.6286 - mean_absolute_error:0.5081\n",
      "132/362 - mean:0.6274 - mean_absolute_error:0.5078\n",
      "133/362 - mean:0.6276 - mean_absolute_error:0.5079\n",
      "134/362 - mean:0.6270 - mean_absolute_error:0.5078\n",
      "135/362 - mean:0.6247 - mean_absolute_error:0.5062\n",
      "136/362 - mean:0.6230 - mean_absolute_error:0.5052\n",
      "137/362 - mean:0.6240 - mean_absolute_error:0.5054\n",
      "138/362 - mean:0.6248 - mean_absolute_error:0.5058\n",
      "139/362 - mean:0.6252 - mean_absolute_error:0.5063\n",
      "140/362 - mean:0.6266 - mean_absolute_error:0.5070\n",
      "141/362 - mean:0.6269 - mean_absolute_error:0.5073\n",
      "142/362 - mean:0.6264 - mean_absolute_error:0.5075\n",
      "143/362 - mean:0.6253 - mean_absolute_error:0.5072\n",
      "144/362 - mean:0.6262 - mean_absolute_error:0.5078\n",
      "145/362 - mean:0.6254 - mean_absolute_error:0.5075\n",
      "146/362 - mean:0.6248 - mean_absolute_error:0.5072\n",
      "147/362 - mean:0.6276 - mean_absolute_error:0.5080\n",
      "148/362 - mean:0.6269 - mean_absolute_error:0.5078\n",
      "149/362 - mean:0.6270 - mean_absolute_error:0.5082\n",
      "150/362 - mean:0.6277 - mean_absolute_error:0.5088\n",
      "151/362 - mean:0.6264 - mean_absolute_error:0.5085\n",
      "152/362 - mean:0.6256 - mean_absolute_error:0.5077\n",
      "153/362 - mean:0.6240 - mean_absolute_error:0.5068\n",
      "154/362 - mean:0.6236 - mean_absolute_error:0.5069\n",
      "155/362 - mean:0.6239 - mean_absolute_error:0.5067\n",
      "156/362 - mean:0.6232 - mean_absolute_error:0.5066\n",
      "157/362 - mean:0.6230 - mean_absolute_error:0.5068\n",
      "158/362 - mean:0.6222 - mean_absolute_error:0.5065\n",
      "159/362 - mean:0.6224 - mean_absolute_error:0.5064\n",
      "160/362 - mean:0.6246 - mean_absolute_error:0.5075\n",
      "161/362 - mean:0.6266 - mean_absolute_error:0.5084\n",
      "162/362 - mean:0.6264 - mean_absolute_error:0.5079\n",
      "163/362 - mean:0.6274 - mean_absolute_error:0.5086\n",
      "164/362 - mean:0.6283 - mean_absolute_error:0.5094\n",
      "165/362 - mean:0.6287 - mean_absolute_error:0.5099\n",
      "166/362 - mean:0.6291 - mean_absolute_error:0.5099\n",
      "167/362 - mean:0.6373 - mean_absolute_error:0.5117\n",
      "168/362 - mean:0.6376 - mean_absolute_error:0.5123\n",
      "169/362 - mean:0.6371 - mean_absolute_error:0.5126\n",
      "170/362 - mean:0.6381 - mean_absolute_error:0.5137\n",
      "171/362 - mean:0.6377 - mean_absolute_error:0.5138\n",
      "172/362 - mean:0.6375 - mean_absolute_error:0.5136\n",
      "173/362 - mean:0.6367 - mean_absolute_error:0.5135\n",
      "174/362 - mean:0.6376 - mean_absolute_error:0.5135\n",
      "175/362 - mean:0.6371 - mean_absolute_error:0.5137\n",
      "176/362 - mean:0.6373 - mean_absolute_error:0.5141\n",
      "177/362 - mean:0.6358 - mean_absolute_error:0.5135\n",
      "178/362 - mean:0.6360 - mean_absolute_error:0.5138\n",
      "179/362 - mean:0.6349 - mean_absolute_error:0.5131\n",
      "180/362 - mean:0.6335 - mean_absolute_error:0.5124\n",
      "181/362 - mean:0.6331 - mean_absolute_error:0.5124\n",
      "182/362 - mean:0.6335 - mean_absolute_error:0.5121\n",
      "183/362 - mean:0.6332 - mean_absolute_error:0.5119\n",
      "184/362 - mean:0.6322 - mean_absolute_error:0.5113\n",
      "185/362 - mean:0.6315 - mean_absolute_error:0.5107\n",
      "186/362 - mean:0.6320 - mean_absolute_error:0.5112\n",
      "187/362 - mean:0.6328 - mean_absolute_error:0.5110\n",
      "188/362 - mean:0.6319 - mean_absolute_error:0.5104\n",
      "189/362 - mean:0.6336 - mean_absolute_error:0.5110\n",
      "190/362 - mean:0.6336 - mean_absolute_error:0.5110\n",
      "191/362 - mean:0.6338 - mean_absolute_error:0.5113\n",
      "192/362 - mean:0.6327 - mean_absolute_error:0.5111\n",
      "193/362 - mean:0.6315 - mean_absolute_error:0.5104\n",
      "194/362 - mean:0.6310 - mean_absolute_error:0.5103\n",
      "195/362 - mean:0.6304 - mean_absolute_error:0.5101\n",
      "196/362 - mean:0.6298 - mean_absolute_error:0.5098\n",
      "197/362 - mean:0.6288 - mean_absolute_error:0.5094\n",
      "198/362 - mean:0.6306 - mean_absolute_error:0.5100\n",
      "199/362 - mean:0.6334 - mean_absolute_error:0.5113\n",
      "200/362 - mean:0.6328 - mean_absolute_error:0.5111\n",
      "201/362 - mean:0.6319 - mean_absolute_error:0.5106\n",
      "202/362 - mean:0.6308 - mean_absolute_error:0.5100\n",
      "203/362 - mean:0.6310 - mean_absolute_error:0.5103\n",
      "204/362 - mean:0.6302 - mean_absolute_error:0.5099\n",
      "205/362 - mean:0.6298 - mean_absolute_error:0.5098\n",
      "206/362 - mean:0.6295 - mean_absolute_error:0.5097\n",
      "207/362 - mean:0.6289 - mean_absolute_error:0.5094\n",
      "208/362 - mean:0.6283 - mean_absolute_error:0.5090\n",
      "209/362 - mean:0.6295 - mean_absolute_error:0.5095\n",
      "210/362 - mean:0.6290 - mean_absolute_error:0.5093\n",
      "211/362 - mean:0.6283 - mean_absolute_error:0.5092\n",
      "212/362 - mean:0.6279 - mean_absolute_error:0.5089\n",
      "213/362 - mean:0.6283 - mean_absolute_error:0.5090\n",
      "214/362 - mean:0.6291 - mean_absolute_error:0.5090\n",
      "215/362 - mean:0.6281 - mean_absolute_error:0.5086\n",
      "216/362 - mean:0.6269 - mean_absolute_error:0.5079\n",
      "217/362 - mean:0.6283 - mean_absolute_error:0.5083\n",
      "218/362 - mean:0.6294 - mean_absolute_error:0.5089\n",
      "219/362 - mean:0.6297 - mean_absolute_error:0.5089\n",
      "220/362 - mean:0.6291 - mean_absolute_error:0.5084\n",
      "221/362 - mean:0.6291 - mean_absolute_error:0.5086\n",
      "222/362 - mean:0.6288 - mean_absolute_error:0.5086\n",
      "223/362 - mean:0.6291 - mean_absolute_error:0.5085\n",
      "224/362 - mean:0.6297 - mean_absolute_error:0.5087\n",
      "225/362 - mean:0.6304 - mean_absolute_error:0.5090\n",
      "226/362 - mean:0.6311 - mean_absolute_error:0.5091\n",
      "227/362 - mean:0.6305 - mean_absolute_error:0.5088\n",
      "228/362 - mean:0.6300 - mean_absolute_error:0.5087\n",
      "229/362 - mean:0.6302 - mean_absolute_error:0.5087\n",
      "230/362 - mean:0.6297 - mean_absolute_error:0.5085\n",
      "231/362 - mean:0.6293 - mean_absolute_error:0.5085\n",
      "232/362 - mean:0.6287 - mean_absolute_error:0.5082\n",
      "233/362 - mean:0.6294 - mean_absolute_error:0.5084\n",
      "234/362 - mean:0.6291 - mean_absolute_error:0.5081\n",
      "235/362 - mean:0.6289 - mean_absolute_error:0.5079\n",
      "236/362 - mean:0.6283 - mean_absolute_error:0.5078\n",
      "237/362 - mean:0.6273 - mean_absolute_error:0.5073\n",
      "238/362 - mean:0.6290 - mean_absolute_error:0.5081\n",
      "239/362 - mean:0.6289 - mean_absolute_error:0.5081\n",
      "240/362 - mean:0.6282 - mean_absolute_error:0.5078\n",
      "241/362 - mean:0.6278 - mean_absolute_error:0.5076\n",
      "242/362 - mean:0.6284 - mean_absolute_error:0.5080\n",
      "243/362 - mean:0.6278 - mean_absolute_error:0.5078\n",
      "244/362 - mean:0.6293 - mean_absolute_error:0.5084\n",
      "245/362 - mean:0.6287 - mean_absolute_error:0.5084\n",
      "246/362 - mean:0.6278 - mean_absolute_error:0.5082\n",
      "247/362 - mean:0.6293 - mean_absolute_error:0.5091\n",
      "248/362 - mean:0.6295 - mean_absolute_error:0.5093\n",
      "249/362 - mean:0.6292 - mean_absolute_error:0.5093\n",
      "250/362 - mean:0.6290 - mean_absolute_error:0.5094\n",
      "251/362 - mean:0.6289 - mean_absolute_error:0.5093\n",
      "252/362 - mean:0.6282 - mean_absolute_error:0.5090\n",
      "253/362 - mean:0.6280 - mean_absolute_error:0.5088\n",
      "254/362 - mean:0.6285 - mean_absolute_error:0.5091\n",
      "255/362 - mean:0.6284 - mean_absolute_error:0.5090\n",
      "256/362 - mean:0.6279 - mean_absolute_error:0.5089\n",
      "257/362 - mean:0.6283 - mean_absolute_error:0.5090\n",
      "258/362 - mean:0.6296 - mean_absolute_error:0.5095\n",
      "259/362 - mean:0.6299 - mean_absolute_error:0.5095\n",
      "260/362 - mean:0.6295 - mean_absolute_error:0.5095\n",
      "261/362 - mean:0.6297 - mean_absolute_error:0.5097\n",
      "262/362 - mean:0.6292 - mean_absolute_error:0.5093\n",
      "263/362 - mean:0.6289 - mean_absolute_error:0.5093\n",
      "264/362 - mean:0.6284 - mean_absolute_error:0.5091\n",
      "265/362 - mean:0.6288 - mean_absolute_error:0.5092\n",
      "266/362 - mean:0.6288 - mean_absolute_error:0.5095\n",
      "267/362 - mean:0.6292 - mean_absolute_error:0.5099\n",
      "268/362 - mean:0.6299 - mean_absolute_error:0.5101\n",
      "269/362 - mean:0.6298 - mean_absolute_error:0.5099\n",
      "270/362 - mean:0.6296 - mean_absolute_error:0.5099\n",
      "271/362 - mean:0.6298 - mean_absolute_error:0.5100\n",
      "272/362 - mean:0.6291 - mean_absolute_error:0.5099\n",
      "273/362 - mean:0.6283 - mean_absolute_error:0.5094\n",
      "274/362 - mean:0.6276 - mean_absolute_error:0.5092\n",
      "275/362 - mean:0.6281 - mean_absolute_error:0.5094\n",
      "276/362 - mean:0.6299 - mean_absolute_error:0.5103\n",
      "277/362 - mean:0.6296 - mean_absolute_error:0.5102\n",
      "278/362 - mean:0.6292 - mean_absolute_error:0.5103\n",
      "279/362 - mean:0.6298 - mean_absolute_error:0.5107\n",
      "280/362 - mean:0.6287 - mean_absolute_error:0.5101\n",
      "281/362 - mean:0.6292 - mean_absolute_error:0.5105\n",
      "282/362 - mean:0.6281 - mean_absolute_error:0.5100\n",
      "283/362 - mean:0.6275 - mean_absolute_error:0.5098\n",
      "284/362 - mean:0.6274 - mean_absolute_error:0.5098\n",
      "285/362 - mean:0.6269 - mean_absolute_error:0.5097\n",
      "286/362 - mean:0.6277 - mean_absolute_error:0.5099\n",
      "287/362 - mean:0.6274 - mean_absolute_error:0.5097\n",
      "288/362 - mean:0.6266 - mean_absolute_error:0.5094\n",
      "289/362 - mean:0.6271 - mean_absolute_error:0.5098\n",
      "290/362 - mean:0.6279 - mean_absolute_error:0.5098\n",
      "291/362 - mean:0.6282 - mean_absolute_error:0.5102\n",
      "292/362 - mean:0.6286 - mean_absolute_error:0.5103\n",
      "293/362 - mean:0.6284 - mean_absolute_error:0.5104\n",
      "294/362 - mean:0.6281 - mean_absolute_error:0.5104\n",
      "295/362 - mean:0.6277 - mean_absolute_error:0.5102\n",
      "296/362 - mean:0.6285 - mean_absolute_error:0.5105\n",
      "297/362 - mean:0.6279 - mean_absolute_error:0.5102\n",
      "298/362 - mean:0.6276 - mean_absolute_error:0.5101\n",
      "299/362 - mean:0.6276 - mean_absolute_error:0.5101\n",
      "300/362 - mean:0.6280 - mean_absolute_error:0.5102\n",
      "301/362 - mean:0.6277 - mean_absolute_error:0.5102\n",
      "302/362 - mean:0.6271 - mean_absolute_error:0.5099\n",
      "303/362 - mean:0.6264 - mean_absolute_error:0.5096\n",
      "304/362 - mean:0.6263 - mean_absolute_error:0.5095\n",
      "305/362 - mean:0.6260 - mean_absolute_error:0.5095\n",
      "306/362 - mean:0.6262 - mean_absolute_error:0.5096\n",
      "307/362 - mean:0.6263 - mean_absolute_error:0.5095\n",
      "308/362 - mean:0.6272 - mean_absolute_error:0.5099\n",
      "309/362 - mean:0.6270 - mean_absolute_error:0.5100\n",
      "310/362 - mean:0.6270 - mean_absolute_error:0.5103\n",
      "311/362 - mean:0.6262 - mean_absolute_error:0.5097\n",
      "312/362 - mean:0.6256 - mean_absolute_error:0.5095\n",
      "313/362 - mean:0.6259 - mean_absolute_error:0.5096\n",
      "314/362 - mean:0.6267 - mean_absolute_error:0.5100\n",
      "315/362 - mean:0.6275 - mean_absolute_error:0.5102\n",
      "316/362 - mean:0.6266 - mean_absolute_error:0.5097\n",
      "317/362 - mean:0.6266 - mean_absolute_error:0.5095\n",
      "318/362 - mean:0.6263 - mean_absolute_error:0.5094\n",
      "319/362 - mean:0.6265 - mean_absolute_error:0.5095\n",
      "320/362 - mean:0.6264 - mean_absolute_error:0.5096\n",
      "321/362 - mean:0.6261 - mean_absolute_error:0.5096\n",
      "322/362 - mean:0.6275 - mean_absolute_error:0.5100\n",
      "323/362 - mean:0.6270 - mean_absolute_error:0.5097\n",
      "324/362 - mean:0.6275 - mean_absolute_error:0.5100\n",
      "325/362 - mean:0.6266 - mean_absolute_error:0.5096\n",
      "326/362 - mean:0.6265 - mean_absolute_error:0.5095\n",
      "327/362 - mean:0.6263 - mean_absolute_error:0.5094\n",
      "328/362 - mean:0.6259 - mean_absolute_error:0.5092\n",
      "329/362 - mean:0.6263 - mean_absolute_error:0.5093\n",
      "330/362 - mean:0.6268 - mean_absolute_error:0.5096\n",
      "331/362 - mean:0.6266 - mean_absolute_error:0.5095\n",
      "332/362 - mean:0.6266 - mean_absolute_error:0.5094\n",
      "333/362 - mean:0.6268 - mean_absolute_error:0.5096\n",
      "334/362 - mean:0.6263 - mean_absolute_error:0.5094\n",
      "335/362 - mean:0.6264 - mean_absolute_error:0.5096\n",
      "336/362 - mean:0.6263 - mean_absolute_error:0.5097\n",
      "337/362 - mean:0.6262 - mean_absolute_error:0.5095\n",
      "338/362 - mean:0.6261 - mean_absolute_error:0.5096\n",
      "339/362 - mean:0.6262 - mean_absolute_error:0.5097\n",
      "340/362 - mean:0.6261 - mean_absolute_error:0.5098\n",
      "341/362 - mean:0.6271 - mean_absolute_error:0.5100\n",
      "342/362 - mean:0.6267 - mean_absolute_error:0.5099\n",
      "343/362 - mean:0.6260 - mean_absolute_error:0.5095\n",
      "344/362 - mean:0.6250 - mean_absolute_error:0.5089\n",
      "345/362 - mean:0.6250 - mean_absolute_error:0.5088\n",
      "346/362 - mean:0.6242 - mean_absolute_error:0.5083\n",
      "347/362 - mean:0.6246 - mean_absolute_error:0.5087\n",
      "348/362 - mean:0.6246 - mean_absolute_error:0.5087\n",
      "349/362 - mean:0.6243 - mean_absolute_error:0.5085\n",
      "350/362 - mean:0.6239 - mean_absolute_error:0.5084\n",
      "351/362 - mean:0.6248 - mean_absolute_error:0.5088\n",
      "352/362 - mean:0.6261 - mean_absolute_error:0.5093\n",
      "353/362 - mean:0.6258 - mean_absolute_error:0.5092\n",
      "354/362 - mean:0.6260 - mean_absolute_error:0.5095\n",
      "355/362 - mean:0.6258 - mean_absolute_error:0.5095\n",
      "356/362 - mean:0.6255 - mean_absolute_error:0.5094\n",
      "357/362 - mean:0.6254 - mean_absolute_error:0.5094\n",
      "358/362 - mean:0.6254 - mean_absolute_error:0.5093\n",
      "359/362 - mean:0.6251 - mean_absolute_error:0.5093\n",
      "360/362 - mean:0.6248 - mean_absolute_error:0.5092\n",
      "361/362 - mean:0.6241 - mean_absolute_error:0.5088\n",
      "362/362 - mean:0.6234 - mean_absolute_error:0.5084\n",
      "Epoch 4/5\n",
      "1/362 - mean:0.7476 - mean_absolute_error:0.5487\n",
      "2/362 - mean:0.7591 - mean_absolute_error:0.5638\n",
      "3/362 - mean:0.6927 - mean_absolute_error:0.5460\n",
      "4/362 - mean:0.6143 - mean_absolute_error:0.5058\n",
      "5/362 - mean:0.7086 - mean_absolute_error:0.5382\n",
      "6/362 - mean:0.7418 - mean_absolute_error:0.5600\n",
      "7/362 - mean:0.7410 - mean_absolute_error:0.5606\n",
      "8/362 - mean:0.7048 - mean_absolute_error:0.5379\n",
      "9/362 - mean:0.6883 - mean_absolute_error:0.5321\n",
      "10/362 - mean:0.6733 - mean_absolute_error:0.5329\n",
      "11/362 - mean:0.6622 - mean_absolute_error:0.5309\n",
      "12/362 - mean:0.6793 - mean_absolute_error:0.5456\n",
      "13/362 - mean:0.6602 - mean_absolute_error:0.5359\n",
      "14/362 - mean:0.6536 - mean_absolute_error:0.5341\n",
      "15/362 - mean:0.6590 - mean_absolute_error:0.5396\n",
      "16/362 - mean:0.6543 - mean_absolute_error:0.5403\n",
      "17/362 - mean:0.6484 - mean_absolute_error:0.5378\n",
      "18/362 - mean:0.6494 - mean_absolute_error:0.5394\n",
      "19/362 - mean:0.6531 - mean_absolute_error:0.5414\n",
      "20/362 - mean:0.6591 - mean_absolute_error:0.5458\n",
      "21/362 - mean:0.6728 - mean_absolute_error:0.5476\n",
      "22/362 - mean:0.6712 - mean_absolute_error:0.5458\n",
      "23/362 - mean:0.6630 - mean_absolute_error:0.5413\n",
      "24/362 - mean:0.6777 - mean_absolute_error:0.5459\n",
      "25/362 - mean:0.6683 - mean_absolute_error:0.5412\n",
      "26/362 - mean:0.6677 - mean_absolute_error:0.5423\n",
      "27/362 - mean:0.6604 - mean_absolute_error:0.5379\n",
      "28/362 - mean:0.6501 - mean_absolute_error:0.5322\n",
      "29/362 - mean:0.6513 - mean_absolute_error:0.5335\n",
      "30/362 - mean:0.6469 - mean_absolute_error:0.5295\n",
      "31/362 - mean:0.6405 - mean_absolute_error:0.5256\n",
      "32/362 - mean:0.6385 - mean_absolute_error:0.5247\n",
      "33/362 - mean:0.6602 - mean_absolute_error:0.5281\n",
      "34/362 - mean:0.6769 - mean_absolute_error:0.5350\n",
      "35/362 - mean:0.7047 - mean_absolute_error:0.5446\n",
      "36/362 - mean:0.7010 - mean_absolute_error:0.5430\n",
      "37/362 - mean:0.6984 - mean_absolute_error:0.5430\n",
      "38/362 - mean:0.6979 - mean_absolute_error:0.5429\n",
      "39/362 - mean:0.6902 - mean_absolute_error:0.5380\n",
      "40/362 - mean:0.6853 - mean_absolute_error:0.5353\n",
      "41/362 - mean:0.6835 - mean_absolute_error:0.5345\n",
      "42/362 - mean:0.6800 - mean_absolute_error:0.5332\n",
      "43/362 - mean:0.6765 - mean_absolute_error:0.5323\n",
      "44/362 - mean:0.6771 - mean_absolute_error:0.5329\n",
      "45/362 - mean:0.6703 - mean_absolute_error:0.5285\n",
      "46/362 - mean:0.6717 - mean_absolute_error:0.5292\n",
      "47/362 - mean:0.6694 - mean_absolute_error:0.5280\n",
      "48/362 - mean:0.6718 - mean_absolute_error:0.5279\n",
      "49/362 - mean:0.6716 - mean_absolute_error:0.5293\n",
      "50/362 - mean:0.6858 - mean_absolute_error:0.5301\n",
      "51/362 - mean:0.6852 - mean_absolute_error:0.5298\n",
      "52/362 - mean:0.6805 - mean_absolute_error:0.5282\n",
      "53/362 - mean:0.6790 - mean_absolute_error:0.5279\n",
      "54/362 - mean:0.6738 - mean_absolute_error:0.5253\n",
      "55/362 - mean:0.6752 - mean_absolute_error:0.5269\n",
      "56/362 - mean:0.6724 - mean_absolute_error:0.5261\n",
      "57/362 - mean:0.6729 - mean_absolute_error:0.5267\n",
      "58/362 - mean:0.6709 - mean_absolute_error:0.5251\n",
      "59/362 - mean:0.6668 - mean_absolute_error:0.5226\n",
      "60/362 - mean:0.6648 - mean_absolute_error:0.5212\n",
      "61/362 - mean:0.6619 - mean_absolute_error:0.5199\n",
      "62/362 - mean:0.6585 - mean_absolute_error:0.5184\n",
      "63/362 - mean:0.6603 - mean_absolute_error:0.5184\n",
      "64/362 - mean:0.6570 - mean_absolute_error:0.5167\n",
      "65/362 - mean:0.6543 - mean_absolute_error:0.5155\n",
      "66/362 - mean:0.6532 - mean_absolute_error:0.5147\n",
      "67/362 - mean:0.6543 - mean_absolute_error:0.5157\n",
      "68/362 - mean:0.6529 - mean_absolute_error:0.5154\n",
      "69/362 - mean:0.6521 - mean_absolute_error:0.5147\n",
      "70/362 - mean:0.6525 - mean_absolute_error:0.5152\n",
      "71/362 - mean:0.6560 - mean_absolute_error:0.5169\n",
      "72/362 - mean:0.6714 - mean_absolute_error:0.5196\n",
      "73/362 - mean:0.6706 - mean_absolute_error:0.5196\n",
      "74/362 - mean:0.6710 - mean_absolute_error:0.5205\n",
      "75/362 - mean:0.6693 - mean_absolute_error:0.5198\n",
      "76/362 - mean:0.6719 - mean_absolute_error:0.5215\n",
      "77/362 - mean:0.6723 - mean_absolute_error:0.5221\n",
      "78/362 - mean:0.6687 - mean_absolute_error:0.5209\n",
      "79/362 - mean:0.6688 - mean_absolute_error:0.5217\n",
      "80/362 - mean:0.6653 - mean_absolute_error:0.5198\n",
      "81/362 - mean:0.6655 - mean_absolute_error:0.5204\n",
      "82/362 - mean:0.6655 - mean_absolute_error:0.5204\n",
      "83/362 - mean:0.6694 - mean_absolute_error:0.5225\n",
      "84/362 - mean:0.6698 - mean_absolute_error:0.5233\n",
      "85/362 - mean:0.6679 - mean_absolute_error:0.5225\n",
      "86/362 - mean:0.6672 - mean_absolute_error:0.5228\n",
      "87/362 - mean:0.6680 - mean_absolute_error:0.5226\n",
      "88/362 - mean:0.6677 - mean_absolute_error:0.5228\n",
      "89/362 - mean:0.6669 - mean_absolute_error:0.5232\n",
      "90/362 - mean:0.6679 - mean_absolute_error:0.5238\n",
      "91/362 - mean:0.6675 - mean_absolute_error:0.5239\n",
      "92/362 - mean:0.6669 - mean_absolute_error:0.5234\n",
      "93/362 - mean:0.6675 - mean_absolute_error:0.5228\n",
      "94/362 - mean:0.6665 - mean_absolute_error:0.5227\n",
      "95/362 - mean:0.6659 - mean_absolute_error:0.5225\n",
      "96/362 - mean:0.6635 - mean_absolute_error:0.5213\n",
      "97/362 - mean:0.6636 - mean_absolute_error:0.5212\n",
      "98/362 - mean:0.6612 - mean_absolute_error:0.5207\n",
      "99/362 - mean:0.6589 - mean_absolute_error:0.5197\n",
      "100/362 - mean:0.6586 - mean_absolute_error:0.5200\n",
      "101/362 - mean:0.6565 - mean_absolute_error:0.5193\n",
      "102/362 - mean:0.6562 - mean_absolute_error:0.5192\n",
      "103/362 - mean:0.6589 - mean_absolute_error:0.5206\n",
      "104/362 - mean:0.6572 - mean_absolute_error:0.5200\n",
      "105/362 - mean:0.6552 - mean_absolute_error:0.5190\n",
      "106/362 - mean:0.6569 - mean_absolute_error:0.5196\n",
      "107/362 - mean:0.6563 - mean_absolute_error:0.5194\n",
      "108/362 - mean:0.6567 - mean_absolute_error:0.5200\n",
      "109/362 - mean:0.6557 - mean_absolute_error:0.5199\n",
      "110/362 - mean:0.6580 - mean_absolute_error:0.5211\n",
      "111/362 - mean:0.6553 - mean_absolute_error:0.5201\n",
      "112/362 - mean:0.6576 - mean_absolute_error:0.5213\n",
      "113/362 - mean:0.6553 - mean_absolute_error:0.5203\n",
      "114/362 - mean:0.6533 - mean_absolute_error:0.5193\n",
      "115/362 - mean:0.6516 - mean_absolute_error:0.5185\n",
      "116/362 - mean:0.6514 - mean_absolute_error:0.5183\n",
      "117/362 - mean:0.6517 - mean_absolute_error:0.5184\n",
      "118/362 - mean:0.6525 - mean_absolute_error:0.5188\n",
      "119/362 - mean:0.6538 - mean_absolute_error:0.5189\n",
      "120/362 - mean:0.6550 - mean_absolute_error:0.5192\n",
      "121/362 - mean:0.6551 - mean_absolute_error:0.5196\n",
      "122/362 - mean:0.6532 - mean_absolute_error:0.5186\n",
      "123/362 - mean:0.6515 - mean_absolute_error:0.5178\n",
      "124/362 - mean:0.6490 - mean_absolute_error:0.5164\n",
      "125/362 - mean:0.6505 - mean_absolute_error:0.5174\n",
      "126/362 - mean:0.6500 - mean_absolute_error:0.5173\n",
      "127/362 - mean:0.6510 - mean_absolute_error:0.5182\n",
      "128/362 - mean:0.6507 - mean_absolute_error:0.5179\n",
      "129/362 - mean:0.6506 - mean_absolute_error:0.5179\n",
      "130/362 - mean:0.6494 - mean_absolute_error:0.5176\n",
      "131/362 - mean:0.6501 - mean_absolute_error:0.5184\n",
      "132/362 - mean:0.6484 - mean_absolute_error:0.5176\n",
      "133/362 - mean:0.6478 - mean_absolute_error:0.5174\n",
      "134/362 - mean:0.6479 - mean_absolute_error:0.5177\n",
      "135/362 - mean:0.6475 - mean_absolute_error:0.5176\n",
      "136/362 - mean:0.6471 - mean_absolute_error:0.5175\n",
      "137/362 - mean:0.6458 - mean_absolute_error:0.5171\n",
      "138/362 - mean:0.6467 - mean_absolute_error:0.5174\n",
      "139/362 - mean:0.6451 - mean_absolute_error:0.5167\n",
      "140/362 - mean:0.6465 - mean_absolute_error:0.5178\n",
      "141/362 - mean:0.6476 - mean_absolute_error:0.5179\n",
      "142/362 - mean:0.6457 - mean_absolute_error:0.5172\n",
      "143/362 - mean:0.6451 - mean_absolute_error:0.5167\n",
      "144/362 - mean:0.6441 - mean_absolute_error:0.5164\n",
      "145/362 - mean:0.6463 - mean_absolute_error:0.5177\n",
      "146/362 - mean:0.6457 - mean_absolute_error:0.5177\n",
      "147/362 - mean:0.6472 - mean_absolute_error:0.5186\n",
      "148/362 - mean:0.6473 - mean_absolute_error:0.5191\n",
      "149/362 - mean:0.6453 - mean_absolute_error:0.5181\n",
      "150/362 - mean:0.6442 - mean_absolute_error:0.5175\n",
      "151/362 - mean:0.6480 - mean_absolute_error:0.5191\n",
      "152/362 - mean:0.6485 - mean_absolute_error:0.5195\n",
      "153/362 - mean:0.6483 - mean_absolute_error:0.5194\n",
      "154/362 - mean:0.6467 - mean_absolute_error:0.5184\n",
      "155/362 - mean:0.6509 - mean_absolute_error:0.5193\n",
      "156/362 - mean:0.6503 - mean_absolute_error:0.5192\n",
      "157/362 - mean:0.6495 - mean_absolute_error:0.5189\n",
      "158/362 - mean:0.6481 - mean_absolute_error:0.5181\n",
      "159/362 - mean:0.6480 - mean_absolute_error:0.5180\n",
      "160/362 - mean:0.6463 - mean_absolute_error:0.5172\n",
      "161/362 - mean:0.6449 - mean_absolute_error:0.5168\n",
      "162/362 - mean:0.6446 - mean_absolute_error:0.5164\n",
      "163/362 - mean:0.6445 - mean_absolute_error:0.5165\n",
      "164/362 - mean:0.6454 - mean_absolute_error:0.5170\n",
      "165/362 - mean:0.6440 - mean_absolute_error:0.5167\n",
      "166/362 - mean:0.6429 - mean_absolute_error:0.5163\n",
      "167/362 - mean:0.6427 - mean_absolute_error:0.5164\n",
      "168/362 - mean:0.6409 - mean_absolute_error:0.5155\n",
      "169/362 - mean:0.6404 - mean_absolute_error:0.5150\n",
      "170/362 - mean:0.6394 - mean_absolute_error:0.5149\n",
      "171/362 - mean:0.6395 - mean_absolute_error:0.5148\n",
      "172/362 - mean:0.6388 - mean_absolute_error:0.5145\n",
      "173/362 - mean:0.6387 - mean_absolute_error:0.5147\n",
      "174/362 - mean:0.6400 - mean_absolute_error:0.5153\n",
      "175/362 - mean:0.6417 - mean_absolute_error:0.5159\n",
      "176/362 - mean:0.6408 - mean_absolute_error:0.5155\n",
      "177/362 - mean:0.6424 - mean_absolute_error:0.5154\n",
      "178/362 - mean:0.6428 - mean_absolute_error:0.5160\n",
      "179/362 - mean:0.6417 - mean_absolute_error:0.5155\n",
      "180/362 - mean:0.6417 - mean_absolute_error:0.5155\n",
      "181/362 - mean:0.6440 - mean_absolute_error:0.5161\n",
      "182/362 - mean:0.6435 - mean_absolute_error:0.5159\n",
      "183/362 - mean:0.6433 - mean_absolute_error:0.5159\n",
      "184/362 - mean:0.6429 - mean_absolute_error:0.5159\n",
      "185/362 - mean:0.6430 - mean_absolute_error:0.5157\n",
      "186/362 - mean:0.6436 - mean_absolute_error:0.5158\n",
      "187/362 - mean:0.6452 - mean_absolute_error:0.5161\n",
      "188/362 - mean:0.6438 - mean_absolute_error:0.5156\n",
      "189/362 - mean:0.6432 - mean_absolute_error:0.5155\n",
      "190/362 - mean:0.6442 - mean_absolute_error:0.5161\n",
      "191/362 - mean:0.6437 - mean_absolute_error:0.5162\n",
      "192/362 - mean:0.6441 - mean_absolute_error:0.5166\n",
      "193/362 - mean:0.6441 - mean_absolute_error:0.5166\n",
      "194/362 - mean:0.6428 - mean_absolute_error:0.5162\n",
      "195/362 - mean:0.6411 - mean_absolute_error:0.5154\n",
      "196/362 - mean:0.6427 - mean_absolute_error:0.5161\n",
      "197/362 - mean:0.6439 - mean_absolute_error:0.5160\n",
      "198/362 - mean:0.6440 - mean_absolute_error:0.5162\n",
      "199/362 - mean:0.6433 - mean_absolute_error:0.5159\n",
      "200/362 - mean:0.6448 - mean_absolute_error:0.5165\n",
      "201/362 - mean:0.6461 - mean_absolute_error:0.5171\n",
      "202/362 - mean:0.6466 - mean_absolute_error:0.5174\n",
      "203/362 - mean:0.6461 - mean_absolute_error:0.5175\n",
      "204/362 - mean:0.6461 - mean_absolute_error:0.5176\n",
      "205/362 - mean:0.6474 - mean_absolute_error:0.5182\n",
      "206/362 - mean:0.6464 - mean_absolute_error:0.5178\n",
      "207/362 - mean:0.6463 - mean_absolute_error:0.5179\n",
      "208/362 - mean:0.6465 - mean_absolute_error:0.5184\n",
      "209/362 - mean:0.6462 - mean_absolute_error:0.5184\n",
      "210/362 - mean:0.6478 - mean_absolute_error:0.5192\n",
      "211/362 - mean:0.6475 - mean_absolute_error:0.5192\n",
      "212/362 - mean:0.6473 - mean_absolute_error:0.5193\n",
      "213/362 - mean:0.6481 - mean_absolute_error:0.5198\n",
      "214/362 - mean:0.6493 - mean_absolute_error:0.5203\n",
      "215/362 - mean:0.6487 - mean_absolute_error:0.5201\n",
      "216/362 - mean:0.6483 - mean_absolute_error:0.5201\n",
      "217/362 - mean:0.6481 - mean_absolute_error:0.5198\n",
      "218/362 - mean:0.6494 - mean_absolute_error:0.5205\n",
      "219/362 - mean:0.6497 - mean_absolute_error:0.5208\n",
      "220/362 - mean:0.6507 - mean_absolute_error:0.5213\n",
      "221/362 - mean:0.6510 - mean_absolute_error:0.5216\n",
      "222/362 - mean:0.6503 - mean_absolute_error:0.5216\n",
      "223/362 - mean:0.6490 - mean_absolute_error:0.5209\n",
      "224/362 - mean:0.6481 - mean_absolute_error:0.5204\n",
      "225/362 - mean:0.6477 - mean_absolute_error:0.5201\n",
      "226/362 - mean:0.6470 - mean_absolute_error:0.5200\n",
      "227/362 - mean:0.6459 - mean_absolute_error:0.5195\n",
      "228/362 - mean:0.6461 - mean_absolute_error:0.5195\n",
      "229/362 - mean:0.6460 - mean_absolute_error:0.5193\n",
      "230/362 - mean:0.6450 - mean_absolute_error:0.5188\n",
      "231/362 - mean:0.6455 - mean_absolute_error:0.5192\n",
      "232/362 - mean:0.6455 - mean_absolute_error:0.5190\n",
      "233/362 - mean:0.6444 - mean_absolute_error:0.5185\n",
      "234/362 - mean:0.6443 - mean_absolute_error:0.5185\n",
      "235/362 - mean:0.6440 - mean_absolute_error:0.5185\n",
      "236/362 - mean:0.6439 - mean_absolute_error:0.5186\n",
      "237/362 - mean:0.6438 - mean_absolute_error:0.5185\n",
      "238/362 - mean:0.6447 - mean_absolute_error:0.5186\n",
      "239/362 - mean:0.6441 - mean_absolute_error:0.5184\n",
      "240/362 - mean:0.6441 - mean_absolute_error:0.5186\n",
      "241/362 - mean:0.6436 - mean_absolute_error:0.5184\n",
      "242/362 - mean:0.6427 - mean_absolute_error:0.5179\n",
      "243/362 - mean:0.6428 - mean_absolute_error:0.5180\n",
      "244/362 - mean:0.6423 - mean_absolute_error:0.5178\n",
      "245/362 - mean:0.6425 - mean_absolute_error:0.5177\n",
      "246/362 - mean:0.6423 - mean_absolute_error:0.5177\n",
      "247/362 - mean:0.6419 - mean_absolute_error:0.5176\n",
      "248/362 - mean:0.6412 - mean_absolute_error:0.5173\n",
      "249/362 - mean:0.6410 - mean_absolute_error:0.5173\n",
      "250/362 - mean:0.6414 - mean_absolute_error:0.5176\n",
      "251/362 - mean:0.6413 - mean_absolute_error:0.5175\n",
      "252/362 - mean:0.6420 - mean_absolute_error:0.5177\n",
      "253/362 - mean:0.6418 - mean_absolute_error:0.5177\n",
      "254/362 - mean:0.6420 - mean_absolute_error:0.5180\n",
      "255/362 - mean:0.6425 - mean_absolute_error:0.5185\n",
      "256/362 - mean:0.6434 - mean_absolute_error:0.5189\n",
      "257/362 - mean:0.6431 - mean_absolute_error:0.5185\n",
      "258/362 - mean:0.6426 - mean_absolute_error:0.5182\n",
      "259/362 - mean:0.6418 - mean_absolute_error:0.5178\n",
      "260/362 - mean:0.6434 - mean_absolute_error:0.5182\n",
      "261/362 - mean:0.6430 - mean_absolute_error:0.5183\n",
      "262/362 - mean:0.6424 - mean_absolute_error:0.5180\n",
      "263/362 - mean:0.6425 - mean_absolute_error:0.5182\n",
      "264/362 - mean:0.6419 - mean_absolute_error:0.5180\n",
      "265/362 - mean:0.6410 - mean_absolute_error:0.5178\n",
      "266/362 - mean:0.6405 - mean_absolute_error:0.5176\n",
      "267/362 - mean:0.6398 - mean_absolute_error:0.5172\n",
      "268/362 - mean:0.6405 - mean_absolute_error:0.5172\n",
      "269/362 - mean:0.6400 - mean_absolute_error:0.5170\n",
      "270/362 - mean:0.6395 - mean_absolute_error:0.5169\n",
      "271/362 - mean:0.6389 - mean_absolute_error:0.5169\n",
      "272/362 - mean:0.6389 - mean_absolute_error:0.5171\n",
      "273/362 - mean:0.6384 - mean_absolute_error:0.5170\n",
      "274/362 - mean:0.6392 - mean_absolute_error:0.5172\n",
      "275/362 - mean:0.6394 - mean_absolute_error:0.5172\n",
      "276/362 - mean:0.6396 - mean_absolute_error:0.5173\n",
      "277/362 - mean:0.6398 - mean_absolute_error:0.5174\n",
      "278/362 - mean:0.6404 - mean_absolute_error:0.5176\n",
      "279/362 - mean:0.6399 - mean_absolute_error:0.5175\n",
      "280/362 - mean:0.6410 - mean_absolute_error:0.5178\n",
      "281/362 - mean:0.6402 - mean_absolute_error:0.5174\n",
      "282/362 - mean:0.6413 - mean_absolute_error:0.5172\n",
      "283/362 - mean:0.6408 - mean_absolute_error:0.5170\n",
      "284/362 - mean:0.6406 - mean_absolute_error:0.5171\n",
      "285/362 - mean:0.6416 - mean_absolute_error:0.5173\n",
      "286/362 - mean:0.6418 - mean_absolute_error:0.5177\n",
      "287/362 - mean:0.6414 - mean_absolute_error:0.5175\n",
      "288/362 - mean:0.6407 - mean_absolute_error:0.5171\n",
      "289/362 - mean:0.6401 - mean_absolute_error:0.5169\n",
      "290/362 - mean:0.6395 - mean_absolute_error:0.5165\n",
      "291/362 - mean:0.6397 - mean_absolute_error:0.5165\n",
      "292/362 - mean:0.6410 - mean_absolute_error:0.5169\n",
      "293/362 - mean:0.6402 - mean_absolute_error:0.5166\n",
      "294/362 - mean:0.6397 - mean_absolute_error:0.5165\n",
      "295/362 - mean:0.6392 - mean_absolute_error:0.5163\n",
      "296/362 - mean:0.6395 - mean_absolute_error:0.5164\n",
      "297/362 - mean:0.6396 - mean_absolute_error:0.5165\n",
      "298/362 - mean:0.6394 - mean_absolute_error:0.5164\n",
      "299/362 - mean:0.6393 - mean_absolute_error:0.5163\n",
      "300/362 - mean:0.6405 - mean_absolute_error:0.5167\n",
      "301/362 - mean:0.6414 - mean_absolute_error:0.5170\n",
      "302/362 - mean:0.6412 - mean_absolute_error:0.5170\n",
      "303/362 - mean:0.6403 - mean_absolute_error:0.5166\n",
      "304/362 - mean:0.6401 - mean_absolute_error:0.5167\n",
      "305/362 - mean:0.6403 - mean_absolute_error:0.5168\n",
      "306/362 - mean:0.6403 - mean_absolute_error:0.5168\n",
      "307/362 - mean:0.6395 - mean_absolute_error:0.5165\n",
      "308/362 - mean:0.6404 - mean_absolute_error:0.5170\n",
      "309/362 - mean:0.6395 - mean_absolute_error:0.5164\n",
      "310/362 - mean:0.6410 - mean_absolute_error:0.5172\n",
      "311/362 - mean:0.6427 - mean_absolute_error:0.5178\n",
      "312/362 - mean:0.6421 - mean_absolute_error:0.5176\n",
      "313/362 - mean:0.6421 - mean_absolute_error:0.5179\n",
      "314/362 - mean:0.6424 - mean_absolute_error:0.5181\n",
      "315/362 - mean:0.6432 - mean_absolute_error:0.5184\n",
      "316/362 - mean:0.6433 - mean_absolute_error:0.5186\n",
      "317/362 - mean:0.6430 - mean_absolute_error:0.5188\n",
      "318/362 - mean:0.6424 - mean_absolute_error:0.5186\n",
      "319/362 - mean:0.6415 - mean_absolute_error:0.5181\n",
      "320/362 - mean:0.6413 - mean_absolute_error:0.5182\n",
      "321/362 - mean:0.6417 - mean_absolute_error:0.5187\n",
      "322/362 - mean:0.6412 - mean_absolute_error:0.5184\n",
      "323/362 - mean:0.6421 - mean_absolute_error:0.5190\n",
      "324/362 - mean:0.6426 - mean_absolute_error:0.5194\n",
      "325/362 - mean:0.6421 - mean_absolute_error:0.5190\n",
      "326/362 - mean:0.6417 - mean_absolute_error:0.5189\n",
      "327/362 - mean:0.6410 - mean_absolute_error:0.5185\n",
      "328/362 - mean:0.6405 - mean_absolute_error:0.5184\n",
      "329/362 - mean:0.6402 - mean_absolute_error:0.5184\n",
      "330/362 - mean:0.6405 - mean_absolute_error:0.5186\n",
      "331/362 - mean:0.6400 - mean_absolute_error:0.5184\n",
      "332/362 - mean:0.6395 - mean_absolute_error:0.5179\n",
      "333/362 - mean:0.6397 - mean_absolute_error:0.5181\n",
      "334/362 - mean:0.6392 - mean_absolute_error:0.5179\n",
      "335/362 - mean:0.6394 - mean_absolute_error:0.5180\n",
      "336/362 - mean:0.6403 - mean_absolute_error:0.5182\n",
      "337/362 - mean:0.6402 - mean_absolute_error:0.5184\n",
      "338/362 - mean:0.6394 - mean_absolute_error:0.5180\n",
      "339/362 - mean:0.6391 - mean_absolute_error:0.5178\n",
      "340/362 - mean:0.6390 - mean_absolute_error:0.5180\n",
      "341/362 - mean:0.6382 - mean_absolute_error:0.5175\n",
      "342/362 - mean:0.6382 - mean_absolute_error:0.5177\n",
      "343/362 - mean:0.6381 - mean_absolute_error:0.5177\n",
      "344/362 - mean:0.6376 - mean_absolute_error:0.5174\n",
      "345/362 - mean:0.6371 - mean_absolute_error:0.5173\n",
      "346/362 - mean:0.6376 - mean_absolute_error:0.5173\n",
      "347/362 - mean:0.6373 - mean_absolute_error:0.5172\n",
      "348/362 - mean:0.6369 - mean_absolute_error:0.5170\n",
      "349/362 - mean:0.6378 - mean_absolute_error:0.5174\n",
      "350/362 - mean:0.6374 - mean_absolute_error:0.5171\n",
      "351/362 - mean:0.6380 - mean_absolute_error:0.5173\n",
      "352/362 - mean:0.6387 - mean_absolute_error:0.5178\n",
      "353/362 - mean:0.6420 - mean_absolute_error:0.5185\n",
      "354/362 - mean:0.6419 - mean_absolute_error:0.5184\n",
      "355/362 - mean:0.6411 - mean_absolute_error:0.5181\n",
      "356/362 - mean:0.6412 - mean_absolute_error:0.5182\n",
      "357/362 - mean:0.6420 - mean_absolute_error:0.5182\n",
      "358/362 - mean:0.6416 - mean_absolute_error:0.5180\n",
      "359/362 - mean:0.6409 - mean_absolute_error:0.5178\n",
      "360/362 - mean:0.6413 - mean_absolute_error:0.5180\n",
      "361/362 - mean:0.6419 - mean_absolute_error:0.5179\n",
      "362/362 - mean:0.6413 - mean_absolute_error:0.5178\n",
      "Epoch 5/5\n",
      "1/362 - mean:0.4692 - mean_absolute_error:0.4535\n",
      "2/362 - mean:0.4702 - mean_absolute_error:0.4275\n",
      "3/362 - mean:0.5888 - mean_absolute_error:0.4777\n",
      "4/362 - mean:0.5597 - mean_absolute_error:0.4715\n",
      "5/362 - mean:0.5814 - mean_absolute_error:0.4786\n",
      "6/362 - mean:0.6393 - mean_absolute_error:0.5126\n",
      "7/362 - mean:0.6035 - mean_absolute_error:0.4979\n",
      "8/362 - mean:0.5876 - mean_absolute_error:0.4996\n",
      "9/362 - mean:0.5724 - mean_absolute_error:0.4922\n",
      "10/362 - mean:0.6040 - mean_absolute_error:0.4965\n",
      "11/362 - mean:0.5859 - mean_absolute_error:0.4915\n",
      "12/362 - mean:0.5763 - mean_absolute_error:0.4875\n",
      "13/362 - mean:0.5811 - mean_absolute_error:0.4861\n",
      "14/362 - mean:0.5767 - mean_absolute_error:0.4829\n",
      "15/362 - mean:0.5759 - mean_absolute_error:0.4820\n",
      "16/362 - mean:0.5640 - mean_absolute_error:0.4768\n",
      "17/362 - mean:0.5541 - mean_absolute_error:0.4729\n",
      "18/362 - mean:0.5681 - mean_absolute_error:0.4811\n",
      "19/362 - mean:0.5905 - mean_absolute_error:0.4883\n",
      "20/362 - mean:0.5905 - mean_absolute_error:0.4890\n",
      "21/362 - mean:0.5853 - mean_absolute_error:0.4849\n",
      "22/362 - mean:0.5788 - mean_absolute_error:0.4835\n",
      "23/362 - mean:0.5772 - mean_absolute_error:0.4836\n",
      "24/362 - mean:0.5702 - mean_absolute_error:0.4821\n",
      "25/362 - mean:0.5837 - mean_absolute_error:0.4895\n",
      "26/362 - mean:0.5795 - mean_absolute_error:0.4876\n",
      "27/362 - mean:0.5765 - mean_absolute_error:0.4884\n",
      "28/362 - mean:0.5923 - mean_absolute_error:0.4942\n",
      "29/362 - mean:0.5930 - mean_absolute_error:0.4943\n",
      "30/362 - mean:0.5892 - mean_absolute_error:0.4922\n",
      "31/362 - mean:0.5894 - mean_absolute_error:0.4938\n",
      "32/362 - mean:0.5880 - mean_absolute_error:0.4938\n",
      "33/362 - mean:0.5929 - mean_absolute_error:0.4966\n",
      "34/362 - mean:0.5975 - mean_absolute_error:0.4993\n",
      "35/362 - mean:0.6080 - mean_absolute_error:0.5022\n",
      "36/362 - mean:0.6188 - mean_absolute_error:0.5070\n",
      "37/362 - mean:0.6290 - mean_absolute_error:0.5119\n",
      "38/362 - mean:0.6275 - mean_absolute_error:0.5106\n",
      "39/362 - mean:0.6232 - mean_absolute_error:0.5087\n",
      "40/362 - mean:0.6310 - mean_absolute_error:0.5142\n",
      "41/362 - mean:0.6361 - mean_absolute_error:0.5172\n",
      "42/362 - mean:0.6463 - mean_absolute_error:0.5226\n",
      "43/362 - mean:0.6403 - mean_absolute_error:0.5201\n",
      "44/362 - mean:0.6357 - mean_absolute_error:0.5185\n",
      "45/362 - mean:0.6368 - mean_absolute_error:0.5195\n",
      "46/362 - mean:0.6362 - mean_absolute_error:0.5206\n",
      "47/362 - mean:0.6385 - mean_absolute_error:0.5230\n",
      "48/362 - mean:0.6371 - mean_absolute_error:0.5226\n",
      "49/362 - mean:0.6419 - mean_absolute_error:0.5236\n",
      "50/362 - mean:0.6444 - mean_absolute_error:0.5246\n",
      "51/362 - mean:0.6482 - mean_absolute_error:0.5258\n",
      "52/362 - mean:0.6489 - mean_absolute_error:0.5268\n",
      "53/362 - mean:0.6479 - mean_absolute_error:0.5265\n",
      "54/362 - mean:0.6487 - mean_absolute_error:0.5276\n",
      "55/362 - mean:0.6470 - mean_absolute_error:0.5274\n",
      "56/362 - mean:0.6461 - mean_absolute_error:0.5273\n",
      "57/362 - mean:0.6445 - mean_absolute_error:0.5268\n",
      "58/362 - mean:0.6437 - mean_absolute_error:0.5277\n",
      "59/362 - mean:0.6421 - mean_absolute_error:0.5263\n",
      "60/362 - mean:0.6414 - mean_absolute_error:0.5269\n",
      "61/362 - mean:0.6416 - mean_absolute_error:0.5268\n",
      "62/362 - mean:0.6397 - mean_absolute_error:0.5253\n",
      "63/362 - mean:0.6399 - mean_absolute_error:0.5254\n",
      "64/362 - mean:0.6357 - mean_absolute_error:0.5230\n",
      "65/362 - mean:0.6305 - mean_absolute_error:0.5201\n",
      "66/362 - mean:0.6298 - mean_absolute_error:0.5193\n",
      "67/362 - mean:0.6289 - mean_absolute_error:0.5190\n",
      "68/362 - mean:0.6316 - mean_absolute_error:0.5193\n",
      "69/362 - mean:0.6298 - mean_absolute_error:0.5190\n",
      "70/362 - mean:0.6280 - mean_absolute_error:0.5175\n",
      "71/362 - mean:0.6319 - mean_absolute_error:0.5196\n",
      "72/362 - mean:0.6310 - mean_absolute_error:0.5190\n",
      "73/362 - mean:0.6321 - mean_absolute_error:0.5202\n",
      "74/362 - mean:0.6293 - mean_absolute_error:0.5187\n",
      "75/362 - mean:0.6324 - mean_absolute_error:0.5207\n",
      "76/362 - mean:0.6321 - mean_absolute_error:0.5209\n",
      "77/362 - mean:0.6336 - mean_absolute_error:0.5211\n",
      "78/362 - mean:0.6302 - mean_absolute_error:0.5190\n",
      "79/362 - mean:0.6325 - mean_absolute_error:0.5197\n",
      "80/362 - mean:0.6334 - mean_absolute_error:0.5205\n",
      "81/362 - mean:0.6328 - mean_absolute_error:0.5199\n",
      "82/362 - mean:0.6321 - mean_absolute_error:0.5196\n",
      "83/362 - mean:0.6314 - mean_absolute_error:0.5194\n",
      "84/362 - mean:0.6291 - mean_absolute_error:0.5184\n",
      "85/362 - mean:0.6309 - mean_absolute_error:0.5193\n",
      "86/362 - mean:0.6281 - mean_absolute_error:0.5179\n",
      "87/362 - mean:0.6277 - mean_absolute_error:0.5184\n",
      "88/362 - mean:0.6284 - mean_absolute_error:0.5183\n",
      "89/362 - mean:0.6274 - mean_absolute_error:0.5184\n",
      "90/362 - mean:0.6250 - mean_absolute_error:0.5170\n",
      "91/362 - mean:0.6254 - mean_absolute_error:0.5170\n",
      "92/362 - mean:0.6236 - mean_absolute_error:0.5162\n",
      "93/362 - mean:0.6277 - mean_absolute_error:0.5174\n",
      "94/362 - mean:0.6269 - mean_absolute_error:0.5171\n",
      "95/362 - mean:0.6244 - mean_absolute_error:0.5158\n",
      "96/362 - mean:0.6241 - mean_absolute_error:0.5154\n",
      "97/362 - mean:0.6245 - mean_absolute_error:0.5154\n",
      "98/362 - mean:0.6227 - mean_absolute_error:0.5144\n",
      "99/362 - mean:0.6216 - mean_absolute_error:0.5141\n",
      "100/362 - mean:0.6238 - mean_absolute_error:0.5151\n",
      "101/362 - mean:0.6236 - mean_absolute_error:0.5141\n",
      "102/362 - mean:0.6273 - mean_absolute_error:0.5152\n",
      "103/362 - mean:0.6278 - mean_absolute_error:0.5154\n",
      "104/362 - mean:0.6298 - mean_absolute_error:0.5162\n",
      "105/362 - mean:0.6310 - mean_absolute_error:0.5172\n",
      "106/362 - mean:0.6292 - mean_absolute_error:0.5166\n",
      "107/362 - mean:0.6299 - mean_absolute_error:0.5169\n",
      "108/362 - mean:0.6288 - mean_absolute_error:0.5166\n",
      "109/362 - mean:0.6277 - mean_absolute_error:0.5161\n",
      "110/362 - mean:0.6271 - mean_absolute_error:0.5161\n",
      "111/362 - mean:0.6275 - mean_absolute_error:0.5163\n",
      "112/362 - mean:0.6277 - mean_absolute_error:0.5165\n",
      "113/362 - mean:0.6252 - mean_absolute_error:0.5150\n",
      "114/362 - mean:0.6237 - mean_absolute_error:0.5145\n",
      "115/362 - mean:0.6219 - mean_absolute_error:0.5133\n",
      "116/362 - mean:0.6216 - mean_absolute_error:0.5136\n",
      "117/362 - mean:0.6209 - mean_absolute_error:0.5133\n",
      "118/362 - mean:0.6221 - mean_absolute_error:0.5134\n",
      "119/362 - mean:0.6209 - mean_absolute_error:0.5133\n",
      "120/362 - mean:0.6219 - mean_absolute_error:0.5140\n",
      "121/362 - mean:0.6213 - mean_absolute_error:0.5134\n",
      "122/362 - mean:0.6210 - mean_absolute_error:0.5134\n",
      "123/362 - mean:0.6216 - mean_absolute_error:0.5139\n",
      "124/362 - mean:0.6263 - mean_absolute_error:0.5161\n",
      "125/362 - mean:0.6257 - mean_absolute_error:0.5160\n",
      "126/362 - mean:0.6261 - mean_absolute_error:0.5165\n",
      "127/362 - mean:0.6285 - mean_absolute_error:0.5171\n",
      "128/362 - mean:0.6303 - mean_absolute_error:0.5181\n",
      "129/362 - mean:0.6291 - mean_absolute_error:0.5177\n",
      "130/362 - mean:0.6283 - mean_absolute_error:0.5173\n",
      "131/362 - mean:0.6293 - mean_absolute_error:0.5171\n",
      "132/362 - mean:0.6282 - mean_absolute_error:0.5164\n",
      "133/362 - mean:0.6280 - mean_absolute_error:0.5162\n",
      "134/362 - mean:0.6279 - mean_absolute_error:0.5159\n",
      "135/362 - mean:0.6282 - mean_absolute_error:0.5159\n",
      "136/362 - mean:0.6280 - mean_absolute_error:0.5157\n",
      "137/362 - mean:0.6290 - mean_absolute_error:0.5160\n",
      "138/362 - mean:0.6285 - mean_absolute_error:0.5158\n",
      "139/362 - mean:0.6280 - mean_absolute_error:0.5154\n",
      "140/362 - mean:0.6283 - mean_absolute_error:0.5158\n",
      "141/362 - mean:0.6283 - mean_absolute_error:0.5159\n",
      "142/362 - mean:0.6273 - mean_absolute_error:0.5154\n",
      "143/362 - mean:0.6263 - mean_absolute_error:0.5149\n",
      "144/362 - mean:0.6255 - mean_absolute_error:0.5144\n",
      "145/362 - mean:0.6262 - mean_absolute_error:0.5142\n",
      "146/362 - mean:0.6284 - mean_absolute_error:0.5151\n",
      "147/362 - mean:0.6305 - mean_absolute_error:0.5164\n",
      "148/362 - mean:0.6292 - mean_absolute_error:0.5160\n",
      "149/362 - mean:0.6317 - mean_absolute_error:0.5162\n",
      "150/362 - mean:0.6305 - mean_absolute_error:0.5159\n",
      "151/362 - mean:0.6296 - mean_absolute_error:0.5153\n",
      "152/362 - mean:0.6290 - mean_absolute_error:0.5152\n",
      "153/362 - mean:0.6291 - mean_absolute_error:0.5153\n",
      "154/362 - mean:0.6271 - mean_absolute_error:0.5140\n",
      "155/362 - mean:0.6261 - mean_absolute_error:0.5136\n",
      "156/362 - mean:0.6253 - mean_absolute_error:0.5133\n",
      "157/362 - mean:0.6252 - mean_absolute_error:0.5130\n",
      "158/362 - mean:0.6252 - mean_absolute_error:0.5130\n",
      "159/362 - mean:0.6231 - mean_absolute_error:0.5118\n",
      "160/362 - mean:0.6250 - mean_absolute_error:0.5119\n",
      "161/362 - mean:0.6244 - mean_absolute_error:0.5115\n",
      "162/362 - mean:0.6238 - mean_absolute_error:0.5111\n",
      "163/362 - mean:0.6241 - mean_absolute_error:0.5113\n",
      "164/362 - mean:0.6254 - mean_absolute_error:0.5113\n",
      "165/362 - mean:0.6253 - mean_absolute_error:0.5116\n",
      "166/362 - mean:0.6250 - mean_absolute_error:0.5113\n",
      "167/362 - mean:0.6246 - mean_absolute_error:0.5114\n",
      "168/362 - mean:0.6229 - mean_absolute_error:0.5104\n",
      "169/362 - mean:0.6230 - mean_absolute_error:0.5109\n",
      "170/362 - mean:0.6237 - mean_absolute_error:0.5116\n",
      "171/362 - mean:0.6222 - mean_absolute_error:0.5108\n",
      "172/362 - mean:0.6225 - mean_absolute_error:0.5110\n",
      "173/362 - mean:0.6210 - mean_absolute_error:0.5104\n",
      "174/362 - mean:0.6244 - mean_absolute_error:0.5115\n",
      "175/362 - mean:0.6241 - mean_absolute_error:0.5112\n",
      "176/362 - mean:0.6244 - mean_absolute_error:0.5113\n",
      "177/362 - mean:0.6234 - mean_absolute_error:0.5108\n",
      "178/362 - mean:0.6239 - mean_absolute_error:0.5112\n",
      "179/362 - mean:0.6239 - mean_absolute_error:0.5112\n",
      "180/362 - mean:0.6259 - mean_absolute_error:0.5122\n",
      "181/362 - mean:0.6258 - mean_absolute_error:0.5119\n",
      "182/362 - mean:0.6256 - mean_absolute_error:0.5120\n",
      "183/362 - mean:0.6277 - mean_absolute_error:0.5132\n",
      "184/362 - mean:0.6285 - mean_absolute_error:0.5135\n",
      "185/362 - mean:0.6288 - mean_absolute_error:0.5140\n",
      "186/362 - mean:0.6285 - mean_absolute_error:0.5140\n",
      "187/362 - mean:0.6273 - mean_absolute_error:0.5134\n",
      "188/362 - mean:0.6271 - mean_absolute_error:0.5134\n",
      "189/362 - mean:0.6264 - mean_absolute_error:0.5131\n",
      "190/362 - mean:0.6260 - mean_absolute_error:0.5129\n",
      "191/362 - mean:0.6262 - mean_absolute_error:0.5128\n",
      "192/362 - mean:0.6275 - mean_absolute_error:0.5133\n",
      "193/362 - mean:0.6302 - mean_absolute_error:0.5141\n",
      "194/362 - mean:0.6302 - mean_absolute_error:0.5141\n",
      "195/362 - mean:0.6302 - mean_absolute_error:0.5138\n",
      "196/362 - mean:0.6291 - mean_absolute_error:0.5132\n",
      "197/362 - mean:0.6291 - mean_absolute_error:0.5134\n",
      "198/362 - mean:0.6290 - mean_absolute_error:0.5133\n",
      "199/362 - mean:0.6285 - mean_absolute_error:0.5134\n",
      "200/362 - mean:0.6291 - mean_absolute_error:0.5135\n",
      "201/362 - mean:0.6286 - mean_absolute_error:0.5133\n",
      "202/362 - mean:0.6275 - mean_absolute_error:0.5128\n",
      "203/362 - mean:0.6270 - mean_absolute_error:0.5127\n",
      "204/362 - mean:0.6286 - mean_absolute_error:0.5135\n",
      "205/362 - mean:0.6284 - mean_absolute_error:0.5134\n",
      "206/362 - mean:0.6292 - mean_absolute_error:0.5139\n",
      "207/362 - mean:0.6286 - mean_absolute_error:0.5136\n",
      "208/362 - mean:0.6295 - mean_absolute_error:0.5141\n",
      "209/362 - mean:0.6287 - mean_absolute_error:0.5137\n",
      "210/362 - mean:0.6277 - mean_absolute_error:0.5133\n",
      "211/362 - mean:0.6283 - mean_absolute_error:0.5134\n",
      "212/362 - mean:0.6291 - mean_absolute_error:0.5137\n",
      "213/362 - mean:0.6300 - mean_absolute_error:0.5143\n",
      "214/362 - mean:0.6293 - mean_absolute_error:0.5138\n",
      "215/362 - mean:0.6287 - mean_absolute_error:0.5137\n",
      "216/362 - mean:0.6291 - mean_absolute_error:0.5140\n",
      "217/362 - mean:0.6292 - mean_absolute_error:0.5140\n",
      "218/362 - mean:0.6285 - mean_absolute_error:0.5138\n",
      "219/362 - mean:0.6280 - mean_absolute_error:0.5135\n",
      "220/362 - mean:0.6276 - mean_absolute_error:0.5135\n",
      "221/362 - mean:0.6262 - mean_absolute_error:0.5127\n",
      "222/362 - mean:0.6273 - mean_absolute_error:0.5132\n",
      "223/362 - mean:0.6265 - mean_absolute_error:0.5128\n",
      "224/362 - mean:0.6270 - mean_absolute_error:0.5130\n",
      "225/362 - mean:0.6266 - mean_absolute_error:0.5129\n",
      "226/362 - mean:0.6261 - mean_absolute_error:0.5128\n",
      "227/362 - mean:0.6260 - mean_absolute_error:0.5126\n",
      "228/362 - mean:0.6250 - mean_absolute_error:0.5122\n",
      "229/362 - mean:0.6248 - mean_absolute_error:0.5121\n",
      "230/362 - mean:0.6251 - mean_absolute_error:0.5120\n",
      "231/362 - mean:0.6255 - mean_absolute_error:0.5125\n",
      "232/362 - mean:0.6248 - mean_absolute_error:0.5122\n",
      "233/362 - mean:0.6243 - mean_absolute_error:0.5120\n",
      "234/362 - mean:0.6262 - mean_absolute_error:0.5129\n",
      "235/362 - mean:0.6257 - mean_absolute_error:0.5128\n",
      "236/362 - mean:0.6249 - mean_absolute_error:0.5125\n",
      "237/362 - mean:0.6271 - mean_absolute_error:0.5130\n",
      "238/362 - mean:0.6267 - mean_absolute_error:0.5130\n",
      "239/362 - mean:0.6264 - mean_absolute_error:0.5129\n",
      "240/362 - mean:0.6260 - mean_absolute_error:0.5126\n",
      "241/362 - mean:0.6262 - mean_absolute_error:0.5129\n",
      "242/362 - mean:0.6255 - mean_absolute_error:0.5127\n",
      "243/362 - mean:0.6262 - mean_absolute_error:0.5128\n",
      "244/362 - mean:0.6260 - mean_absolute_error:0.5126\n",
      "245/362 - mean:0.6253 - mean_absolute_error:0.5121\n",
      "246/362 - mean:0.6252 - mean_absolute_error:0.5121\n",
      "247/362 - mean:0.6247 - mean_absolute_error:0.5119\n",
      "248/362 - mean:0.6239 - mean_absolute_error:0.5117\n",
      "249/362 - mean:0.6255 - mean_absolute_error:0.5121\n",
      "250/362 - mean:0.6250 - mean_absolute_error:0.5119\n",
      "251/362 - mean:0.6247 - mean_absolute_error:0.5119\n",
      "252/362 - mean:0.6248 - mean_absolute_error:0.5119\n",
      "253/362 - mean:0.6265 - mean_absolute_error:0.5121\n",
      "254/362 - mean:0.6268 - mean_absolute_error:0.5124\n",
      "255/362 - mean:0.6266 - mean_absolute_error:0.5125\n",
      "256/362 - mean:0.6260 - mean_absolute_error:0.5122\n",
      "257/362 - mean:0.6254 - mean_absolute_error:0.5120\n",
      "258/362 - mean:0.6261 - mean_absolute_error:0.5123\n",
      "259/362 - mean:0.6253 - mean_absolute_error:0.5120\n",
      "260/362 - mean:0.6251 - mean_absolute_error:0.5120\n",
      "261/362 - mean:0.6253 - mean_absolute_error:0.5118\n",
      "262/362 - mean:0.6255 - mean_absolute_error:0.5120\n",
      "263/362 - mean:0.6259 - mean_absolute_error:0.5123\n",
      "264/362 - mean:0.6266 - mean_absolute_error:0.5127\n",
      "265/362 - mean:0.6259 - mean_absolute_error:0.5123\n",
      "266/362 - mean:0.6269 - mean_absolute_error:0.5126\n",
      "267/362 - mean:0.6266 - mean_absolute_error:0.5124\n",
      "268/362 - mean:0.6260 - mean_absolute_error:0.5123\n",
      "269/362 - mean:0.6260 - mean_absolute_error:0.5122\n",
      "270/362 - mean:0.6264 - mean_absolute_error:0.5123\n",
      "271/362 - mean:0.6275 - mean_absolute_error:0.5129\n",
      "272/362 - mean:0.6275 - mean_absolute_error:0.5127\n",
      "273/362 - mean:0.6279 - mean_absolute_error:0.5128\n",
      "274/362 - mean:0.6284 - mean_absolute_error:0.5132\n",
      "275/362 - mean:0.6276 - mean_absolute_error:0.5130\n",
      "276/362 - mean:0.6290 - mean_absolute_error:0.5136\n",
      "277/362 - mean:0.6280 - mean_absolute_error:0.5131\n",
      "278/362 - mean:0.6283 - mean_absolute_error:0.5134\n",
      "279/362 - mean:0.6283 - mean_absolute_error:0.5133\n",
      "280/362 - mean:0.6284 - mean_absolute_error:0.5133\n",
      "281/362 - mean:0.6312 - mean_absolute_error:0.5135\n",
      "282/362 - mean:0.6312 - mean_absolute_error:0.5132\n",
      "283/362 - mean:0.6308 - mean_absolute_error:0.5130\n",
      "284/362 - mean:0.6313 - mean_absolute_error:0.5132\n",
      "285/362 - mean:0.6306 - mean_absolute_error:0.5128\n",
      "286/362 - mean:0.6306 - mean_absolute_error:0.5128\n",
      "287/362 - mean:0.6301 - mean_absolute_error:0.5127\n",
      "288/362 - mean:0.6312 - mean_absolute_error:0.5133\n",
      "289/362 - mean:0.6321 - mean_absolute_error:0.5136\n",
      "290/362 - mean:0.6316 - mean_absolute_error:0.5135\n",
      "291/362 - mean:0.6325 - mean_absolute_error:0.5140\n",
      "292/362 - mean:0.6330 - mean_absolute_error:0.5145\n",
      "293/362 - mean:0.6326 - mean_absolute_error:0.5144\n",
      "294/362 - mean:0.6332 - mean_absolute_error:0.5147\n",
      "295/362 - mean:0.6331 - mean_absolute_error:0.5147\n",
      "296/362 - mean:0.6339 - mean_absolute_error:0.5153\n",
      "297/362 - mean:0.6348 - mean_absolute_error:0.5155\n",
      "298/362 - mean:0.6343 - mean_absolute_error:0.5154\n",
      "299/362 - mean:0.6354 - mean_absolute_error:0.5157\n",
      "300/362 - mean:0.6350 - mean_absolute_error:0.5157\n",
      "301/362 - mean:0.6353 - mean_absolute_error:0.5159\n",
      "302/362 - mean:0.6352 - mean_absolute_error:0.5159\n",
      "303/362 - mean:0.6349 - mean_absolute_error:0.5158\n",
      "304/362 - mean:0.6343 - mean_absolute_error:0.5156\n",
      "305/362 - mean:0.6342 - mean_absolute_error:0.5155\n",
      "306/362 - mean:0.6341 - mean_absolute_error:0.5154\n",
      "307/362 - mean:0.6334 - mean_absolute_error:0.5151\n",
      "308/362 - mean:0.6330 - mean_absolute_error:0.5148\n",
      "309/362 - mean:0.6333 - mean_absolute_error:0.5150\n",
      "310/362 - mean:0.6334 - mean_absolute_error:0.5150\n",
      "311/362 - mean:0.6334 - mean_absolute_error:0.5150\n",
      "312/362 - mean:0.6348 - mean_absolute_error:0.5153\n",
      "313/362 - mean:0.6353 - mean_absolute_error:0.5155\n",
      "314/362 - mean:0.6351 - mean_absolute_error:0.5155\n",
      "315/362 - mean:0.6346 - mean_absolute_error:0.5153\n",
      "316/362 - mean:0.6343 - mean_absolute_error:0.5151\n",
      "317/362 - mean:0.6346 - mean_absolute_error:0.5153\n",
      "318/362 - mean:0.6353 - mean_absolute_error:0.5157\n",
      "319/362 - mean:0.6344 - mean_absolute_error:0.5152\n",
      "320/362 - mean:0.6344 - mean_absolute_error:0.5153\n",
      "321/362 - mean:0.6341 - mean_absolute_error:0.5152\n",
      "322/362 - mean:0.6337 - mean_absolute_error:0.5150\n",
      "323/362 - mean:0.6353 - mean_absolute_error:0.5155\n",
      "324/362 - mean:0.6357 - mean_absolute_error:0.5157\n",
      "325/362 - mean:0.6364 - mean_absolute_error:0.5157\n",
      "326/362 - mean:0.6361 - mean_absolute_error:0.5157\n",
      "327/362 - mean:0.6358 - mean_absolute_error:0.5155\n",
      "328/362 - mean:0.6353 - mean_absolute_error:0.5152\n",
      "329/362 - mean:0.6356 - mean_absolute_error:0.5154\n",
      "330/362 - mean:0.6357 - mean_absolute_error:0.5155\n",
      "331/362 - mean:0.6352 - mean_absolute_error:0.5153\n",
      "332/362 - mean:0.6355 - mean_absolute_error:0.5154\n",
      "333/362 - mean:0.6357 - mean_absolute_error:0.5157\n",
      "334/362 - mean:0.6364 - mean_absolute_error:0.5159\n",
      "335/362 - mean:0.6359 - mean_absolute_error:0.5157\n",
      "336/362 - mean:0.6360 - mean_absolute_error:0.5158\n",
      "337/362 - mean:0.6362 - mean_absolute_error:0.5160\n",
      "338/362 - mean:0.6359 - mean_absolute_error:0.5160\n",
      "339/362 - mean:0.6374 - mean_absolute_error:0.5165\n",
      "340/362 - mean:0.6383 - mean_absolute_error:0.5171\n",
      "341/362 - mean:0.6391 - mean_absolute_error:0.5174\n",
      "342/362 - mean:0.6388 - mean_absolute_error:0.5173\n",
      "343/362 - mean:0.6389 - mean_absolute_error:0.5174\n",
      "344/362 - mean:0.6389 - mean_absolute_error:0.5174\n",
      "345/362 - mean:0.6386 - mean_absolute_error:0.5175\n",
      "346/362 - mean:0.6382 - mean_absolute_error:0.5175\n",
      "347/362 - mean:0.6380 - mean_absolute_error:0.5174\n",
      "348/362 - mean:0.6387 - mean_absolute_error:0.5179\n",
      "349/362 - mean:0.6391 - mean_absolute_error:0.5180\n",
      "350/362 - mean:0.6393 - mean_absolute_error:0.5183\n",
      "351/362 - mean:0.6392 - mean_absolute_error:0.5182\n",
      "352/362 - mean:0.6398 - mean_absolute_error:0.5186\n",
      "353/362 - mean:0.6404 - mean_absolute_error:0.5188\n",
      "354/362 - mean:0.6397 - mean_absolute_error:0.5185\n",
      "355/362 - mean:0.6402 - mean_absolute_error:0.5186\n",
      "356/362 - mean:0.6402 - mean_absolute_error:0.5188\n",
      "357/362 - mean:0.6411 - mean_absolute_error:0.5188\n",
      "358/362 - mean:0.6411 - mean_absolute_error:0.5190\n",
      "359/362 - mean:0.6422 - mean_absolute_error:0.5193\n",
      "360/362 - mean:0.6420 - mean_absolute_error:0.5194\n",
      "361/362 - mean:0.6418 - mean_absolute_error:0.5192\n",
      "362/362 - mean:0.6415 - mean_absolute_error:0.5190\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch, training=True)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # extra code – if your model has variable constraints\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "\n",
    "        print_status_bar(step, n_steps, mean_loss, metrics)\n",
    "\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow Functions and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cube(x):\n",
    "    return x**3\n",
    "cube(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x161f28b50>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube.python_function(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow functions and concrete functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction (x: TensorSpec(shape=(), dtype=tf.float32, name=None)) -> TensorSpec(shape=(), dtype=tf.float32, name=None) at 0x306E5A6D0>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "concrete_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function is tf_cube.get_concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring Functions Definiations of Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x161f27540>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = concrete_function.graph.get_operations()\n",
    "ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'pow/y:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op = ops[2]\n",
    "list(pow_op.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_pytorcch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
