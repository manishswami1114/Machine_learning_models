{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e919825",
   "metadata": {},
   "source": [
    "# Using LangGraph to Add Memory to Your Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d117f76",
   "metadata": {},
   "source": [
    "## Building a ChatBot Memory System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a153dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user asked, \"What is the capital of France?\" and I responded with \"The capital of France is Paris.\" Now they\\'re asking, \"What did you say just now?\" Let me make sure I understand their question correctly.\\n\\nThey want to know what I said in the previous message. Since I just provided the answer, I need to confirm that. The user might be checking if I remembered the correct answer or if there\\'s any confusion. I should restate the answer clearly to ensure they understand. Also, maybe they want to verify if my response was accurate. I should keep it simple and straightforward, just reiterating the information without any extra details. Let me make sure the response is polite and helpful.\\n</think>\\n\\nYou asked, \"What did you say just now?\"  \\nI replied, \"The capital of France is Paris.\"  \\nLet me know if you need further clarification! ðŸ˜Š'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"\"\"You are a helpful assistant that can answer questions and help with tasks.\"\"\"),\n",
    "    ('placeholder',\"{messages}\")\n",
    "])\n",
    "model  = OllamaLLM(model='qwen3:1.7b')\n",
    "chain = prompt|model\n",
    "chain.invoke({\n",
    "    \"messages\":[\n",
    "        (\"human\",\"What is the capital of France?\"),\n",
    "        (\"ai\",\"The capital of France is Paris.\"),\n",
    "        (\"human\",\"what did you say just now?\")\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e09ef6",
   "metadata": {},
   "source": [
    "***While this is simple and it works, when taking your application to production,youâ€™ll*** ***facesomemore challenges related to managing memory at scale, such as:***\n",
    "\n",
    "Youâ€™ll need to update the memory after every interaction, atomically (i.e.,\n",
    "donâ€™t record only the question or only the answer in the case of failure).\n",
    "\n",
    "Youâ€™ll want to store these memories in durable storage, such as a relational\n",
    "database.\n",
    "\n",
    "Youâ€™ll want to control how many and which messages are stored for later, and\n",
    "how many of these are used for new interactions.\n",
    "\n",
    "Youâ€™ll want to inspect and modify this state (for now, just a list of messages)\n",
    "outside a call to an LLM.\n",
    "\n",
    "Weâ€™ll now introduce some better tooling, which will help with this and all later\n",
    "chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9f0f80",
   "metadata": {},
   "source": [
    "### Langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95610dc",
   "metadata": {},
   "source": [
    "#### Creating a StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "786f0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated , TypedDict\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages:Annotated[list,add_messages]\n",
    "builder = StateGraph(State) # Create a state graph with name builder\n",
    "model=OllamaLLM(model=\"qwen3:1.7b\")\n",
    "\n",
    "def chatbot(state:State):\n",
    "    answer = model.invoke(state['messages'])\n",
    "    return {'messages':[answer]}\n",
    "\n",
    "\n",
    "builder.add_node('chatbot',chatbot) # Add a node to the graph\n",
    "\n",
    "builder.add_edge(START,'chatbot') # Add an edge from the start node to the chatbot node\n",
    "\n",
    "builder.add_edge('chatbot',END) # Add an edge from the chatbot node to the end node\n",
    "\n",
    "graph = builder.compile() # Compile the graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6f8918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get PNG OF graph  \n",
    "from IPython.display import Image, display\n",
    "\n",
    "png_bytes = graph.get_graph().draw_mermaid_png()\n",
    "display(Image(png_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acb5ac57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chatbot': {'messages': ['<think>\\nOkay, the user said \"hi!\" so I need to respond politely. Let me make sure my reply is friendly and open-ended. Maybe ask how they\\'re doing? That\\'s a common way to start a conversation. I should keep it simple and not too formal. Let me check for any grammar issues. Yep, looks good. Alright, time to send the response.\\n</think>\\n\\nHi! How are you doing today? ðŸ˜Š I\\'m doing great, thanks! How about you?']}}\n"
     ]
    }
   ],
   "source": [
    "input = {'messages':[HumanMessage('hi!')]}\n",
    "for chunk in graph.stream(input):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d3fac",
   "metadata": {},
   "source": [
    "#### Adding Memory to LangGraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b36857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "graph = builder.compile(checkpointer = MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e74dbd6",
   "metadata": {},
   "source": [
    "**below code used as memory to chatbot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89524f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='hi, my name is manish', additional_kwargs={}, response_metadata={}, id='1ad8d702-4bc4-498f-89c0-d318a544773f'), HumanMessage(content='<think>\\nOkay, the user said, \"hi, my name is manish.\" So they\\'re introducing themselves. I need to respond in a friendly and helpful way.\\n\\nFirst, I should acknowledge their greeting. Maybe say \"Hello!\" to be polite. Then ask how they\\'re doing. \"How are you today?\" is a common question. \\n\\nThey mentioned their name, so I can add that to the response. \"My name is Manish\" â€“ maybe use their name as is, but the user wrote \"manish\" with an \\'m\\' and \\'a\\'... Wait, the user wrote \"manish\" with an \\'m\\' and \\'a\\'? Wait, no, the user wrote \"manish\" â€“ let me check. The original message was \"hi, my name is manish\". So \"manish\" is spelled with an \\'m\\' and \\'a\\'... Wait, no, actually, \"manish\" is spelled M-A-N-I-S-H. So the user wrote \"manish\" with an \\'m\\' and \\'a\\'... Wait, no, \"manish\" is spelled M-A-N-I-S-H. So the user\\'s name is Manish. So I should use their name as is. \\n\\nSo the response should be something like: \"Hello, Manish! How are you today? I\\'m doing well, thanks! Let me know if there\\'s anything I can help with.\" \\n\\nBut maybe the user wants a more casual response. Let me check the initial message again. The user just said \"hi, my name is manish\" â€“ so they\\'re probably looking for a simple, friendly reply. \\n\\nI should make sure to use their name correctly. \"Manish\" is the correct spelling. So the response should be in that format. \\n\\nAlso, maybe add an emoji to keep it friendly. Like a smiley face. \\n\\nSo the final response would be: \"Hello, Manish! How are you today? I\\'m doing well, thanks! Let me know if there\\'s anything I can help with. ðŸ˜Š\"\\n</think>\\n\\nHello, Manish! How are you today? I\\'m doing well, thanks! Let me know if there\\'s anything I can help with. ðŸ˜Š', additional_kwargs={}, response_metadata={}, id='48d4799b-68dd-4ed1-a1b0-13f65afd1d83')]}\n",
      "{'messages': [HumanMessage(content='hi, my name is manish', additional_kwargs={}, response_metadata={}, id='1ad8d702-4bc4-498f-89c0-d318a544773f'), HumanMessage(content='<think>\\nOkay, the user said, \"hi, my name is manish.\" So they\\'re introducing themselves. I need to respond in a friendly and helpful way.\\n\\nFirst, I should acknowledge their greeting. Maybe say \"Hello!\" to be polite. Then ask how they\\'re doing. \"How are you today?\" is a common question. \\n\\nThey mentioned their name, so I can add that to the response. \"My name is Manish\" â€“ maybe use their name as is, but the user wrote \"manish\" with an \\'m\\' and \\'a\\'... Wait, the user wrote \"manish\" with an \\'m\\' and \\'a\\'? Wait, no, the user wrote \"manish\" â€“ let me check. The original message was \"hi, my name is manish\". So \"manish\" is spelled with an \\'m\\' and \\'a\\'... Wait, no, actually, \"manish\" is spelled M-A-N-I-S-H. So the user wrote \"manish\" with an \\'m\\' and \\'a\\'... Wait, no, \"manish\" is spelled M-A-N-I-S-H. So the user\\'s name is Manish. So I should use their name as is. \\n\\nSo the response should be something like: \"Hello, Manish! How are you today? I\\'m doing well, thanks! Let me know if there\\'s anything I can help with.\" \\n\\nBut maybe the user wants a more casual response. Let me check the initial message again. The user just said \"hi, my name is manish\" â€“ so they\\'re probably looking for a simple, friendly reply. \\n\\nI should make sure to use their name correctly. \"Manish\" is the correct spelling. So the response should be in that format. \\n\\nAlso, maybe add an emoji to keep it friendly. Like a smiley face. \\n\\nSo the final response would be: \"Hello, Manish! How are you today? I\\'m doing well, thanks! Let me know if there\\'s anything I can help with. ðŸ˜Š\"\\n</think>\\n\\nHello, Manish! How are you today? I\\'m doing well, thanks! Let me know if there\\'s anything I can help with. ðŸ˜Š', additional_kwargs={}, response_metadata={}, id='48d4799b-68dd-4ed1-a1b0-13f65afd1d83'), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}, id='72e40f1a-4959-430e-a4f3-89c8a7e2aa55'), HumanMessage(content='<think>\\nOkay, the user asked, \"what is my name?\" after my previous response. They\\'re probably trying to confirm their name or maybe ask for more info. Since they mentioned their name as \"manish\" earlier, I should confirm that. But wait, in the initial message, the user wrote \"manish\" with an \\'m\\' and \\'a\\'... Wait, no, \"manish\" is spelled M-A-N-I-S-H. So their name is Manish. \\n\\nI need to make sure to respond correctly. The user might be confused if I used the wrong spelling. So I should clarify their name. Also, maybe add a friendly emoji. \\n\\nSo the response should be: \"Your name is Manish! ðŸ˜Š Let me know if there\\'s anything I can help with.\" That way, it\\'s clear and friendly. Also, check if there\\'s any other info they need. Maybe ask if they want to continue the conversation. \\n\\nBut the user didn\\'t ask for anything else, so just confirm their name and offer help. Keep it simple and polite.\\n</think>\\n\\nYour name is Manish! ðŸ˜Š Let me know if there\\'s anything I can help with.', additional_kwargs={}, response_metadata={}, id='037e13d8-79c0-45b1-a102-304eb6d5c815')]}\n",
      "StateSnapshot(values={'messages': [HumanMessage(content='hi, my name is manish', additional_kwargs={}, response_metadata={}, id='1ad8d702-4bc4-498f-89c0-d318a544773f'), HumanMessage(content='<think>\\nOkay, the user said, \"hi, my name is manish.\" So they\\'re introducing themselves. I need to respond in a friendly and helpful way.\\n\\nFirst, I should acknowledge their greeting. Maybe say \"Hello!\" to be polite. Then ask how they\\'re doing. \"How are you today?\" is a common question. \\n\\nThey mentioned their name, so I can add that to the response. \"My name is Manish\" â€“ maybe use their name as is, but the user wrote \"manish\" with an \\'m\\' and \\'a\\'... Wait, the user wrote \"manish\" with an \\'m\\' and \\'a\\'? Wait, no, the user wrote \"manish\" â€“ let me check. The original message was \"hi, my name is manish\". So \"manish\" is spelled with an \\'m\\' and \\'a\\'... Wait, no, actually, \"manish\" is spelled M-A-N-I-S-H. So the user wrote \"manish\" with an \\'m\\' and \\'a\\'... Wait, no, \"manish\" is spelled M-A-N-I-S-H. So the user\\'s name is Manish. So I should use their name as is. \\n\\nSo the response should be something like: \"Hello, Manish! How are you today? I\\'m doing well, thanks! Let me know if there\\'s anything I can help with.\" \\n\\nBut maybe the user wants a more casual response. Let me check the initial message again. The user just said \"hi, my name is manish\" â€“ so they\\'re probably looking for a simple, friendly reply. \\n\\nI should make sure to use their name correctly. \"Manish\" is the correct spelling. So the response should be in that format. \\n\\nAlso, maybe add an emoji to keep it friendly. Like a smiley face. \\n\\nSo the final response would be: \"Hello, Manish! How are you today? I\\'m doing well, thanks! Let me know if there\\'s anything I can help with. ðŸ˜Š\"\\n</think>\\n\\nHello, Manish! How are you today? I\\'m doing well, thanks! Let me know if there\\'s anything I can help with. ðŸ˜Š', additional_kwargs={}, response_metadata={}, id='48d4799b-68dd-4ed1-a1b0-13f65afd1d83'), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}, id='72e40f1a-4959-430e-a4f3-89c8a7e2aa55'), HumanMessage(content='<think>\\nOkay, the user asked, \"what is my name?\" after my previous response. They\\'re probably trying to confirm their name or maybe ask for more info. Since they mentioned their name as \"manish\" earlier, I should confirm that. But wait, in the initial message, the user wrote \"manish\" with an \\'m\\' and \\'a\\'... Wait, no, \"manish\" is spelled M-A-N-I-S-H. So their name is Manish. \\n\\nI need to make sure to respond correctly. The user might be confused if I used the wrong spelling. So I should clarify their name. Also, maybe add a friendly emoji. \\n\\nSo the response should be: \"Your name is Manish! ðŸ˜Š Let me know if there\\'s anything I can help with.\" That way, it\\'s clear and friendly. Also, check if there\\'s any other info they need. Maybe ask if they want to continue the conversation. \\n\\nBut the user didn\\'t ask for anything else, so just confirm their name and offer help. Keep it simple and polite.\\n</think>\\n\\nYour name is Manish! ðŸ˜Š Let me know if there\\'s anything I can help with.', additional_kwargs={}, response_metadata={}, id='037e13d8-79c0-45b1-a102-304eb6d5c815')]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0856e9-2d47-6484-8004-e4a95bd708d8'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': ['<think>\\nOkay, the user asked, \"what is my name?\" after my previous response. They\\'re probably trying to confirm their name or maybe ask for more info. Since they mentioned their name as \"manish\" earlier, I should confirm that. But wait, in the initial message, the user wrote \"manish\" with an \\'m\\' and \\'a\\'... Wait, no, \"manish\" is spelled M-A-N-I-S-H. So their name is Manish. \\n\\nI need to make sure to respond correctly. The user might be confused if I used the wrong spelling. So I should clarify their name. Also, maybe add a friendly emoji. \\n\\nSo the response should be: \"Your name is Manish! ðŸ˜Š Let me know if there\\'s anything I can help with.\" That way, it\\'s clear and friendly. Also, check if there\\'s any other info they need. Maybe ask if they want to continue the conversation. \\n\\nBut the user didn\\'t ask for anything else, so just confirm their name and offer help. Keep it simple and polite.\\n</think>\\n\\nYour name is Manish! ðŸ˜Š Let me know if there\\'s anything I can help with.']}}, 'thread_id': '1', 'step': 4, 'parents': {}}, created_at='2025-08-30T06:57:20.477873+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0856e8-be22-664e-8003-9fd97f4b4448'}}, tasks=())\n"
     ]
    }
   ],
   "source": [
    "thread1 = {'configurable':{\"thread_id\":\"1\"}} # Create a memory box with id 1\n",
    "\n",
    "result_1 = graph.invoke({\"messages\":[HumanMessage('hi, my name is manish')]},thread1) # call the chatbot with a message and result_1 store the response\n",
    "print(result_1)\n",
    "result_2 = graph.invoke(\n",
    "    {\"messages\":[HumanMessage(\"what is my name?\")]},thread1\n",
    ")\n",
    "print(result_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca84c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='hi, my name is manish', additional_kwargs={}, response_metadata={}, id='1ad8d702-4bc4-498f-89c0-d318a544773f'), HumanMessage(content='<think>\\nOkay, the user said, \"hi, my name is manish.\" So they\\'re introducing themselves. I need to respond in a friendly and helpful way.\\n\\nFirst, I should acknowledge their greeting. Maybe say \"Hello!\" to be polite. Then ask how they\\'re doing. \"How are you today?\" is a common question. \\n\\nThey mentioned their name, so I can add that to the response. \"My name is Manish\" â€“ maybe use their name as is, but the user wrote \"manish\" with an \\'m\\' and \\'a\\'... Wait, the user wrote \"manish\" with an \\'m\\' and \\'a\\'? Wait, no, the user wrote \"manish\" â€“ let me check. The original message was \"hi, my name is manish\". So \"manish\" is spelled with an \\'m\\' and \\'a\\'... Wait, no, actually, \"manish\" is spelled M-A-N-I-S-H. So the user wrote \"manish\" with an \\'m\\' and \\'a\\'... Wait, no, \"manish\" is spelled M-A-N-I-S-H. So the user\\'s name is Manish. So I should use their name as is. \\n\\nSo the response should be something like: \"Hello, Manish! How are you today? I\\'m doing well, thanks! Let me know if there\\'s anything I can help with.\" \\n\\nBut maybe the user wants a more casual response. Let me check the initial message again. The user just said \"hi, my name is manish\" â€“ so they\\'re probably looking for a simple, friendly reply. \\n\\nI should make sure to use their name correctly. \"Manish\" is the correct spelling. So the response should be in that format. \\n\\nAlso, maybe add an emoji to keep it friendly. Like a smiley face. \\n\\nSo the final response would be: \"Hello, Manish! How are you today? I\\'m doing well, thanks! Let me know if there\\'s anything I can help with. ðŸ˜Š\"\\n</think>\\n\\nHello, Manish! How are you today? I\\'m doing well, thanks! Let me know if there\\'s anything I can help with. ðŸ˜Š', additional_kwargs={}, response_metadata={}, id='48d4799b-68dd-4ed1-a1b0-13f65afd1d83'), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}, id='72e40f1a-4959-430e-a4f3-89c8a7e2aa55'), HumanMessage(content='<think>\\nOkay, the user asked, \"what is my name?\" after my previous response. They\\'re probably trying to confirm their name or maybe ask for more info. Since they mentioned their name as \"manish\" earlier, I should confirm that. But wait, in the initial message, the user wrote \"manish\" with an \\'m\\' and \\'a\\'... Wait, no, \"manish\" is spelled M-A-N-I-S-H. So their name is Manish. \\n\\nI need to make sure to respond correctly. The user might be confused if I used the wrong spelling. So I should clarify their name. Also, maybe add a friendly emoji. \\n\\nSo the response should be: \"Your name is Manish! ðŸ˜Š Let me know if there\\'s anything I can help with.\" That way, it\\'s clear and friendly. Also, check if there\\'s any other info they need. Maybe ask if they want to continue the conversation. \\n\\nBut the user didn\\'t ask for anything else, so just confirm their name and offer help. Keep it simple and polite.\\n</think>\\n\\nYour name is Manish! ðŸ˜Š Let me know if there\\'s anything I can help with.', additional_kwargs={}, response_metadata={}, id='037e13d8-79c0-45b1-a102-304eb6d5c815')]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0856e9-2d47-6484-8004-e4a95bd708d8'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': ['<think>\\nOkay, the user asked, \"what is my name?\" after my previous response. They\\'re probably trying to confirm their name or maybe ask for more info. Since they mentioned their name as \"manish\" earlier, I should confirm that. But wait, in the initial message, the user wrote \"manish\" with an \\'m\\' and \\'a\\'... Wait, no, \"manish\" is spelled M-A-N-I-S-H. So their name is Manish. \\n\\nI need to make sure to respond correctly. The user might be confused if I used the wrong spelling. So I should clarify their name. Also, maybe add a friendly emoji. \\n\\nSo the response should be: \"Your name is Manish! ðŸ˜Š Let me know if there\\'s anything I can help with.\" That way, it\\'s clear and friendly. Also, check if there\\'s any other info they need. Maybe ask if they want to continue the conversation. \\n\\nBut the user didn\\'t ask for anything else, so just confirm their name and offer help. Keep it simple and polite.\\n</think>\\n\\nYour name is Manish! ðŸ˜Š Let me know if there\\'s anything I can help with.']}}, 'thread_id': '1', 'step': 4, 'parents': {}}, created_at='2025-08-30T06:57:20.477873+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0856e8-be22-664e-8003-9fd97f4b4448'}}, tasks=())"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(thread1) # return the current state of Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfa550d",
   "metadata": {},
   "source": [
    "### Modifying Chat History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aa7288",
   "metadata": {},
   "source": [
    "#### Trimming Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcdb2181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/GEN_ENV/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"hi! I'm manish\", additional_kwargs={}, response_metadata={}), AIMessage(content='hi!', additional_kwargs={}, response_metadata={}), HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}), AIMessage(content='nice', additional_kwargs={}, response_metadata={}), HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}), AIMessage(content='4', additional_kwargs={}, response_metadata={}), HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}), AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}), HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}), AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages,HumanMessage,AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm manish\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 65,\n",
    "    strategy =\"last\",\n",
    "    token_counter = OllamaLLM(model=\"llama3.2:3b\"),\n",
    "    include_system = True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "trimmed = trimmer.invoke(messages)\n",
    "print(trimmed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cdeea2",
   "metadata": {},
   "source": [
    "#### Filtering Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa4e366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human messages: [HumanMessage(content='example input', additional_kwargs={}, response_metadata={}, name='example_user', id='2'), HumanMessage(content='real input', additional_kwargs={}, response_metadata={}, name='bob', id='4')]\n",
      "\n",
      "Excluding example names: [SystemMessage(content='you are a good assistant', additional_kwargs={}, response_metadata={}, id='1'), HumanMessage(content='real input', additional_kwargs={}, response_metadata={}, name='bob', id='4'), AIMessage(content='real output', additional_kwargs={}, response_metadata={}, name='alice', id='5')]\n",
      "\n",
      "Filtered by types and IDs: [HumanMessage(content='example input', additional_kwargs={}, response_metadata={}, name='example_user', id='2'), HumanMessage(content='real input', additional_kwargs={}, response_metadata={}, name='bob', id='4'), AIMessage(content='real output', additional_kwargs={}, response_metadata={}, name='alice', id='5')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    filter_messages,\n",
    ")\n",
    "\n",
    "# Sample messages\n",
    "messages = [\n",
    "    SystemMessage(content=\"you are a good assistant\", id=\"1\"),\n",
    "    HumanMessage(content=\"example input\", id=\"2\", name=\"example_user\"),\n",
    "    AIMessage(content=\"example output\", id=\"3\", name=\"example_assistant\"),\n",
    "    HumanMessage(content=\"real input\", id=\"4\", name=\"bob\"),\n",
    "    AIMessage(content=\"real output\", id=\"5\", name=\"alice\"),\n",
    "]\n",
    "human_messages = filter_messages(messages,include_types = \"human\")\n",
    "print(\"Human messages:\", human_messages)\n",
    "\n",
    "excluded_name = filter_messages(\n",
    "    messages,exclude_names=['example_user','example_assistant']\n",
    ")\n",
    "\n",
    "print(\"\\nExcluding example names:\", excluded_name)\n",
    "\n",
    "filtered_messages = filter_messages(\n",
    "    messages,include_types=[\"human\",\"ai\"],exclude_ids=[\"3\"]\n",
    "    \n",
    ")\n",
    "print(\"\\nFiltered by types and IDs:\",filtered_messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae2d9aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=RunnableLambda(...) middle=[] last=OllamaLLM(model='qwen3:1.7b')\n"
     ]
    }
   ],
   "source": [
    "filter = filter_messages(excluded_name=[\"example_user\"])\n",
    "chain = filter|model\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606dbd0c",
   "metadata": {},
   "source": [
    "#### Merging Consecutive Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "018a0825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=\"you're a good assistant.\\nyou always respond with a joke.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=[{'type': 'text', 'text': \"i wonder why it's called langchain\"}, 'and who is harrison chasing anyways'], additional_kwargs={}, response_metadata={}), AIMessage(content='Well, I guess they thought \"WordRope\" and \"SentenceString\" just didn\\'t have the same ring to it!\\nWhy, he\\'s probably chasing after the last cup of coffee in the office!', additional_kwargs={}, response_metadata={}), SystemMessage(content='how good this function is lets see', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import merge_message_runs\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant.\"),\n",
    "    SystemMessage(content=\"you always respond with a joke.\"),\n",
    "    HumanMessage(\n",
    "        content=[{\"type\": \"text\", \"text\": \"i wonder why it's called langchain\"}]\n",
    "    ),\n",
    "    HumanMessage(content=\"and who is harrison chasing anyways\"),\n",
    "    AIMessage(\n",
    "        content='Well, I guess they thought \"WordRope\" and \"SentenceString\" just didn\\'t have the same ring to it!'\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content=\"Why, he's probably chasing after the last cup of coffee in the office!\"\n",
    "    ),\n",
    "    SystemMessage(content=\"how good this function is lets see\"),\n",
    "]\n",
    "merged = merge_message_runs(messages)\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afe8106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merger = merge_message_runs()\n",
    "chain = merger | model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEN_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
